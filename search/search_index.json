{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Sherlock AI","text":"<p>A Python package for performance monitoring and logging utilities that helps you track execution times and debug your applications with ease.</p>"},{"location":"#overview","title":"Overview","text":"<p>Sherlock AI provides a comprehensive suite of tools for monitoring, logging, and analyzing Python applications. Whether you're building APIs, data pipelines, or any Python application, Sherlock AI helps you understand performance characteristics, track errors, and maintain code quality.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83c\udfaf Performance Decorators: Easy-to-use decorators for tracking function execution times</li> <li>\ud83e\udde0 Memory Monitoring: Track Python memory usage with detailed heap and tracemalloc integration</li> <li>\ud83d\udcca Resource Monitoring: Monitor CPU, memory, I/O, and network usage during function execution</li> <li>\u23f1\ufe0f Context Managers: Monitor code block execution with simple context managers</li> <li>\ud83d\udd27 Advanced Configuration System: Complete control over logging with dataclass-based configuration</li> <li>\u26a1 Simplified Configuration: Auto-expanding file paths - just specify base names instead of full paths</li> <li>\ud83c\udf9b\ufe0f Configuration Presets: Pre-built setups for development, production, and testing environments</li> <li>\ud83d\udd04 Async/Sync Support: Works seamlessly with both synchronous and asynchronous functions</li> <li>\ud83d\udcc8 Request Tracking: Built-in request ID tracking for distributed systems</li> <li>\ud83d\udcc1 Flexible Log Management: Enable/disable log files, custom directories, and rotation settings</li> <li>\ud83c\udff7\ufe0f Logger Name Constants: Easy access to available logger names with autocomplete support</li> <li>\ud83d\udd0d Logger Discovery: Programmatically discover available loggers in your application</li> <li>\ud83d\udc1b Development-Friendly: Optimized for FastAPI auto-reload and development environments</li> <li>\ud83c\udfa8 Modular Architecture: Clean, focused modules for different monitoring aspects</li> <li>\ud83c\udfd7\ufe0f Class-Based Architecture: Advanced <code>SherlockAI</code> class for instance-based logging management</li> <li>\ud83d\udd04 Runtime Reconfiguration: Change logging settings without application restart</li> <li>\ud83e\uddf9 Resource Management: Automatic cleanup and context manager support</li> <li>\ud83d\udd0d Logging Introspection: Query current logging configuration and statistics</li> <li>\ud83d\udccb JSON Format Support: Choose between standard log format or structured JSON output for better parsing and analysis</li> <li>\ud83d\udd0d Code Analysis: Automatic detection and refactoring of hardcoded values using AST parsing and LLM suggestions</li> <li>\ud83d\uddc4\ufe0f MongoDB Integration: Automatic error insights storage with MongoDB support</li> <li>\ud83c\udf10 API Client Integration: HTTP-based data ingestion to centralized backend services</li> <li>\ud83d\udea8 Error Analysis: AI-powered error analysis with automatic probable cause detection</li> <li>\ud83d\udca1 Performance Insights: AI-powered performance analysis that intelligently extracts user-defined function source code</li> <li>\ud83d\udd04 Auto-Instrumentation: Zero-code setup for popular frameworks like FastAPI, automatically instrumenting routes with monitoring decorators</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sherlock-ai\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code>from sherlock_ai import sherlock_ai, get_logger, log_performance\nimport time\n\n# Initialize logging (call once at application startup)\nsherlock_ai()\n\n# Get a logger for your module\nlogger = get_logger(__name__)\n\n@log_performance\ndef my_function():\n    time.sleep(1)\n    logger.info(\"Processing completed\")\n    return \"result\"\n\n# This will log: PERFORMANCE | my_module.my_function | SUCCESS | 1.003s\nresult = my_function()\n</code></pre>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li> <p> Installation</p> <p>Install Sherlock AI and learn about requirements</p> </li> <li> <p> Quick Start</p> <p>Get up and running in minutes with basic examples</p> </li> <li> <p> Features</p> <p>Explore performance, memory, and resource monitoring</p> </li> <li> <p> Configuration</p> <p>Learn how to configure Sherlock AI for your needs</p> </li> <li> <p> Examples</p> <p>Real-world examples and integration patterns</p> </li> <li> <p> API Reference</p> <p>Complete API documentation and reference</p> </li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<ul> <li>API Performance Monitoring: Track response times for your web APIs</li> <li>Memory Leak Detection: Monitor memory usage patterns to identify potential leaks</li> <li>Resource Optimization: Analyze CPU, memory, and I/O usage</li> <li>Database Query Optimization: Monitor slow database operations</li> <li>Microservices Debugging: Trace execution times across service boundaries</li> <li>Production Monitoring: Get insights into application performance characteristics</li> <li>Error Analysis &amp; Debugging: AI-powered error analysis with automatic storage</li> <li>Code Quality Improvement: Automatically detect and refactor hardcoded values</li> </ul>"},{"location":"#authors","title":"Authors","text":"<p>Pranaw Mishra - pranawmishra73@gmail.com</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#links","title":"Links","text":"<ul> <li>Homepage: https://github.com/pranawmishra/sherlock-ai</li> <li>Repository: https://github.com/pranawmishra/sherlock-ai</li> <li>Issues: https://github.com/pranawmishra/sherlock-ai/issues</li> <li>PyPI: https://pypi.org/project/sherlock-ai/</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python &gt;= 3.8</li> <li>psutil &gt;= 5.8.0 (for memory and resource monitoring)</li> <li>astor &gt;= 0.8.1 (for AST to source code conversion in code analysis)</li> <li>groq &gt;= 0.30.0 (for LLM-based analysis and constant naming)</li> <li>pymongo &gt;= 4.0.0 (for MongoDB error insight storage)</li> <li>requests &gt;= 2.32.4 (for HTTP-based API client integration)</li> </ul>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>Install Sherlock AI using pip:</p> <pre><code>pip install sherlock-ai\n</code></pre>"},{"location":"installation/#install-from-source","title":"Install from Source","text":"<p>If you want to install from source for development:</p> <pre><code>git clone https://github.com/pranawmishra/sherlock-ai.git\ncd sherlock-ai\npip install -e .\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>Verify that Sherlock AI is installed correctly:</p> <pre><code>import sherlock_ai\nprint(sherlock_ai.__version__)\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"installation/#mongodb-support","title":"MongoDB Support","text":"<p>For error insight storage with MongoDB:</p> <pre><code>pip install pymongo\n</code></pre> <p>Set up your MongoDB connection:</p> <pre><code>import os\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\n</code></pre>"},{"location":"installation/#api-client-support","title":"API Client Support","text":"<p>For HTTP-based data ingestion to centralized backend services:</p> <pre><code>pip install requests\n</code></pre> <p>Configure your API key:</p> <pre><code>import os\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"your-api-key-here\"\n</code></pre>"},{"location":"installation/#code-analysis-support","title":"Code Analysis Support","text":"<p>For automatic hardcoded value detection and refactoring:</p> <pre><code>pip install astor groq\n</code></pre> <p>Set up your Groq API key for intelligent constant naming:</p> <pre><code>import os\nos.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key\"\n</code></pre>"},{"location":"installation/#whats-next","title":"What's Next?","text":"<ul> <li>Quick Start Guide - Get started with basic usage</li> <li>Configuration - Learn about configuration options</li> <li>Features - Explore all available features</li> </ul>"},{"location":"log-output-format/","title":"Log Output Format","text":"<p>Understanding Sherlock AI's log output formats and structure.</p>"},{"location":"log-output-format/#standard-log-format","title":"Standard Log Format","text":"<p>The default log format follows this pattern:</p> <pre><code>{timestamp} - {request_id} - {logger_name} - {log_level} - {message}\n</code></pre>"},{"location":"log-output-format/#example","title":"Example","text":"<pre><code>2025-07-15 20:51:19 - aa580b62 - ApiLogger - INFO - Request started\n</code></pre>"},{"location":"log-output-format/#components","title":"Components","text":"<ul> <li>timestamp: Date and time (<code>%Y-%m-%d %H:%M:%S</code>)</li> <li>request_id: Request ID (or <code>-</code> if not set)</li> <li>logger_name: Name of the logger</li> <li>log_level: INFO, DEBUG, WARNING, ERROR, CRITICAL</li> <li>message: The log message content</li> </ul>"},{"location":"log-output-format/#json-log-format","title":"JSON Log Format","text":"<p>Structured JSON format for better parsing and analysis:</p> <pre><code>{\n  \"timestamp\": \"2025-07-15 20:51:19\",\n  \"level\": \"INFO\",\n  \"logger\": \"ApiLogger\",\n  \"message\": \"Request started\",\n  \"request_id\": \"aa580b62\",\n  \"module\": \"myapp\",\n  \"function\": \"api_call\",\n  \"line\": 42,\n  \"thread\": 13672,\n  \"thread_name\": \"MainThread\",\n  \"process\": 22008\n}\n</code></pre>"},{"location":"log-output-format/#performance-logs","title":"Performance Logs","text":""},{"location":"log-output-format/#standard-format","title":"Standard Format","text":"<pre><code>PERFORMANCE | {function_name} | {STATUS} | {execution_time}s | {additional_info}\n</code></pre>"},{"location":"log-output-format/#examples","title":"Examples","text":"<pre><code>2025-07-05 19:19:11 - 07ca74ed - PerformanceLogger - INFO - PERFORMANCE | tests.test_fastapi.health_check | SUCCESS | 0.262s\n\n2025-07-05 21:13:03 - 2c4774b0 - PerformanceLogger - INFO - PERFORMANCE | my_module.api_call | ERROR | 2.456s | Connection timeout\n\n2025-07-05 19:20:15 - - - PerformanceLogger - INFO - PERFORMANCE | database_query | SUCCESS | 0.089s | Args: ('user123',) | Kwargs: {'limit': 10}\n</code></pre>"},{"location":"log-output-format/#with-arguments","title":"With Arguments","text":"<p>When <code>include_args=True</code>:</p> <pre><code>PERFORMANCE | my_module.slow_query | SUCCESS | 0.156s | Args: ('user123',) | Kwargs: {'limit': 10}\n</code></pre>"},{"location":"log-output-format/#memory-monitoring-logs","title":"Memory Monitoring Logs","text":""},{"location":"log-output-format/#format","title":"Format","text":"<pre><code>MEMORY | {function_name} | {STATUS} | {execution_time}s | Current: {current_memory} | Change: {memory_change} | Traced: {traced_memory} (Peak: {peak_memory})\n</code></pre>"},{"location":"log-output-format/#examples_1","title":"Examples","text":"<pre><code>2025-07-05 19:19:11 - 07ca74ed - MonitoringLogger - INFO - MEMORY | tests.test_fastapi.health_check | SUCCESS | 0.261s | Current: 57.66MB | Change: +1.64MB | Traced: 24.33KB (Peak: 30.33KB)\n\n2025-07-05 21:15:22 - - - MonitoringLogger - INFO - MEMORY | data_processor | SUCCESS | 0.245s | Current: 45.67MB | Change: +12.34MB\n\n2025-07-05 19:20:15 - 2c4774b0 - MonitoringLogger - INFO - MEMORY | load_large_file | SUCCESS | 2.156s | Current: 256.89MB | Change: +128.45MB | Traced: 125.67MB (Peak: 145.23MB)\n</code></pre>"},{"location":"log-output-format/#components_1","title":"Components","text":"<ul> <li>Current: Total process memory (RSS)</li> <li>Change: Memory difference during execution</li> <li>Traced: Python object memory (when <code>trace_malloc=True</code>)</li> <li>Peak: Peak memory during execution</li> </ul>"},{"location":"log-output-format/#resource-monitoring-logs","title":"Resource Monitoring Logs","text":""},{"location":"log-output-format/#format_1","title":"Format","text":"<pre><code>RESOURCES | {function_name} | {STATUS} | {execution_time}s | CPU: {cpu_percent}% | Memory: {memory_usage} ({memory_change}) | Threads: {thread_count} | I/O: R:{read_bytes} W:{write_bytes} | Network: Sent:{sent_bytes} Recv:{recv_bytes}\n</code></pre>"},{"location":"log-output-format/#examples_2","title":"Examples","text":"<pre><code>2025-07-05 19:19:11 - 07ca74ed - MonitoringLogger - INFO - RESOURCES | tests.test_fastapi.health_check | SUCCESS | 0.144s | CPU: 59.3% | Memory: 57.66MB (+1.63MB) | Threads: 9 | I/O: R:0.00B W:414.00B\n\n2025-07-05 21:13:03 - 2c4774b0 - MonitoringLogger - INFO - RESOURCES | api_handler | SUCCESS | 0.156s | CPU: 25.4% | Memory: 128.45MB (+5.23MB) | Threads: 12 | I/O: R:2.34MB W:1.12MB\n\n2025-07-05 19:25:30 - - - MonitoringLogger - INFO - RESOURCES | database_query | SUCCESS | 0.089s | CPU: 15.2% | Memory: 95.67MB (+0.12MB) | Threads: 8\n\n2025-07-05 20:15:45 - a1b2c3d4 - MonitoringLogger - INFO - RESOURCES | api_call | SUCCESS | 0.523s | CPU: 10.5% | Memory: 85.34MB (+2.15MB) | Threads: 10 | I/O: R:1.23MB W:0.05MB | Network: Sent:2.34KB Recv:125.67KB\n</code></pre>"},{"location":"log-output-format/#components_2","title":"Components","text":"<ul> <li>CPU: CPU usage percentage</li> <li>Memory: Current memory and change</li> <li>Threads: Number of threads</li> <li>I/O: Disk read/write (when <code>include_io=True</code>)</li> <li>Network: Network send/receive (when <code>include_network=True</code>)</li> </ul>"},{"location":"log-output-format/#request-id-in-logs","title":"Request ID in Logs","text":""},{"location":"log-output-format/#with-request-id","title":"With Request ID","text":"<pre><code>2025-07-05 19:19:11 - 07ca74ed - PerformanceLogger - INFO - PERFORMANCE | api_call | SUCCESS | 0.234s\n</code></pre>"},{"location":"log-output-format/#without-request-id","title":"Without Request ID","text":"<pre><code>2025-07-05 19:19:11 - - - PerformanceLogger - INFO - PERFORMANCE | api_call | SUCCESS | 0.234s\n</code></pre>"},{"location":"log-output-format/#setting-request-ids","title":"Setting Request IDs","text":"<pre><code>from sherlock_ai import set_request_id\n\n# Auto-generate\nrequest_id = set_request_id()\n\n# Custom ID\nrequest_id = set_request_id(\"req-12345\")\n</code></pre>"},{"location":"log-output-format/#parsing-logs","title":"Parsing Logs","text":""},{"location":"log-output-format/#parse-standard-format","title":"Parse Standard Format","text":"<pre><code>import re\n\npattern = r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) - ([^ ]+) - ([^ ]+) - (\\w+) - (.+)'\n\nwith open('logs/app.log', 'r') as f:\n    for line in f:\n        match = re.match(pattern, line)\n        if match:\n            timestamp, request_id, logger, level, message = match.groups()\n            print(f\"Level: {level}, Message: {message}\")\n</code></pre>"},{"location":"log-output-format/#parse-json-format","title":"Parse JSON Format","text":"<pre><code>import json\n\nwith open('logs/app.json', 'r') as f:\n    for line in f:\n        if line.strip():\n            log = json.loads(line)\n            print(f\"{log['level']}: {log['message']}\")\n</code></pre>"},{"location":"log-output-format/#parse-performance-logs","title":"Parse Performance Logs","text":"<pre><code>import re\n\npattern = r'PERFORMANCE \\| ([^ ]+) \\| (\\w+) \\| ([\\d.]+)s'\n\nwith open('logs/performance.log', 'r') as f:\n    for line in f:\n        match = re.search(pattern, line)\n        if match:\n            function, status, duration = match.groups()\n            print(f\"{function}: {duration}s ({status})\")\n</code></pre>"},{"location":"log-output-format/#custom-log-formats","title":"Custom Log Formats","text":"<p>You can customize the log format:</p> <pre><code>from sherlock_ai import LoggingConfig\n\nconfig = LoggingConfig(\n    log_format=\"%(asctime)s | %(name)s | %(levelname)s | %(message)s\",\n    date_format=\"%Y-%m-%d %H:%M:%S\"\n)\n</code></pre>"},{"location":"log-output-format/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration - Configure log formats</li> <li>JSON Logging - Use JSON format</li> <li>Examples - See logs in action</li> </ul>"},{"location":"quick-start/","title":"Quick Start","text":"<p>Get up and running with Sherlock AI in minutes.</p>"},{"location":"quick-start/#basic-setup","title":"Basic Setup","text":"<p>The simplest way to get started:</p> <pre><code>from sherlock_ai import sherlock_ai, get_logger, log_performance\nimport time\n\n# Initialize logging (call once at application startup)\nsherlock_ai()\n\n# Get a logger for your module\nlogger = get_logger(__name__)\n\n@log_performance\ndef my_function():\n    time.sleep(1)\n    logger.info(\"Processing completed\")\n    return \"result\"\n\n# This will log: PERFORMANCE | my_module.my_function | SUCCESS | 1.003s\nresult = my_function()\n</code></pre>"},{"location":"quick-start/#with-error-handling-and-code-analysis","title":"With Error Handling and Code Analysis","text":"<p>Add more features with decorators:</p> <pre><code>from sherlock_ai import sherlock_ai, get_logger, log_performance, hardcoded_value_detector\nfrom sherlock_ai.monitoring import sherlock_error_handler\nimport time\n\n# Initialize logging\nsherlock_ai()\nlogger = get_logger(__name__)\n\n@log_performance\n@hardcoded_value_detector\n@sherlock_error_handler\ndef my_function():\n    # Your code here - hardcoded values will be automatically detected\n    # Errors will be automatically analyzed and stored in MongoDB\n    try:\n        time.sleep(1)\n        logger.info(\"Processing completed\")\n        return \"result\"\n    except Exception as e:\n        logger.error(f\"Error: {e}\")\n        raise\n\nresult = my_function()\n</code></pre> <p>This will: - Log performance metrics: <code>PERFORMANCE | my_module.my_function | SUCCESS | 1.003s</code> - Automatically refactor any hardcoded values to constants - Analyze any errors with AI-powered insights</p>"},{"location":"quick-start/#class-based-setup-advanced","title":"Class-Based Setup (Advanced)","text":"<p>For more control, use the class-based API:</p> <pre><code>from sherlock_ai import SherlockAI, get_logger, log_performance\n\n# Initialize with class-based approach\nlogger_manager = SherlockAI()\nlogger_manager.setup()\n\n# Get a logger for your module\nlogger = get_logger(__name__)\n\n@log_performance\ndef my_function():\n    logger.info(\"Processing with class-based setup\")\n    return \"result\"\n\n# Later, reconfigure without restart\nfrom sherlock_ai import LoggingPresets\nlogger_manager.reconfigure(LoggingPresets.development())\n\n# Or use as context manager\nwith SherlockAI() as temp_logger:\n    # Temporary logging configuration\n    logger.info(\"This uses temporary configuration\")\n# Automatically cleaned up\n</code></pre>"},{"location":"quick-start/#using-logger-name-constants","title":"Using Logger Name Constants","text":"<p>Use predefined logger names with autocomplete support:</p> <pre><code>from sherlock_ai import sherlock_ai, get_logger, LoggerNames, list_available_loggers\n\n# Initialize logging\nsherlock_ai()\n\n# Use predefined logger names with autocomplete support\napi_logger = get_logger(LoggerNames.API)\ndb_logger = get_logger(LoggerNames.DATABASE)\nservice_logger = get_logger(LoggerNames.SERVICES)\n\n# Discover available loggers programmatically\navailable_loggers = list_available_loggers()\nprint(f\"Available loggers: {available_loggers}\")\n\n# Use the loggers\napi_logger.info(\"API request received\")        # \u2192 logs/api.log\ndb_logger.info(\"Database query executed\")     # \u2192 logs/database.log\nservice_logger.info(\"Service operation done\") # \u2192 logs/services.log\n</code></pre>"},{"location":"quick-start/#advanced-configuration","title":"Advanced Configuration","text":"<p>Configure performance monitoring with custom parameters:</p> <pre><code>@log_performance(min_duration=0.1, include_args=True, log_level=\"DEBUG\")\ndef slow_database_query(user_id, limit=10):\n    # Only logs if execution time &gt;= 0.1 seconds\n    # Includes function arguments in the log\n    pass\n</code></pre>"},{"location":"quick-start/#context-manager-for-code-blocks","title":"Context Manager for Code Blocks","text":"<p>Monitor specific code blocks:</p> <pre><code>from sherlock_ai.performance import PerformanceTimer\n\nwith PerformanceTimer(\"database_operation\"):\n    # Your code block here\n    result = database.query(\"SELECT * FROM users\")\n\n# Logs: PERFORMANCE | database_operation | SUCCESS | 0.234s\n</code></pre>"},{"location":"quick-start/#async-function-support","title":"Async Function Support","text":"<p>Works automatically with async functions:</p> <pre><code>import httpx\n\n@log_performance\nasync def async_api_call():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com\")\n        return response.json()\n\n# Works automatically with async functions\nresult = await async_api_call()\n</code></pre>"},{"location":"quick-start/#default-log-files","title":"Default Log Files","text":"<p>When you call <code>sherlock_ai()</code>, it automatically creates a <code>logs/</code> directory with these files:</p> <ul> <li><code>app.log</code> - All INFO+ level logs from root logger</li> <li><code>errors.log</code> - Only ERROR+ level logs from any logger</li> <li><code>api.log</code> - Logs from <code>app.api</code> logger</li> <li><code>database.log</code> - Logs from <code>app.core.dbConnection</code> logger</li> <li><code>services.log</code> - Logs from <code>app.services</code> logger</li> <li><code>performance.log</code> - Performance monitoring logs</li> </ul>"},{"location":"quick-start/#whats-next","title":"What's Next?","text":"<p>Now that you have the basics, explore more features:</p> <ul> <li>Performance Monitoring - Track execution times</li> <li>Memory Monitoring - Monitor memory usage</li> <li>Resource Monitoring - Track CPU, I/O, and network</li> <li>Error Analysis - AI-powered error insights</li> <li>Configuration - Customize your setup</li> <li>Examples - Real-world integration examples</li> </ul>"},{"location":"advanced/class-based-api/","title":"Class-Based API","text":"<p>Advanced logging management using the <code>SherlockAI</code> class for instance-based configuration and runtime control.</p>"},{"location":"advanced/class-based-api/#basic-usage","title":"Basic Usage","text":"<pre><code>from sherlock_ai import SherlockAI, get_logger\n\n# Initialize with class-based approach\nlogger_manager = SherlockAI()\nlogger_manager.setup()\n\n# Get a logger\nlogger = get_logger(__name__)\n\n@log_performance\ndef my_function():\n    logger.info(\"Processing with class-based setup\")\n    return \"result\"\n</code></pre>"},{"location":"advanced/class-based-api/#with-custom-configuration","title":"With Custom Configuration","text":"<pre><code>from sherlock_ai import SherlockAI, LoggingConfig, LogFileConfig\n\nconfig = LoggingConfig(\n    logs_dir=\"custom_logs\",\n    log_format_type=\"json\",\n    log_files={\n        \"app\": LogFileConfig(\"application\", max_bytes=50*1024*1024)\n    }\n)\n\nlogger_manager = SherlockAI(config=config)\nlogger_manager.setup()\n</code></pre>"},{"location":"advanced/class-based-api/#runtime-reconfiguration","title":"Runtime Reconfiguration","text":"<pre><code>from sherlock_ai import SherlockAI, LoggingPresets\n\n# Initial setup\nlogger_manager = SherlockAI()\nlogger_manager.setup()\n\n# Later, change configuration without restart\nlogger_manager.reconfigure(LoggingPresets.production())\n</code></pre>"},{"location":"advanced/class-based-api/#context-manager","title":"Context Manager","text":"<pre><code>from sherlock_ai import SherlockAI, LoggingConfig\n\n# Temporary configuration\nwith SherlockAI(LoggingConfig(logs_dir=\"temp_logs\")) as temp_logger:\n    # Use temporary logging configuration\n    logger.info(\"This uses temporary config\")\n# Automatically cleaned up\n</code></pre>"},{"location":"advanced/class-based-api/#singleton-pattern","title":"Singleton Pattern","text":"<pre><code>from sherlock_ai import SherlockAI\n\n# Get or create singleton instance\nlogger_manager = SherlockAI.get_instance()\n</code></pre> <p>Learn more about runtime reconfiguration \u2192</p>"},{"location":"advanced/introspection/","title":"Logging Introspection","text":"<p>Query current logging configuration and statistics at runtime.</p>"},{"location":"advanced/introspection/#get-logging-statistics","title":"Get Logging Statistics","text":"<pre><code>from sherlock_ai import sherlock_ai, get_logging_stats\n\nsherlock_ai()\n\nstats = get_logging_stats()\nprint(f\"Configured: {stats['is_configured']}\")\nprint(f\"Active handlers: {stats['handlers']}\")\nprint(f\"Log directory: {stats['logs_dir']}\")\n</code></pre>"},{"location":"advanced/introspection/#get-current-configuration","title":"Get Current Configuration","text":"<pre><code>from sherlock_ai import sherlock_ai, get_current_config\n\nsherlock_ai()\n\nconfig = get_current_config()\nif config:\n    print(f\"Console enabled: {config.console_enabled}\")\n    print(f\"Console level: {config.console_level}\")\n    print(f\"Log files: {list(config.log_files.keys())}\")\n\n    for name, log_file in config.log_files.items():\n        print(f\"{name}: enabled={log_file.enabled}, level={log_file.level}\")\n</code></pre>"},{"location":"advanced/introspection/#class-based-statistics","title":"Class-Based Statistics","text":"<pre><code>from sherlock_ai import SherlockAI\n\nlogger_manager = SherlockAI()\nlogger_manager.setup()\n\nstats = logger_manager.get_stats()\nprint(f\"Configuration: {stats}\")\n</code></pre>"},{"location":"advanced/introspection/#use-cases","title":"Use Cases","text":"<ul> <li>Monitor logging health</li> <li>Debug configuration issues</li> <li>Dynamic configuration adjustments</li> <li>Logging dashboards</li> </ul>"},{"location":"advanced/request-tracking/","title":"Request Tracking","text":"<p>Track requests across distributed systems with request IDs.</p>"},{"location":"advanced/request-tracking/#setting-request-ids","title":"Setting Request IDs","text":"<pre><code>from sherlock_ai import set_request_id, get_request_id\n\n# Auto-generate request ID\nrequest_id = set_request_id()  # Returns: \"a1b2c3d4\"\n\n# Custom request ID\nrequest_id = set_request_id(\"req-12345\")\n\n# Get current request ID\ncurrent_id = get_request_id()\n</code></pre>"},{"location":"advanced/request-tracking/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI, Request\nfrom sherlock_ai import SherlockAI, LoggingConfig, set_request_id\n\nconfig = LoggingConfig(auto_instrument=True)\nlogger_manager = SherlockAI(config=config)\nlogger_manager.setup()\n\napp = FastAPI()\n\n@app.middleware(\"http\")\nasync def request_id_middleware(request: Request, call_next):\n    # Get from header or generate\n    request_id = request.headers.get(\"X-Request-ID\", set_request_id())\n\n    response = await call_next(request)\n\n    # Return in response header\n    response.headers[\"X-Request-ID\"] = request_id\n    return response\n</code></pre>"},{"location":"advanced/request-tracking/#log-output-with-request-id","title":"Log Output with Request ID","text":"<p>All logs include the request ID:</p> <pre><code>2025-01-01 12:34:56 - a1b2c3d4 - ApiLogger - INFO - Request started\n2025-01-01 12:34:56 - a1b2c3d4 - PerformanceLogger - INFO - PERFORMANCE | api_call | SUCCESS | 0.234s\n</code></pre>"},{"location":"advanced/request-tracking/#distributed-tracing","title":"Distributed Tracing","text":"<p>Pass request IDs between services:</p> <pre><code>import httpx\n\ndef call_downstream_service():\n    request_id = get_request_id()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            \"https://downstream-service.com/api\",\n            headers={\"X-Request-ID\": request_id}\n        )\n\n    return response.json()\n</code></pre>"},{"location":"advanced/runtime-reconfiguration/","title":"Runtime Reconfiguration","text":"<p>Change logging configuration without restarting your application.</p>"},{"location":"advanced/runtime-reconfiguration/#basic-reconfiguration","title":"Basic Reconfiguration","text":"<pre><code>from sherlock_ai import SherlockAI, LoggingConfig, LoggingPresets\n\n# Initial setup\nlogger_manager = SherlockAI()\nlogger_manager.setup()\n\n# Change to production configuration\nlogger_manager.reconfigure(LoggingPresets.production())\n\n# Change to debug mode\nlogger_manager.reconfigure(LoggingPresets.development())\n</code></pre>"},{"location":"advanced/runtime-reconfiguration/#custom-reconfiguration","title":"Custom Reconfiguration","text":"<pre><code>new_config = LoggingConfig(\n    console_level=\"DEBUG\",\n    logs_dir=\"new_logs_dir\",\n    log_files={\n        \"app\": LogFileConfig(\"app\", max_bytes=100*1024*1024)\n    }\n)\n\nlogger_manager.reconfigure(new_config)\n</code></pre>"},{"location":"advanced/runtime-reconfiguration/#dynamic-configuration","title":"Dynamic Configuration","text":"<pre><code>import os\n\ndef update_logging_level():\n    level = os.getenv(\"LOG_LEVEL\", \"INFO\")\n    config = LoggingConfig(console_level=level)\n    logger_manager.reconfigure(config)\n\n# Can be called anytime\nupdate_logging_level()\n</code></pre>"},{"location":"advanced/runtime-reconfiguration/#use-cases","title":"Use Cases","text":"<ul> <li>Switch between development and production modes</li> <li>Temporarily enable debug logging</li> <li>Change log file locations</li> <li>Adjust log levels based on load</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API documentation for Sherlock AI.</p>"},{"location":"api-reference/#core-functions","title":"Core Functions","text":""},{"location":"api-reference/#sherlock_ai","title":"sherlock_ai()","text":"<p>Initialize logging configuration.</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingConfig, LoggingPresets\n\n# Default configuration\nsherlock_ai()\n\n# With preset\nsherlock_ai(LoggingPresets.production())\n\n# With format type\nsherlock_ai(format_type=\"json\")\n\n# With custom config\nconfig = LoggingConfig(...)\nsherlock_ai(config)\n</code></pre>"},{"location":"api-reference/#get_logger","title":"get_logger()","text":"<p>Get a logger instance.</p> <pre><code>from sherlock_ai import get_logger, LoggerNames\n\nlogger = get_logger(__name__)\nlogger = get_logger(LoggerNames.API)\n</code></pre>"},{"location":"api-reference/#decorators","title":"Decorators","text":"<p>View Decorators Reference \u2192</p> <ul> <li><code>@log_performance</code> - Track execution times</li> <li><code>@monitor_memory</code> - Monitor memory usage</li> <li><code>@monitor_resources</code> - Monitor system resources</li> <li><code>@sherlock_error_handler</code> - AI-powered error analysis</li> <li><code>@hardcoded_value_detector</code> - Detect hardcoded values</li> <li><code>@sherlock_performance_insights</code> - Performance analysis</li> </ul>"},{"location":"api-reference/#classes","title":"Classes","text":"<p>View Classes Reference \u2192</p> <ul> <li><code>SherlockAI</code> - Main logging manager class</li> <li><code>CodeAnalyzer</code> - Code analysis utilities</li> <li><code>MongoManager</code> - MongoDB storage</li> <li><code>ApiClient</code> - HTTP client for data ingestion</li> <li><code>ResourceMonitor</code> - Resource monitoring utilities</li> </ul>"},{"location":"api-reference/#configuration","title":"Configuration","text":"<p>View Configuration Reference \u2192</p> <ul> <li><code>LoggingConfig</code> - Main configuration class</li> <li><code>LogFileConfig</code> - Log file configuration</li> <li><code>LoggerConfig</code> - Logger configuration</li> <li><code>LoggingPresets</code> - Pre-configured setups</li> </ul>"},{"location":"api-reference/#utilities","title":"Utilities","text":"<p>View Utilities Reference \u2192</p> <ul> <li><code>set_request_id()</code> - Set request ID</li> <li><code>get_request_id()</code> - Get current request ID</li> <li><code>list_available_loggers()</code> - List available loggers</li> <li><code>get_logging_stats()</code> - Get logging statistics</li> <li><code>get_current_config()</code> - Get current configuration</li> </ul>"},{"location":"api-reference/classes/","title":"Classes Reference","text":"<p>Complete reference for all Sherlock AI classes.</p>"},{"location":"api-reference/classes/#sherlockai","title":"SherlockAI","text":"<p>Advanced logging management class.</p> <p>Constructor: <pre><code>SherlockAI(config: Optional[LoggingConfig] = None)\n</code></pre></p> <p>Methods:</p>"},{"location":"api-reference/classes/#setupformat_typelog","title":"setup(format_type=\"log\")","text":"<p>Set up logging configuration. <pre><code>logger_manager = SherlockAI()\nlogger_manager.setup(\"json\")\n</code></pre></p>"},{"location":"api-reference/classes/#reconfigurenew_config","title":"reconfigure(new_config)","text":"<p>Change configuration without restart. <pre><code>logger_manager.reconfigure(new_config)\n</code></pre></p>"},{"location":"api-reference/classes/#cleanup","title":"cleanup()","text":"<p>Clean up handlers and resources. <pre><code>logger_manager.cleanup()\n</code></pre></p>"},{"location":"api-reference/classes/#get_stats","title":"get_stats()","text":"<p>Get current logging statistics. <pre><code>stats = logger_manager.get_stats()\n</code></pre></p>"},{"location":"api-reference/classes/#codeanalyzer","title":"CodeAnalyzer","text":"<p>Code analysis utilities.</p> <p>Constructor: <pre><code>CodeAnalyzer(api_key: Optional[str] = None, constants_file: str = \"constants.py\")\n</code></pre></p> <p>Methods:</p>"},{"location":"api-reference/classes/#detect_hardcoded_valuessource_code","title":"detect_hardcoded_values(source_code)","text":"<p>Detect hardcoded values in source code. <pre><code>values = analyzer.detect_hardcoded_values(source)\n</code></pre></p>"},{"location":"api-reference/classes/#suggest_constant_namevalue-value_type-context","title":"suggest_constant_name(value, value_type, context)","text":"<p>Suggest constant name for a value. <pre><code>name = analyzer.suggest_constant_name(\"https://api.com\", \"url\", \"fetch_data\")\n</code></pre></p>"},{"location":"api-reference/classes/#mongomanager","title":"MongoManager","text":"<p>MongoDB storage management.</p> <p>Constructor: <pre><code>MongoManager(mongo_uri: Optional[str] = None)\n</code></pre></p> <p>Methods:</p>"},{"location":"api-reference/classes/#savedata","title":"save(data)","text":"<p>Save data to MongoDB. <pre><code>mongo.save(error_data)\n</code></pre></p> <p>Properties:</p>"},{"location":"api-reference/classes/#enabled","title":"enabled","text":"<p>Check if MongoDB is configured. <pre><code>if mongo.enabled:\n    mongo.save(data)\n</code></pre></p>"},{"location":"api-reference/classes/#apiclient","title":"ApiClient","text":"<p>HTTP client for data ingestion.</p> <p>Constructor: <pre><code>ApiClient()  # Uses environment variables\n</code></pre></p> <p>Methods:</p>"},{"location":"api-reference/classes/#post_error_insightsdata","title":"post_error_insights(data)","text":"<p>Send error insights to backend. <pre><code>api_client.post_error_insights(error_data)\n</code></pre></p>"},{"location":"api-reference/classes/#post_performance_insightsdata","title":"post_performance_insights(data)","text":"<p>Send performance insights to backend. <pre><code>api_client.post_performance_insights(perf_data)\n</code></pre></p>"},{"location":"api-reference/classes/#resourcemonitor","title":"ResourceMonitor","text":"<p>Resource monitoring utilities.</p> <p>Static Methods:</p>"},{"location":"api-reference/classes/#capture_resources","title":"capture_resources()","text":"<p>Capture current resource snapshot. <pre><code>snapshot = ResourceMonitor.capture_resources()\n</code></pre></p>"},{"location":"api-reference/classes/#capture_memory","title":"capture_memory()","text":"<p>Capture memory snapshot. <pre><code>memory = ResourceMonitor.capture_memory()\n</code></pre></p>"},{"location":"api-reference/classes/#format_bytesbytes_val","title":"format_bytes(bytes_val)","text":"<p>Format bytes in human-readable format. <pre><code>formatted = ResourceMonitor.format_bytes(1024*1024*512)  # \"512.00MB\"\n</code></pre></p>"},{"location":"api-reference/configuration/","title":"Configuration Reference","text":"<p>Complete reference for configuration classes.</p>"},{"location":"api-reference/configuration/#loggingconfig","title":"LoggingConfig","text":"<p>Main configuration class.</p> <p>Parameters: - <code>logs_dir</code> (str, default=\"logs\"): Directory for log files - <code>log_format</code> (str): Log message format string - <code>date_format</code> (str, default=\"%Y-%m-%d %H:%M:%S\"): Date format - <code>console_enabled</code> (bool, default=True): Enable console output - <code>console_level</code> (str/int, default=INFO): Console log level - <code>root_level</code> (str/int, default=INFO): Root logger level - <code>log_format_type</code> (str, default=\"log\"): \"log\" or \"json\" - <code>log_files</code> (dict): Log file configurations - <code>loggers</code> (dict): Logger configurations - <code>external_loggers</code> (dict): External library log levels</p>"},{"location":"api-reference/configuration/#logfileconfig","title":"LogFileConfig","text":"<p>Log file configuration.</p> <p>Parameters: - <code>filename</code> (str, required): Base filename or full path - <code>level</code> (str/int, default=INFO): Log level - <code>max_bytes</code> (int, default=10MB): Max file size before rotation - <code>backup_count</code> (int, default=5): Number of backups to keep - <code>encoding</code> (str, default=\"utf-8\"): File encoding - <code>enabled</code> (bool, default=True): Whether file is enabled</p>"},{"location":"api-reference/configuration/#loggerconfig","title":"LoggerConfig","text":"<p>Logger configuration.</p> <p>Parameters: - <code>name</code> (str, required): Logger name - <code>level</code> (str/int, default=INFO): Logger level - <code>log_files</code> (list): List of log file names - <code>propagate</code> (bool, default=True): Propagate to parent - <code>enabled</code> (bool, default=True): Whether logger is enabled</p>"},{"location":"api-reference/configuration/#loggingpresets","title":"LoggingPresets","text":"<p>Pre-configured setups.</p> <p>Methods:</p>"},{"location":"api-reference/configuration/#development","title":"development()","text":"<p>Development environment preset. <pre><code>config = LoggingPresets.development()\n</code></pre></p>"},{"location":"api-reference/configuration/#production","title":"production()","text":"<p>Production environment preset. <pre><code>config = LoggingPresets.production()\n</code></pre></p>"},{"location":"api-reference/configuration/#minimal","title":"minimal()","text":"<p>Minimal setup preset. <pre><code>config = LoggingPresets.minimal()\n</code></pre></p>"},{"location":"api-reference/configuration/#performance_only","title":"performance_only()","text":"<p>Performance monitoring only. <pre><code>config = LoggingPresets.performance_only()\n</code></pre></p>"},{"location":"api-reference/configuration/#custom_filesfile_configs","title":"custom_files(file_configs)","text":"<p>Custom file names. <pre><code>config = LoggingPresets.custom_files({\n    \"app\": \"logs/application.log\",\n    \"errors\": \"logs/errors.log\"\n})\n</code></pre></p>"},{"location":"api-reference/decorators/","title":"Decorators Reference","text":"<p>Complete reference for all Sherlock AI decorators.</p>"},{"location":"api-reference/decorators/#log_performance","title":"@log_performance","text":"<p>Track execution times of functions.</p> <p>Parameters: - <code>min_duration</code> (float, default=0.0): Only log if execution time &gt;= this value in seconds - <code>include_args</code> (bool, default=False): Include function arguments in log - <code>log_level</code> (str, default=\"INFO\"): Log level to use</p> <p>Example: <pre><code>@log_performance(min_duration=0.1, include_args=True, log_level=\"DEBUG\")\ndef my_function(arg1, arg2):\n    pass\n</code></pre></p>"},{"location":"api-reference/decorators/#monitor_memory","title":"@monitor_memory","text":"<p>Monitor memory usage during function execution.</p> <p>Parameters: - <code>min_duration</code> (float, default=0.0): Only log if execution time &gt;= this value - <code>log_level</code> (str, default=\"INFO\"): Log level to use - <code>trace_malloc</code> (bool, default=True): Use tracemalloc for detailed tracking</p> <p>Example: <pre><code>@monitor_memory(trace_malloc=True, min_duration=0.1)\ndef memory_function():\n    pass\n</code></pre></p>"},{"location":"api-reference/decorators/#monitor_resources","title":"@monitor_resources","text":"<p>Monitor comprehensive system resources.</p> <p>Parameters: - <code>min_duration</code> (float, default=0.0): Only log if execution time &gt;= this value - <code>log_level</code> (str, default=\"INFO\"): Log level to use - <code>include_io</code> (bool, default=True): Include I/O statistics - <code>include_network</code> (bool, default=False): Include network statistics</p> <p>Example: <pre><code>@monitor_resources(include_io=True, include_network=True)\ndef resource_function():\n    pass\n</code></pre></p>"},{"location":"api-reference/decorators/#sherlock_error_handler","title":"@sherlock_error_handler","text":"<p>AI-powered error analysis with automatic storage.</p> <p>Parameters: None</p> <p>Example: <pre><code>@sherlock_error_handler\ndef risky_function():\n    pass\n</code></pre></p>"},{"location":"api-reference/decorators/#hardcoded_value_detector","title":"@hardcoded_value_detector","text":"<p>Detect and refactor hardcoded values.</p> <p>Parameters: - <code>analyzer</code> (CodeAnalyzer, optional): Custom analyzer instance</p> <p>Example: <pre><code>@hardcoded_value_detector\ndef my_function():\n    pass\n</code></pre></p>"},{"location":"api-reference/decorators/#sherlock_performance_insights","title":"@sherlock_performance_insights","text":"<p>AI-powered performance analysis.</p> <p>Parameters: None</p> <p>Example: <pre><code>@sherlock_performance_insights\ndef slow_function():\n    pass\n</code></pre></p>"},{"location":"api-reference/utilities/","title":"Utilities Reference","text":"<p>Complete reference for utility functions.</p>"},{"location":"api-reference/utilities/#request-id-functions","title":"Request ID Functions","text":""},{"location":"api-reference/utilities/#set_request_idrequest_idnone","title":"set_request_id(request_id=None)","text":"<p>Set request ID for current context.</p> <p>Parameters: - <code>request_id</code> (str, optional): Custom request ID. If None, generates one.</p> <p>Returns: str - The request ID that was set</p> <p>Example: <pre><code>from sherlock_ai import set_request_id\n\n# Auto-generate ID\nrequest_id = set_request_id()  # Returns: \"a1b2c3d4\"\n\n# Custom ID\nrequest_id = set_request_id(\"req-12345\")  # Returns: \"req-12345\"\n</code></pre></p>"},{"location":"api-reference/utilities/#get_request_id","title":"get_request_id()","text":"<p>Get current request ID.</p> <p>Returns: str - Current request ID or None</p> <p>Example: <pre><code>from sherlock_ai import get_request_id\n\ncurrent_id = get_request_id()\n</code></pre></p>"},{"location":"api-reference/utilities/#logger-functions","title":"Logger Functions","text":""},{"location":"api-reference/utilities/#list_available_loggers","title":"list_available_loggers()","text":"<p>List all available logger names.</p> <p>Returns: List[str] - List of logger names</p> <p>Example: <pre><code>from sherlock_ai import list_available_loggers\n\nloggers = list_available_loggers()\nprint(f\"Available: {loggers}\")\n</code></pre></p>"},{"location":"api-reference/utilities/#loggernames","title":"LoggerNames","text":"<p>Constants for available logger names.</p> <p>Attributes: - <code>LoggerNames.API</code> - API logger name - <code>LoggerNames.DATABASE</code> - Database logger name - <code>LoggerNames.SERVICES</code> - Services logger name - <code>LoggerNames.PERFORMANCE</code> - Performance logger name</p> <p>Example: <pre><code>from sherlock_ai import get_logger, LoggerNames\n\napi_logger = get_logger(LoggerNames.API)\ndb_logger = get_logger(LoggerNames.DATABASE)\n</code></pre></p>"},{"location":"api-reference/utilities/#introspection-functions","title":"Introspection Functions","text":""},{"location":"api-reference/utilities/#get_logging_stats","title":"get_logging_stats()","text":"<p>Get current logging statistics.</p> <p>Returns: Dict[str, Any] - Statistics dictionary</p> <p>Example: <pre><code>from sherlock_ai import get_logging_stats\n\nstats = get_logging_stats()\nprint(f\"Configured: {stats['is_configured']}\")\nprint(f\"Handlers: {stats['handlers']}\")\nprint(f\"Log directory: {stats['logs_dir']}\")\n</code></pre></p>"},{"location":"api-reference/utilities/#get_current_config","title":"get_current_config()","text":"<p>Get current logging configuration.</p> <p>Returns: Optional[LoggingConfig] - Current configuration</p> <p>Example: <pre><code>from sherlock_ai import get_current_config\n\nconfig = get_current_config()\nif config:\n    print(f\"Console enabled: {config.console_enabled}\")\n    print(f\"Log files: {list(config.log_files.keys())}\")\n</code></pre></p>"},{"location":"api-reference/utilities/#context-managers","title":"Context Managers","text":""},{"location":"api-reference/utilities/#performancetimer","title":"PerformanceTimer","text":"<p>Context manager for timing code blocks.</p> <p>Parameters: - <code>name</code> (str, required): Name for the operation - <code>min_duration</code> (float, default=0.0): Only log if &gt;= this value</p> <p>Example: <pre><code>from sherlock_ai.performance import PerformanceTimer\n\nwith PerformanceTimer(\"database_query\"):\n    result = db.query(\"SELECT * FROM users\")\n</code></pre></p>"},{"location":"api-reference/utilities/#memorytracker","title":"MemoryTracker","text":"<p>Context manager for tracking memory usage.</p> <p>Parameters: - <code>name</code> (str, required): Name for the operation - <code>min_duration</code> (float, default=0.0): Only log if &gt;= this value - <code>trace_malloc</code> (bool, default=True): Use tracemalloc</p> <p>Example: <pre><code>from sherlock_ai import MemoryTracker\n\nwith MemoryTracker(\"data_processing\"):\n    data = process_large_dataset()\n</code></pre></p>"},{"location":"api-reference/utilities/#resourcetracker","title":"ResourceTracker","text":"<p>Context manager for tracking system resources.</p> <p>Parameters: - <code>name</code> (str, required): Name for the operation - <code>min_duration</code> (float, default=0.0): Only log if &gt;= this value - <code>include_io</code> (bool, default=True): Include I/O stats - <code>include_network</code> (bool, default=False): Include network stats</p> <p>Example: <pre><code>from sherlock_ai import ResourceTracker\n\nwith ResourceTracker(\"api_call\", include_network=True):\n    response = requests.get(\"https://api.example.com\")\n</code></pre></p>"},{"location":"configuration/","title":"Configuration Overview","text":"<p>Sherlock AI provides flexible configuration options to customize logging behavior for your specific needs. From simple presets to advanced custom configurations, you have complete control over how monitoring and logging works in your application.</p>"},{"location":"configuration/#quick-configuration","title":"Quick Configuration","text":""},{"location":"configuration/#using-presets","title":"Using Presets","text":"<p>The easiest way to configure Sherlock AI:</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingPresets\n\n# Development environment\nsherlock_ai(LoggingPresets.development())\n\n# Production environment\nsherlock_ai(LoggingPresets.production())\n\n# Minimal setup\nsherlock_ai(LoggingPresets.minimal())\n</code></pre> <p>Learn more about presets \u2192</p>"},{"location":"configuration/#json-format","title":"JSON Format","text":"<p>Choose between standard logs and JSON format:</p> <pre><code>from sherlock_ai import sherlock_ai\n\n# Standard format (default) - creates .log files\nsherlock_ai()\n\n# JSON format - creates .json files\nsherlock_ai(format_type=\"json\")\n</code></pre> <p>Learn more about JSON logging \u2192</p>"},{"location":"configuration/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code>graph TD\n    DefaultConfig[Default Configuration] --&gt; Presets[Configuration Presets]\n    Presets --&gt; CustomConfig[Custom Configuration]\n    DefaultConfig --&gt; CustomConfig\n    CustomConfig --&gt; RuntimeReconfig[Runtime Reconfiguration]\n</code></pre>"},{"location":"configuration/#configuration-components","title":"Configuration Components","text":""},{"location":"configuration/#loggingconfig","title":"LoggingConfig","text":"<p>Main configuration class that controls all aspects of logging:</p> <pre><code>from sherlock_ai import LoggingConfig\n\nconfig = LoggingConfig(\n    logs_dir=\"logs\",              # Log directory\n    log_format_type=\"json\",       # \"log\" or \"json\"\n    console_enabled=True,         # Enable console output\n    console_level=\"INFO\",         # Console log level\n    log_files={...},              # Log file configurations\n    loggers={...}                 # Logger configurations\n)\n</code></pre> <p>Learn more \u2192</p>"},{"location":"configuration/#logfileconfig","title":"LogFileConfig","text":"<p>Configure individual log files:</p> <pre><code>from sherlock_ai import LogFileConfig\n\nlog_file = LogFileConfig(\n    filename=\"app\",               # Base filename\n    level=\"INFO\",                 # Log level\n    max_bytes=10*1024*1024,      # Max file size (10MB)\n    backup_count=5,              # Number of backups\n    enabled=True                 # Enable/disable file\n)\n</code></pre>"},{"location":"configuration/#loggerconfig","title":"LoggerConfig","text":"<p>Configure individual loggers:</p> <pre><code>from sherlock_ai import LoggerConfig\n\nlogger_config = LoggerConfig(\n    name=\"myapp.api\",            # Logger name\n    level=\"INFO\",                # Logger level\n    log_files=[\"app\", \"api\"],    # Files to write to\n    propagate=True,              # Propagate to parent\n    enabled=True                 # Enable/disable logger\n)\n</code></pre>"},{"location":"configuration/#configuration-methods","title":"Configuration Methods","text":""},{"location":"configuration/#function-based-api","title":"Function-Based API","text":"<p>Simple configuration for most use cases:</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingPresets\n\n# Default configuration\nsherlock_ai()\n\n# With preset\nsherlock_ai(LoggingPresets.production())\n\n# With format type\nsherlock_ai(format_type=\"json\")\n</code></pre>"},{"location":"configuration/#class-based-api","title":"Class-Based API","text":"<p>Advanced configuration with more control:</p> <pre><code>from sherlock_ai import SherlockAI, LoggingConfig\n\nconfig = LoggingConfig(...)\nlogger_manager = SherlockAI(config=config)\nlogger_manager.setup()\n\n# Later, reconfigure without restart\nnew_config = LoggingConfig(...)\nlogger_manager.reconfigure(new_config)\n</code></pre> <p>Learn more about class-based API \u2192</p>"},{"location":"configuration/#configuration-options","title":"Configuration Options","text":""},{"location":"configuration/#log-directory","title":"Log Directory","text":"<pre><code>config = LoggingConfig(\n    logs_dir=\"application_logs\"  # Custom directory\n)\n</code></pre>"},{"location":"configuration/#console-output","title":"Console Output","text":"<pre><code>config = LoggingConfig(\n    console_enabled=True,        # Enable console\n    console_level=\"DEBUG\"        # Console log level\n)\n</code></pre>"},{"location":"configuration/#file-rotation","title":"File Rotation","text":"<pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=100*1024*1024,  # 100MB\n            backup_count=10           # Keep 10 backups\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/#enabledisable-log-files","title":"Enable/Disable Log Files","text":"<pre><code>config = LoggingConfig()\nconfig.log_files[\"api\"].enabled = False      # Disable API logs\nconfig.log_files[\"services\"].enabled = False  # Disable services logs\n</code></pre> <p>Learn more about log management \u2192</p>"},{"location":"configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<p>Configure based on environment:</p> <pre><code>import os\nfrom sherlock_ai import sherlock_ai, LoggingPresets, LoggingConfig, LogFileConfig\n\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\n\nif env == \"production\":\n    sherlock_ai(LoggingPresets.production())\nelif env == \"development\":\n    sherlock_ai(LoggingPresets.development())\nelif env == \"testing\":\n    config = LoggingConfig(\n        logs_dir=\"test_logs\",\n        console_enabled=False,\n        log_files={\"test_results\": LogFileConfig(\"results\")}\n    )\n    sherlock_ai(config)\nelse:\n    sherlock_ai()  # Default\n</code></pre>"},{"location":"configuration/#default-log-files","title":"Default Log Files","text":"<p>When using default configuration, these log files are created:</p> File Purpose Logger Level <code>app.log</code> All application logs Root logger INFO+ <code>errors.log</code> Error logs only All loggers ERROR+ <code>api.log</code> API logs app.api INFO+ <code>database.log</code> Database logs app.core.dbConnection INFO+ <code>services.log</code> Service logs app.services INFO+ <code>performance.log</code> Performance monitoring PerformanceLogger INFO+"},{"location":"configuration/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"configuration/#1-use-presets-for-common-scenarios","title":"1. Use Presets for Common Scenarios","text":"<pre><code># Development\nsherlock_ai(LoggingPresets.development())\n\n# Production\nsherlock_ai(LoggingPresets.production())\n</code></pre>"},{"location":"configuration/#2-customize-only-what-you-need","title":"2. Customize Only What You Need","text":"<pre><code># Start with a preset, then customize\nconfig = LoggingPresets.production()\nconfig.console_level = \"WARNING\"\nconfig.log_files[\"app\"].max_bytes = 100*1024*1024\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/#3-use-environment-variables","title":"3. Use Environment Variables","text":"<pre><code>import os\n\nconfig = LoggingConfig(\n    logs_dir=os.getenv(\"LOG_DIR\", \"logs\"),\n    console_level=os.getenv(\"LOG_LEVEL\", \"INFO\")\n)\n</code></pre>"},{"location":"configuration/#4-disable-unused-log-files","title":"4. Disable Unused Log Files","text":"<pre><code>config = LoggingConfig()\nconfig.log_files[\"services\"].enabled = False\nconfig.log_files[\"database\"].enabled = False\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/#configuration-sections","title":"Configuration Sections","text":"<p>Explore each configuration topic in detail:</p> <ul> <li>Configuration Presets - Ready-made configurations for common scenarios</li> <li>Custom Configuration - Build your own configuration</li> <li>JSON Logging - Structured logging with JSON format</li> <li>Log Management - File rotation, sizing, and management</li> </ul>"},{"location":"configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Get started with basic configuration</li> <li>API Reference - Complete configuration API</li> <li>Advanced - Runtime reconfiguration</li> <li>Examples - Configuration examples</li> </ul>"},{"location":"configuration/custom-config/","title":"Custom Configuration","text":"<p>Build completely custom logging configurations tailored to your application's specific needs. This guide covers all configuration options and how to create sophisticated logging setups.</p>"},{"location":"configuration/custom-config/#basic-custom-configuration","title":"Basic Custom Configuration","text":"<pre><code>from sherlock_ai import sherlock_ai, LoggingConfig, LogFileConfig, LoggerConfig\n\nconfig = LoggingConfig(\n    logs_dir=\"my_app_logs\",\n    console_level=\"INFO\",\n    log_files={\n        \"app\": LogFileConfig(\"application\"),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\")\n    }\n)\n\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/custom-config/#complete-custom-configuration","title":"Complete Custom Configuration","text":"<pre><code>from sherlock_ai import LoggingConfig, LogFileConfig, LoggerConfig, sherlock_ai\n\nconfig = LoggingConfig(\n    # Directory configuration\n    logs_dir=\"application_logs\",\n\n    # Format configuration\n    log_format=\"%(asctime)s - %(request_id)s - %(name)s - %(levelname)s - %(message)s\",\n    date_format=\"%Y-%m-%d %H:%M:%S\",\n\n    # Console configuration\n    console_enabled=True,\n    console_level=\"DEBUG\",\n\n    # Root logger level\n    root_level=\"INFO\",\n\n    # Log files\n    log_files={\n        \"application\": LogFileConfig(\n            \"app\",\n            level=\"INFO\",\n            max_bytes=50*1024*1024,  # 50MB\n            backup_count=10,\n            encoding=\"utf-8\",\n            enabled=True\n        ),\n        \"errors\": LogFileConfig(\n            \"errors\",\n            level=\"ERROR\",\n            max_bytes=25*1024*1024,  # 25MB\n            backup_count=15\n        ),\n        \"performance\": LogFileConfig(\n            \"perf\",\n            level=\"INFO\",\n            max_bytes=100*1024*1024,  # 100MB\n            backup_count=5\n        ),\n        \"api\": LogFileConfig(\"api_requests\"),\n        \"database\": LogFileConfig(\"db_operations\")\n    },\n\n    # Loggers\n    loggers={\n        \"api\": LoggerConfig(\n            \"mycompany.api\",\n            level=\"INFO\",\n            log_files=[\"application\", \"api\"],\n            propagate=True,\n            enabled=True\n        ),\n        \"database\": LoggerConfig(\n            \"mycompany.db\",\n            level=\"INFO\",\n            log_files=[\"application\", \"database\"]\n        ),\n        \"performance\": LoggerConfig(\n            \"PerformanceLogger\",\n            level=\"INFO\",\n            log_files=[\"performance\"],\n            propagate=False\n        )\n    },\n\n    # External loggers\n    external_loggers={\n        \"uvicorn\": \"INFO\",\n        \"sqlalchemy.engine\": \"WARNING\"\n    }\n)\n\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/custom-config/#configuration-components","title":"Configuration Components","text":""},{"location":"configuration/custom-config/#loggingconfig-parameters","title":"LoggingConfig Parameters","text":"Parameter Type Default Description <code>logs_dir</code> str \"logs\" Directory for log files <code>log_format</code> str Standard format Log message format string <code>date_format</code> str \"%Y-%m-%d %H:%M:%S\" Date format for timestamps <code>console_enabled</code> bool True Enable console output <code>console_level</code> str/int INFO Console log level <code>root_level</code> str/int INFO Root logger level <code>log_files</code> dict Default files Log file configurations <code>loggers</code> dict Default loggers Logger configurations <code>external_loggers</code> dict {} External library log levels"},{"location":"configuration/custom-config/#logfileconfig-parameters","title":"LogFileConfig Parameters","text":"Parameter Type Default Description <code>filename</code> str Required Base filename or full path <code>level</code> str/int INFO Log level for this file <code>max_bytes</code> int 10MB Maximum file size before rotation <code>backup_count</code> int 5 Number of backup files to keep <code>encoding</code> str \"utf-8\" File encoding <code>enabled</code> bool True Whether this file is enabled"},{"location":"configuration/custom-config/#loggerconfig-parameters","title":"LoggerConfig Parameters","text":"Parameter Type Default Description <code>name</code> str Required Logger name <code>level</code> str/int INFO Logger level <code>log_files</code> list [] List of log file names <code>propagate</code> bool True Propagate to parent loggers <code>enabled</code> bool True Whether this logger is enabled"},{"location":"configuration/custom-config/#simplified-vs-full-path-configuration","title":"Simplified vs Full Path Configuration","text":""},{"location":"configuration/custom-config/#simplified-recommended","title":"Simplified (Recommended)","text":"<p>Automatic path expansion - just specify base names:</p> <pre><code>config = LoggingConfig(\n    logs_dir=\"logs\",\n    log_format_type=\"json\",\n    log_files={\n        \"app\": LogFileConfig(\"application\"),      # \u2192 logs/application.json\n        \"errors\": LogFileConfig(\"error_log\"),     # \u2192 logs/error_log.json\n        \"api\": LogFileConfig(\"api_requests\"),     # \u2192 logs/api_requests.json\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#full-paths","title":"Full Paths","text":"<p>Specify complete file paths:</p> <pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"logs/custom/app.log\"),\n        \"errors\": LogFileConfig(\"/var/log/myapp/errors.log\")\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#real-world-examples","title":"Real-World Examples","text":""},{"location":"configuration/custom-config/#microservice-configuration","title":"Microservice Configuration","text":"<pre><code>from sherlock_ai import LoggingConfig, LogFileConfig, LoggerConfig, sherlock_ai\n\nconfig = LoggingConfig(\n    logs_dir=\"service_logs\",\n    log_format_type=\"json\",  # JSON for log aggregation\n    console_level=\"INFO\",\n    log_files={\n        \"app\": LogFileConfig(\"application\", max_bytes=100*1024*1024),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\", backup_count=20),\n        \"api\": LogFileConfig(\"api_requests\", backup_count=15),\n        \"performance\": LogFileConfig(\"performance_metrics\"),\n    },\n    loggers={\n        \"api\": LoggerConfig(\"service.api\", log_files=[\"app\", \"api\"]),\n        \"business\": LoggerConfig(\"service.business\", log_files=[\"app\"]),\n        \"performance\": LoggerConfig(\"PerformanceLogger\", log_files=[\"performance\"])\n    },\n    external_loggers={\n        \"uvicorn\": \"WARNING\",\n        \"httpx\": \"WARNING\"\n    }\n)\n\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/custom-config/#data-pipeline-configuration","title":"Data Pipeline Configuration","text":"<pre><code>config = LoggingConfig(\n    logs_dir=\"pipeline_logs\",\n    console_level=\"INFO\",\n    log_files={\n        \"pipeline\": LogFileConfig(\"pipeline\", max_bytes=200*1024*1024),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\"),\n        \"data_quality\": LogFileConfig(\"quality_checks\"),\n        \"performance\": LogFileConfig(\"performance\")\n    },\n    loggers={\n        \"ingestion\": LoggerConfig(\"pipeline.ingestion\", log_files=[\"pipeline\"]),\n        \"transform\": LoggerConfig(\"pipeline.transform\", log_files=[\"pipeline\"]),\n        \"quality\": LoggerConfig(\"pipeline.quality\", log_files=[\"data_quality\"])\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#web-application-configuration","title":"Web Application Configuration","text":"<pre><code>config = LoggingConfig(\n    logs_dir=\"webapp_logs\",\n    log_format_type=\"json\",\n    console_level=\"INFO\",\n    log_files={\n        \"app\": LogFileConfig(\"application\", max_bytes=50*1024*1024),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\"),\n        \"api\": LogFileConfig(\"api_requests\"),\n        \"security\": LogFileConfig(\"security_events\"),\n        \"performance\": LogFileConfig(\"performance\")\n    },\n    loggers={\n        \"api\": LoggerConfig(\"webapp.api\", log_files=[\"app\", \"api\"]),\n        \"auth\": LoggerConfig(\"webapp.auth\", log_files=[\"app\", \"security\"]),\n        \"db\": LoggerConfig(\"webapp.database\", log_files=[\"app\"])\n    },\n    external_loggers={\n        \"uvicorn\": \"INFO\",\n        \"sqlalchemy.engine\": \"WARNING\"\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"configuration/custom-config/#separate-error-logging","title":"Separate Error Logging","text":"<p>Log errors to multiple destinations:</p> <pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"app\", level=\"INFO\"),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\"),\n        \"critical\": LogFileConfig(\"critical\", level=\"CRITICAL\")\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#performance-only-logger","title":"Performance-Only Logger","text":"<p>Isolate performance logs:</p> <pre><code>config = LoggingConfig(\n    loggers={\n        \"performance\": LoggerConfig(\n            \"PerformanceLogger\",\n            log_files=[\"performance\"],\n            propagate=False  # Don't send to root logger\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#conditional-configuration","title":"Conditional Configuration","text":"<p>Configure based on conditions:</p> <pre><code>import os\n\nis_production = os.getenv(\"ENV\") == \"production\"\n\nconfig = LoggingConfig(\n    console_enabled=not is_production,\n    console_level=\"WARNING\" if is_production else \"DEBUG\",\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=100*1024*1024 if is_production else 10*1024*1024,\n            backup_count=20 if is_production else 5\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#configuration-validation","title":"Configuration Validation","text":"<p>Sherlock AI validates your configuration:</p> <pre><code>from sherlock_ai import LoggingConfig, LogFileConfig\n\n# This will raise validation errors\ntry:\n    config = LoggingConfig(\n        log_files={\n            \"app\": LogFileConfig(\n                \"app\",\n                max_bytes=-1,  # \u274c Invalid: must be positive\n                backup_count=0  # \u274c Warning: no backups\n            )\n        }\n    )\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n</code></pre>"},{"location":"configuration/custom-config/#best-practices","title":"Best Practices","text":""},{"location":"configuration/custom-config/#1-start-simple","title":"1. Start Simple","text":"<p>Begin with basic configuration and add complexity as needed:</p> <pre><code># Start simple\nconfig = LoggingConfig(\n    logs_dir=\"logs\",\n    log_files={\"app\": LogFileConfig(\"app\")}\n)\n\n# Add more as needed\nconfig.log_files[\"errors\"] = LogFileConfig(\"errors\", level=\"ERROR\")\nconfig.log_files[\"api\"] = LogFileConfig(\"api\")\n</code></pre>"},{"location":"configuration/custom-config/#2-use-meaningful-names","title":"2. Use Meaningful Names","text":"<p>Choose descriptive file and logger names:</p> <pre><code># \u2705 Good\nconfig = LoggingConfig(\n    log_files={\n        \"application\": LogFileConfig(\"app\"),\n        \"user_activities\": LogFileConfig(\"user_activity\"),\n        \"security_events\": LogFileConfig(\"security\")\n    }\n)\n\n# \u274c Avoid\nconfig = LoggingConfig(\n    log_files={\n        \"log1\": LogFileConfig(\"l1\"),\n        \"log2\": LogFileConfig(\"l2\")\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#3-plan-file-sizes","title":"3. Plan File Sizes","text":"<p>Consider your logging volume:</p> <pre><code># High-traffic application\nconfig = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=100*1024*1024,  # 100MB\n            backup_count=20            # 2GB total\n        )\n    }\n)\n\n# Low-traffic application\nconfig = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=10*1024*1024,   # 10MB\n            backup_count=5             # 50MB total\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#4-external-logger-management","title":"4. External Logger Management","text":"<p>Control third-party library logging:</p> <pre><code>config = LoggingConfig(\n    external_loggers={\n        \"uvicorn\": \"INFO\",           # Keep uvicorn logs\n        \"httpx\": \"WARNING\",          # Reduce httpx verbosity\n        \"sqlalchemy.engine\": \"ERROR\", # Only SQL errors\n        \"boto3\": \"CRITICAL\"          # Silence AWS SDK\n    }\n)\n</code></pre>"},{"location":"configuration/custom-config/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Presets - Start with presets</li> <li>JSON Logging - Use JSON format</li> <li>Log Management - Manage files and rotation</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"configuration/json-logging/","title":"JSON Logging","text":"<p>Sherlock AI supports structured JSON logging for better log parsing, analysis, and integration with log aggregation systems. JSON format makes it easy to query, filter, and analyze logs programmatically.</p>"},{"location":"configuration/json-logging/#enabling-json-format","title":"Enabling JSON Format","text":""},{"location":"configuration/json-logging/#function-based-api","title":"Function-Based API","text":"<pre><code>from sherlock_ai import sherlock_ai\n\n# Enable JSON format (creates .json files)\nsherlock_ai(format_type=\"json\")\n</code></pre>"},{"location":"configuration/json-logging/#class-based-api","title":"Class-Based API","text":"<pre><code>from sherlock_ai import SherlockAI\n\nlogger_manager = SherlockAI()\nlogger_manager.setup(\"json\")  # Creates app.json, errors.json, etc.\n</code></pre>"},{"location":"configuration/json-logging/#configuration-object","title":"Configuration Object","text":"<pre><code>from sherlock_ai import LoggingConfig, sherlock_ai\n\nconfig = LoggingConfig(\n    log_format_type=\"json\",  # or \"log\" for standard format\n    logs_dir=\"json_logs\"\n)\n\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/json-logging/#log-output-comparison","title":"Log Output Comparison","text":""},{"location":"configuration/json-logging/#standard-format","title":"Standard Format","text":"<pre><code>2025-07-15 20:51:19 - aa580b62 - ApiLogger - INFO - Request started\n2025-07-15 20:51:19 - aa580b62 - PerformanceLogger - INFO - PERFORMANCE | myapp.api_call | SUCCESS | 0.234s\n</code></pre>"},{"location":"configuration/json-logging/#json-format","title":"JSON Format","text":"<pre><code>{\"timestamp\": \"2025-07-15 20:51:19\", \"level\": \"INFO\", \"logger\": \"ApiLogger\", \"message\": \"Request started\", \"request_id\": \"aa580b62\", \"module\": \"myapp\", \"function\": \"api_call\", \"line\": 42, \"thread\": 13672, \"thread_name\": \"MainThread\", \"process\": 22008}\n\n{\"timestamp\": \"2025-07-15 20:51:19\", \"level\": \"INFO\", \"logger\": \"PerformanceLogger\", \"message\": \"PERFORMANCE | myapp.api_call | SUCCESS | 0.234s\", \"request_id\": \"aa580b62\", \"module\": \"performance\", \"function\": \"log_performance\", \"line\": 89, \"thread\": 13672, \"thread_name\": \"MainThread\", \"process\": 22008}\n</code></pre>"},{"location":"configuration/json-logging/#json-log-structure","title":"JSON Log Structure","text":"<p>Each JSON log entry contains:</p> <pre><code>{\n  \"timestamp\": \"2025-07-15 20:51:19\",\n  \"level\": \"INFO\",\n  \"logger\": \"ApiLogger\",\n  \"message\": \"Request started\",\n  \"request_id\": \"aa580b62\",\n  \"module\": \"myapp\",\n  \"function\": \"api_call\",\n  \"line\": 42,\n  \"thread\": 13672,\n  \"thread_name\": \"MainThread\",\n  \"process\": 22008\n}\n</code></pre>"},{"location":"configuration/json-logging/#fields","title":"Fields","text":"Field Type Description <code>timestamp</code> string ISO format timestamp <code>level</code> string Log level (INFO, DEBUG, WARNING, ERROR, CRITICAL) <code>logger</code> string Logger name <code>message</code> string Log message content <code>request_id</code> string Request ID (if set) <code>module</code> string Module name where log originated <code>function</code> string Function name where log originated <code>line</code> integer Line number in source file <code>thread</code> integer Thread ID <code>thread_name</code> string Thread name <code>process</code> integer Process ID"},{"location":"configuration/json-logging/#reading-json-logs","title":"Reading JSON Logs","text":""},{"location":"configuration/json-logging/#python","title":"Python","text":"<pre><code>import json\n\ndef load_json_logs(filename):\n    logs = []\n    with open(filename, 'r') as f:\n        for line in f:\n            if line.strip():\n                logs.append(json.loads(line.strip()))\n    return logs\n\n# Usage\nlogs = load_json_logs('logs/api.json')\nfor log in logs:\n    print(f\"[{log['timestamp']}] {log['level']}: {log['message']}\")\n</code></pre>"},{"location":"configuration/json-logging/#filtering-logs","title":"Filtering Logs","text":"<pre><code># Filter by level\nerrors = [log for log in logs if log['level'] == 'ERROR']\n\n# Filter by request_id\nrequest_logs = [log for log in logs if log['request_id'] == 'aa580b62']\n\n# Filter by time range\nfrom datetime import datetime\nstart_time = datetime(2025, 7, 15, 20, 0, 0)\ntime_filtered = [\n    log for log in logs \n    if datetime.strptime(log['timestamp'], '%Y-%m-%d %H:%M:%S') &gt;= start_time\n]\n</code></pre>"},{"location":"configuration/json-logging/#aggregation","title":"Aggregation","text":"<pre><code>from collections import Counter\n\n# Count logs by level\nlevel_counts = Counter(log['level'] for log in logs)\nprint(f\"Errors: {level_counts['ERROR']}\")\nprint(f\"Warnings: {level_counts['WARNING']}\")\n\n# Count logs by logger\nlogger_counts = Counter(log['logger'] for log in logs)\nfor logger, count in logger_counts.most_common():\n    print(f\"{logger}: {count}\")\n</code></pre>"},{"location":"configuration/json-logging/#integration-with-log-aggregation","title":"Integration with Log Aggregation","text":""},{"location":"configuration/json-logging/#elasticsearch","title":"Elasticsearch","text":"<pre><code>from elasticsearch import Elasticsearch\nimport json\n\nes = Elasticsearch(['localhost:9200'])\n\n# Index logs\nwith open('logs/app.json', 'r') as f:\n    for line in f:\n        if line.strip():\n            log = json.loads(line)\n            es.index(index='sherlock-logs', document=log)\n</code></pre>"},{"location":"configuration/json-logging/#splunk","title":"Splunk","text":"<pre><code>import requests\nimport json\n\nSPLUNK_URL = \"http://localhost:8088/services/collector\"\nSPLUNK_TOKEN = \"your-hec-token\"\n\nwith open('logs/app.json', 'r') as f:\n    for line in f:\n        if line.strip():\n            log = json.loads(line)\n            requests.post(\n                SPLUNK_URL,\n                headers={\"Authorization\": f\"Splunk {SPLUNK_TOKEN}\"},\n                json={\"event\": log}\n            )\n</code></pre>"},{"location":"configuration/json-logging/#cloudwatch-logs","title":"CloudWatch Logs","text":"<pre><code>import boto3\nimport json\nimport time\n\nlogs_client = boto3.client('logs')\nlog_group = '/aws/sherlock-ai'\nlog_stream = 'application'\n\nwith open('logs/app.json', 'r') as f:\n    log_events = []\n    for line in f:\n        if line.strip():\n            log = json.loads(line)\n            log_events.append({\n                'timestamp': int(time.time() * 1000),\n                'message': json.dumps(log)\n            })\n\n    logs_client.put_log_events(\n        logGroupName=log_group,\n        logStreamName=log_stream,\n        logEvents=log_events\n    )\n</code></pre>"},{"location":"configuration/json-logging/#json-with-monitoring","title":"JSON with Monitoring","text":""},{"location":"configuration/json-logging/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>{\n  \"timestamp\": \"2025-07-15 20:51:19\",\n  \"level\": \"INFO\",\n  \"logger\": \"PerformanceLogger\",\n  \"message\": \"PERFORMANCE | myapp.api_call | SUCCESS | 0.234s\",\n  \"request_id\": \"aa580b62\",\n  \"module\": \"performance\",\n  \"function\": \"log_performance\",\n  \"line\": 89\n}\n</code></pre>"},{"location":"configuration/json-logging/#memory-monitoring","title":"Memory Monitoring","text":"<pre><code>{\n  \"timestamp\": \"2025-07-15 20:51:19\",\n  \"level\": \"INFO\",\n  \"logger\": \"MonitoringLogger\",\n  \"message\": \"MEMORY | myapp.process_data | SUCCESS | 0.245s | Current: 45.67MB | Change: +12.34MB | Traced: 38.92MB (Peak: 52.18MB)\",\n  \"request_id\": \"aa580b62\",\n  \"module\": \"monitoring\",\n  \"function\": \"monitor_memory\"\n}\n</code></pre>"},{"location":"configuration/json-logging/#resource-monitoring","title":"Resource Monitoring","text":"<pre><code>{\n  \"timestamp\": \"2025-07-15 20:51:19\",\n  \"level\": \"INFO\",\n  \"logger\": \"MonitoringLogger\",\n  \"message\": \"RESOURCES | myapp.api_handler | SUCCESS | 0.156s | CPU: 25.4% | Memory: 128.45MB (+5.23MB) | Threads: 12 | I/O: R:2.34MB W:1.12MB\",\n  \"request_id\": \"aa580b62\",\n  \"module\": \"monitoring\",\n  \"function\": \"monitor_resources\"\n}\n</code></pre>"},{"location":"configuration/json-logging/#configuration-examples","title":"Configuration Examples","text":""},{"location":"configuration/json-logging/#production-with-json","title":"Production with JSON","text":"<pre><code>from sherlock_ai import LoggingConfig, LogFileConfig, sherlock_ai\n\nconfig = LoggingConfig(\n    logs_dir=\"production_logs\",\n    log_format_type=\"json\",  # JSON format\n    console_level=\"INFO\",\n    log_files={\n        \"app\": LogFileConfig(\"application\", max_bytes=100*1024*1024),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\", backup_count=20),\n        \"performance\": LogFileConfig(\"performance\", backup_count=15)\n    }\n)\n\nsherlock_ai(config)\n\n# Creates:\n# production_logs/application.json\n# production_logs/errors.json\n# production_logs/performance.json\n</code></pre>"},{"location":"configuration/json-logging/#development-with-json","title":"Development with JSON","text":"<pre><code>from sherlock_ai import LoggingPresets, sherlock_ai\n\n# Use development preset with JSON format\nconfig = LoggingPresets.development()\nconfig.log_format_type = \"json\"\n\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/json-logging/#parsing-performance-logs","title":"Parsing Performance Logs","text":"<p>Extract performance metrics from JSON logs:</p> <pre><code>import json\nimport statistics\n\ndef analyze_performance(log_file):\n    durations = []\n    errors = 0\n\n    with open(log_file, 'r') as f:\n        for line in f:\n            if line.strip():\n                log = json.loads(line)\n                if log['logger'] == 'PerformanceLogger':\n                    # Extract duration from message\n                    # Format: \"PERFORMANCE | function | STATUS | 0.234s\"\n                    parts = log['message'].split('|')\n                    status = parts[2].strip()\n                    duration_str = parts[3].strip().rstrip('s')\n                    duration = float(duration_str)\n\n                    durations.append(duration)\n                    if status == 'ERROR':\n                        errors += 1\n\n    return {\n        'count': len(durations),\n        'errors': errors,\n        'avg': statistics.mean(durations) if durations else 0,\n        'median': statistics.median(durations) if durations else 0,\n        'min': min(durations) if durations else 0,\n        'max': max(durations) if durations else 0\n    }\n\n# Usage\nstats = analyze_performance('logs/performance.json')\nprint(f\"Total requests: {stats['count']}\")\nprint(f\"Errors: {stats['errors']}\")\nprint(f\"Average duration: {stats['avg']:.3f}s\")\nprint(f\"Median duration: {stats['median']:.3f}s\")\n</code></pre>"},{"location":"configuration/json-logging/#best-practices","title":"Best Practices","text":""},{"location":"configuration/json-logging/#1-use-json-for-production","title":"1. Use JSON for Production","text":"<p>JSON is ideal for production environments:</p> <pre><code>import os\n\nif os.getenv(\"ENV\") == \"production\":\n    config = LoggingConfig(log_format_type=\"json\")\nelse:\n    config = LoggingConfig(log_format_type=\"log\")\n</code></pre>"},{"location":"configuration/json-logging/#2-structured-log-aggregation","title":"2. Structured Log Aggregation","text":"<p>Use JSON with log aggregation tools:</p> <pre><code># Optimized for Elasticsearch, Splunk, etc.\nconfig = LoggingConfig(\n    log_format_type=\"json\",\n    logs_dir=\"/var/log/myapp\"\n)\n</code></pre>"},{"location":"configuration/json-logging/#3-performance-analysis","title":"3. Performance Analysis","text":"<p>Parse JSON logs for performance insights:</p> <pre><code># Easy to parse and analyze\nlogs = load_json_logs('logs/performance.json')\nslow_requests = [log for log in logs if '| SUCCESS |' in log['message'] and float(log['message'].split('|')[-1].strip().rstrip('s')) &gt; 1.0]\n</code></pre>"},{"location":"configuration/json-logging/#4-request-tracing","title":"4. Request Tracing","text":"<p>Use request_id for distributed tracing:</p> <pre><code># Filter by request ID\ndef get_request_trace(logs, request_id):\n    return [log for log in logs if log.get('request_id') == request_id]\n\ntrace = get_request_trace(logs, 'aa580b62')\nfor log in trace:\n    print(f\"{log['timestamp']} - {log['logger']} - {log['message']}\")\n</code></pre>"},{"location":"configuration/json-logging/#advantages-of-json-format","title":"Advantages of JSON Format","text":"<ol> <li>Machine Readable: Easy to parse programmatically</li> <li>Structured Data: Consistent field structure</li> <li>Query-Friendly: Simple to filter and aggregate</li> <li>Integration: Works with log aggregation tools</li> <li>Analysis: Statistical analysis is straightforward</li> <li>Debugging: Quick filtering by request ID or other fields</li> </ol>"},{"location":"configuration/json-logging/#next-steps","title":"Next Steps","text":"<ul> <li>Log Management - Manage JSON log files</li> <li>Examples - See JSON logging in action</li> <li>Advanced - Query logging configuration</li> <li>API Reference - Configuration API</li> </ul>"},{"location":"configuration/log-management/","title":"Log Management","text":"<p>Manage log files, rotation, sizing, and cleanup with Sherlock AI's flexible log management features.</p>"},{"location":"configuration/log-management/#file-rotation","title":"File Rotation","text":""},{"location":"configuration/log-management/#automatic-rotation","title":"Automatic Rotation","text":"<p>Log files automatically rotate when they reach the configured size:</p> <pre><code>from sherlock_ai import LoggingConfig, LogFileConfig, sherlock_ai\n\nconfig = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=10*1024*1024,  # Rotate at 10MB\n            backup_count=5            # Keep 5 backup files\n        )\n    }\n)\n\nsherlock_ai(config)\n</code></pre> <p>Result: <pre><code>logs/\n\u251c\u2500\u2500 app.log          # Current log file\n\u251c\u2500\u2500 app.log.1        # Most recent backup\n\u251c\u2500\u2500 app.log.2\n\u251c\u2500\u2500 app.log.3\n\u251c\u2500\u2500 app.log.4\n\u2514\u2500\u2500 app.log.5        # Oldest backup (will be deleted on next rotation)\n</code></pre></p>"},{"location":"configuration/log-management/#custom-rotation-settings","title":"Custom Rotation Settings","text":"<p>Different rotation settings for different log files:</p> <pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=50*1024*1024,   # 50MB\n            backup_count=10\n        ),\n        \"errors\": LogFileConfig(\n            \"errors\",\n            level=\"ERROR\",\n            max_bytes=25*1024*1024,   # 25MB (errors are typically smaller)\n            backup_count=20           # Keep more error history\n        ),\n        \"performance\": LogFileConfig(\n            \"performance\",\n            max_bytes=100*1024*1024,  # 100MB (lots of performance data)\n            backup_count=5\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#enabledisable-log-files","title":"Enable/Disable Log Files","text":""},{"location":"configuration/log-management/#at-initialization","title":"At Initialization","text":"<pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"app\", enabled=True),\n        \"api\": LogFileConfig(\"api\", enabled=False),      # Disabled\n        \"services\": LogFileConfig(\"services\", enabled=False)  # Disabled\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#runtime-configuration","title":"Runtime Configuration","text":"<pre><code>from sherlock_ai import LoggingConfig, sherlock_ai\n\n# Start with default configuration\nconfig = LoggingConfig()\n\n# Disable specific log files\nconfig.log_files[\"api\"].enabled = False\nconfig.log_files[\"services\"].enabled = False\n\n# Enable errors with higher retention\nconfig.log_files[\"errors\"].enabled = True\nconfig.log_files[\"errors\"].backup_count = 15\n\n# Apply the modified configuration\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/log-management/#log-levels","title":"Log Levels","text":""},{"location":"configuration/log-management/#per-file-log-levels","title":"Per-File Log Levels","text":"<pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"app\", level=\"INFO\"),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\"),  # Only errors\n        \"debug\": LogFileConfig(\"debug\", level=\"DEBUG\"),    # Everything\n        \"performance\": LogFileConfig(\"performance\", level=\"INFO\")\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#console-vs-file-levels","title":"Console vs File Levels","text":"<pre><code>config = LoggingConfig(\n    console_level=\"WARNING\",  # Only warnings and errors to console\n    log_files={\n        \"app\": LogFileConfig(\"app\", level=\"INFO\")  # All info+ to file\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#custom-log-directories","title":"Custom Log Directories","text":""},{"location":"configuration/log-management/#single-directory","title":"Single Directory","text":"<pre><code>config = LoggingConfig(\n    logs_dir=\"application_logs\",\n    log_files={\n        \"app\": LogFileConfig(\"app\"),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\")\n    }\n)\n# Creates: application_logs/app.log, application_logs/errors.log\n</code></pre>"},{"location":"configuration/log-management/#multiple-directories","title":"Multiple Directories","text":"<pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"logs/app.log\"),\n        \"errors\": LogFileConfig(\"errors/critical.log\"),\n        \"api\": LogFileConfig(\"/var/log/myapp/api.log\")  # Absolute path\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#disk-space-management","title":"Disk Space Management","text":""},{"location":"configuration/log-management/#calculate-log-space-usage","title":"Calculate Log Space Usage","text":"<pre><code>import os\n\ndef get_log_directory_size(logs_dir=\"logs\"):\n    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(logs_dir):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            total_size += os.path.getsize(filepath)\n    return total_size\n\n# Get size in MB\nsize_mb = get_log_directory_size() / (1024 * 1024)\nprint(f\"Log directory size: {size_mb:.2f}MB\")\n</code></pre>"},{"location":"configuration/log-management/#plan-storage-requirements","title":"Plan Storage Requirements","text":"<pre><code># Calculate maximum disk usage\ndef calculate_max_log_usage(config):\n    total_size = 0\n    for log_file in config.log_files.values():\n        if log_file.enabled:\n            # Current file + all backups\n            max_size = log_file.max_bytes * (log_file.backup_count + 1)\n            total_size += max_size\n    return total_size\n\n# Example\nconfig = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"app\", max_bytes=50*1024*1024, backup_count=10),\n        \"errors\": LogFileConfig(\"errors\", max_bytes=25*1024*1024, backup_count=20)\n    }\n)\n\nmax_usage = calculate_max_log_usage(config)\nprint(f\"Maximum disk usage: {max_usage / (1024*1024):.2f}MB\")\n# Output: Maximum disk usage: 1075.00MB (50MB * 11 + 25MB * 21)\n</code></pre>"},{"location":"configuration/log-management/#log-file-cleanup","title":"Log File Cleanup","text":""},{"location":"configuration/log-management/#manual-cleanup","title":"Manual Cleanup","text":"<pre><code>import os\nimport glob\nfrom datetime import datetime, timedelta\n\ndef cleanup_old_logs(logs_dir=\"logs\", days_old=30):\n    \"\"\"Delete log files older than specified days.\"\"\"\n    cutoff = datetime.now() - timedelta(days=days_old)\n\n    for log_file in glob.glob(f\"{logs_dir}/*.log*\"):\n        file_time = datetime.fromtimestamp(os.path.getmtime(log_file))\n        if file_time &lt; cutoff:\n            os.remove(log_file)\n            print(f\"Deleted: {log_file}\")\n\n# Clean up logs older than 30 days\ncleanup_old_logs(days_old=30)\n</code></pre>"},{"location":"configuration/log-management/#archive-old-logs","title":"Archive Old Logs","text":"<pre><code>import shutil\nfrom datetime import datetime\n\ndef archive_logs(logs_dir=\"logs\", archive_dir=\"logs/archive\"):\n    \"\"\"Archive logs to a separate directory.\"\"\"\n    os.makedirs(archive_dir, exist_ok=True)\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    archive_name = f\"logs_archive_{timestamp}\"\n    shutil.make_archive(archive_name, 'zip', logs_dir)\n    shutil.move(f\"{archive_name}.zip\", archive_dir)\n\n    print(f\"Archived to: {archive_dir}/{archive_name}.zip\")\n\n# Create archive\narchive_logs()\n</code></pre>"},{"location":"configuration/log-management/#environment-specific-settings","title":"Environment-Specific Settings","text":""},{"location":"configuration/log-management/#development","title":"Development","text":"<pre><code>dev_config = LoggingConfig(\n    logs_dir=\"dev_logs\",\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=10*1024*1024,  # 10MB (smaller for dev)\n            backup_count=3           # Fewer backups\n        ),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\")\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#production","title":"Production","text":"<pre><code>prod_config = LoggingConfig(\n    logs_dir=\"/var/log/myapp\",\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=100*1024*1024,  # 100MB\n            backup_count=20           # More history\n        ),\n        \"errors\": LogFileConfig(\n            \"errors\",\n            level=\"ERROR\",\n            max_bytes=50*1024*1024,\n            backup_count=30\n        ),\n        \"performance\": LogFileConfig(\n            \"performance\",\n            max_bytes=200*1024*1024,\n            backup_count=15\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#best-practices","title":"Best Practices","text":""},{"location":"configuration/log-management/#1-plan-disk-usage","title":"1. Plan Disk Usage","text":"<p>Calculate maximum disk usage before deployment:</p> <pre><code># High-traffic application\nconfig = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"app\", max_bytes=100*1024*1024, backup_count=20),\n        # Maximum: 2.1GB (100MB * 21)\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#2-separate-error-logs","title":"2. Separate Error Logs","text":"<p>Keep errors in dedicated files with longer retention:</p> <pre><code>config = LoggingConfig(\n    log_files={\n        \"app\": LogFileConfig(\"app\", backup_count=5),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\", backup_count=30)\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#3-performance-log-rotation","title":"3. Performance Log Rotation","text":"<p>Performance logs can be large - configure appropriately:</p> <pre><code>config = LoggingConfig(\n    log_files={\n        \"performance\": LogFileConfig(\n            \"performance\",\n            max_bytes=200*1024*1024,  # 200MB\n            backup_count=10           # 2GB total\n        )\n    }\n)\n</code></pre>"},{"location":"configuration/log-management/#4-disable-unused-logs","title":"4. Disable Unused Logs","text":"<p>Save disk space by disabling unnecessary log files:</p> <pre><code>config = LoggingConfig()\nconfig.log_files[\"api\"].enabled = False\nconfig.log_files[\"services\"].enabled = False\nconfig.log_files[\"database\"].enabled = False\n</code></pre>"},{"location":"configuration/log-management/#5-use-monitoring","title":"5. Use Monitoring","text":"<p>Monitor log file sizes and rotation:</p> <pre><code>import os\n\ndef check_log_health(logs_dir=\"logs\"):\n    for filename in os.listdir(logs_dir):\n        filepath = os.path.join(logs_dir, filename)\n        size = os.path.getsize(filepath)\n        size_mb = size / (1024 * 1024)\n        print(f\"{filename}: {size_mb:.2f}MB\")\n\ncheck_log_health()\n</code></pre>"},{"location":"configuration/log-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configuration/log-management/#logs-not-rotating","title":"Logs Not Rotating","text":"<p>If logs aren't rotating:</p> <ol> <li>Check max_bytes setting</li> <li>Verify write permissions</li> <li>Ensure backup_count &gt; 0</li> </ol>"},{"location":"configuration/log-management/#disk-space-issues","title":"Disk Space Issues","text":"<p>If running out of disk space:</p> <ol> <li>Reduce max_bytes or backup_count</li> <li>Disable unused log files</li> <li>Implement automatic cleanup</li> <li>Archive old logs to external storage</li> </ol>"},{"location":"configuration/log-management/#missing-log-files","title":"Missing Log Files","text":"<p>If log files aren't created:</p> <ol> <li>Check directory permissions</li> <li>Verify logs_dir exists</li> <li>Ensure enabled=True</li> <li>Check for configuration errors</li> </ol>"},{"location":"configuration/log-management/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Presets - Pre-configured setups</li> <li>Custom Configuration - Build custom configs</li> <li>JSON Logging - Use JSON format</li> <li>Production Deployment - Deploy to production</li> </ul>"},{"location":"configuration/presets/","title":"Configuration Presets","text":"<p>Sherlock AI provides pre-built configuration presets for common scenarios. These presets are ready-to-use configurations that follow best practices for different environments.</p>"},{"location":"configuration/presets/#available-presets","title":"Available Presets","text":""},{"location":"configuration/presets/#development-preset","title":"Development Preset","text":"<p>Optimized for development with debug-level logging:</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingPresets\n\nsherlock_ai(LoggingPresets.development())\n</code></pre> <p>Features: - Debug-level console output - All log files enabled - Detailed logging for debugging - Suitable for local development</p> <p>Configuration: <pre><code>LoggingConfig(\n    console_level=\"DEBUG\",\n    root_level=\"DEBUG\",\n    log_files={\n        \"app\": LogFileConfig(\"app\"),\n        \"errors\": LogFileConfig(\"errors\", level=\"ERROR\"),\n        \"api\": LogFileConfig(\"api\"),\n        \"database\": LogFileConfig(\"database\"),\n        \"services\": LogFileConfig(\"services\"),\n        \"performance\": LogFileConfig(\"performance\")\n    }\n)\n</code></pre></p>"},{"location":"configuration/presets/#production-preset","title":"Production Preset","text":"<p>Optimized for production with performance and stability:</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingPresets\n\nsherlock_ai(LoggingPresets.production())\n</code></pre> <p>Features: - INFO-level logging (less verbose) - Larger file sizes for fewer rotations - More backup files - Optimized for performance</p> <p>Configuration: <pre><code>LoggingConfig(\n    console_level=\"INFO\",\n    root_level=\"INFO\",\n    log_files={\n        \"app\": LogFileConfig(\n            \"app\",\n            max_bytes=50*1024*1024,  # 50MB\n            backup_count=10\n        ),\n        \"errors\": LogFileConfig(\n            \"errors\",\n            level=\"ERROR\",\n            max_bytes=50*1024*1024,\n            backup_count=10\n        ),\n        \"performance\": LogFileConfig(\n            \"performance\",\n            max_bytes=50*1024*1024,\n            backup_count=10\n        )\n    }\n)\n</code></pre></p>"},{"location":"configuration/presets/#minimal-preset","title":"Minimal Preset","text":"<p>Basic setup with only essential logging:</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingPresets\n\nsherlock_ai(LoggingPresets.minimal())\n</code></pre> <p>Features: - Only app log file - INFO-level logging - Console output enabled - Minimal disk usage</p> <p>Configuration: <pre><code>LoggingConfig(\n    console_level=\"INFO\",\n    log_files={\n        \"app\": LogFileConfig(\"app\")\n    }\n)\n</code></pre></p>"},{"location":"configuration/presets/#performance-only-preset","title":"Performance Only Preset","text":"<p>Focus on performance monitoring:</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingPresets\n\nsherlock_ai(LoggingPresets.performance_only())\n</code></pre> <p>Features: - Only performance log file - No console output (cleaner for benchmarking) - Dedicated to performance metrics</p> <p>Configuration: <pre><code>LoggingConfig(\n    console_enabled=False,\n    log_files={\n        \"performance\": LogFileConfig(\"performance\")\n    },\n    loggers={\n        \"performance\": LoggerConfig(\n            \"PerformanceLogger\",\n            log_files=[\"performance\"],\n            propagate=False\n        )\n    }\n)\n</code></pre></p>"},{"location":"configuration/presets/#custom-file-names","title":"Custom File Names","text":"<p>Create a preset with custom file names:</p> <pre><code>from sherlock_ai import LoggingPresets\n\n# Use custom file names\nconfig = LoggingPresets.custom_files({\n    \"app\": \"logs/application.log\",\n    \"performance\": \"logs/metrics.log\",\n    \"errors\": \"logs/error_tracking.log\"\n})\n\nfrom sherlock_ai import sherlock_ai\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/presets/#modifying-presets","title":"Modifying Presets","text":"<p>Start with a preset and customize it:</p> <pre><code>from sherlock_ai import sherlock_ai, LoggingPresets\n\n# Start with production preset\nconfig = LoggingPresets.production()\n\n# Customize as needed\nconfig.console_level = \"WARNING\"\nconfig.log_files[\"app\"].max_bytes = 100*1024*1024  # 100MB\nconfig.log_files[\"api\"].enabled = True  # Enable API logs\n\n# Apply the modified configuration\nsherlock_ai(config)\n</code></pre>"},{"location":"configuration/presets/#environment-based-presets","title":"Environment-Based Presets","text":"<p>Use different presets based on environment:</p> <pre><code>import os\nfrom sherlock_ai import sherlock_ai, LoggingPresets\n\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\n\nif env == \"production\":\n    sherlock_ai(LoggingPresets.production())\nelif env == \"staging\":\n    # Production settings with debug for staging\n    config = LoggingPresets.production()\n    config.console_level = \"DEBUG\"\n    sherlock_ai(config)\nelif env == \"testing\":\n    # Minimal for testing\n    sherlock_ai(LoggingPresets.minimal())\nelse:\n    # Development\n    sherlock_ai(LoggingPresets.development())\n</code></pre>"},{"location":"configuration/presets/#preset-comparison","title":"Preset Comparison","text":"Preset Console Level Log Files File Size Backups Use Case Development DEBUG All 10MB 5 Local development Production INFO App, Errors, Performance 50MB 10 Production Minimal INFO App only 10MB 5 Simple apps Performance Only Disabled Performance only 10MB 5 Benchmarking"},{"location":"configuration/presets/#best-practices","title":"Best Practices","text":""},{"location":"configuration/presets/#1-start-with-a-preset","title":"1. Start with a Preset","text":"<p>Always start with the closest preset:</p> <pre><code># For production\nconfig = LoggingPresets.production()\n# Then customize\nconfig.console_level = \"WARNING\"\n</code></pre>"},{"location":"configuration/presets/#2-environment-variables","title":"2. Environment Variables","text":"<p>Use environment variables for flexibility:</p> <pre><code>env = os.getenv(\"ENV\", \"development\")\npreset = getattr(LoggingPresets, env)()\nsherlock_ai(preset)\n</code></pre>"},{"location":"configuration/presets/#3-testing-configuration","title":"3. Testing Configuration","text":"<p>Use minimal preset for testing:</p> <pre><code># In test setup\nsherlock_ai(LoggingPresets.minimal())\n</code></pre>"},{"location":"configuration/presets/#4-custom-presets","title":"4. Custom Presets","text":"<p>Create your own preset functions:</p> <pre><code>from sherlock_ai import LoggingConfig, LogFileConfig\n\ndef my_custom_preset():\n    return LoggingConfig(\n        logs_dir=\"custom_logs\",\n        console_level=\"INFO\",\n        log_files={\n            \"app\": LogFileConfig(\"application\", max_bytes=25*1024*1024),\n            \"errors\": LogFileConfig(\"errors\", level=\"ERROR\")\n        }\n    )\n\n# Use it\nfrom sherlock_ai import sherlock_ai\nsherlock_ai(my_custom_preset())\n</code></pre>"},{"location":"configuration/presets/#next-steps","title":"Next Steps","text":"<ul> <li>Custom Configuration - Build your own configuration from scratch</li> <li>JSON Logging - Use JSON format with presets</li> <li>Log Management - Manage log files and rotation</li> <li>Examples - See presets in action</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>Real-world examples and integration patterns for Sherlock AI. These examples demonstrate practical usage scenarios with complete, runnable code.</p>"},{"location":"examples/#example-categories","title":"Example Categories","text":""},{"location":"examples/#fastapi-integration","title":"FastAPI Integration","text":"<p>Complete FastAPI application with auto-instrumentation and manual decorators.</p> <p>View example \u2192</p>"},{"location":"examples/#async-functions","title":"Async Functions","text":"<p>Monitor asynchronous functions and coroutines.</p> <p>View example \u2192</p>"},{"location":"examples/#mongodb-storage","title":"MongoDB Storage","text":"<p>Store error insights and performance data in MongoDB.</p> <p>View example \u2192</p>"},{"location":"examples/#api-client-integration","title":"API Client Integration","text":"<p>HTTP-based data ingestion to centralized backend.</p> <p>View example \u2192</p>"},{"location":"examples/#combined-monitoring","title":"Combined Monitoring","text":"<p>Use multiple decorators together for comprehensive monitoring.</p> <p>View example \u2192</p>"},{"location":"examples/#quick-examples","title":"Quick Examples","text":""},{"location":"examples/#basic-monitoring","title":"Basic Monitoring","text":"<pre><code>from sherlock_ai import sherlock_ai, get_logger, log_performance\n\nsherlock_ai()\nlogger = get_logger(__name__)\n\n@log_performance\ndef process_data(data):\n    logger.info(f\"Processing {len(data)} items\")\n    result = sum(data)\n    return result\n\nresult = process_data([1, 2, 3, 4, 5])\n</code></pre>"},{"location":"examples/#error-analysis","title":"Error Analysis","text":"<pre><code>from sherlock_ai.monitoring import sherlock_error_handler\nimport os\n\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\n\n@sherlock_error_handler\ndef risky_operation():\n    result = 1 / 0  # AI analyzes this error\n    return result\n</code></pre>"},{"location":"examples/#memory-monitoring","title":"Memory Monitoring","text":"<pre><code>from sherlock_ai import monitor_memory\n\n@monitor_memory(trace_malloc=True)\ndef allocate_memory():\n    data = [i * i for i in range(1000000)]\n    return len(data)\n</code></pre>"},{"location":"examples/#complete-application-examples","title":"Complete Application Examples","text":"<p>Explore detailed, production-ready examples:</p> <ul> <li>FastAPI Integration - Full web application setup</li> <li>Async Functions - Async/await patterns</li> <li>MongoDB Storage - Error insight storage</li> <li>API Client - Centralized monitoring</li> <li>Combined Monitoring - Multiple features together</li> </ul>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<ul> <li>Features - Learn about available features</li> <li>Configuration - Configure Sherlock AI</li> </ul>"},{"location":"examples/api-client/","title":"API Client Integration","text":"<p>HTTP-based data ingestion to centralized backend services.</p>"},{"location":"examples/api-client/#setup","title":"Setup","text":"<pre><code>import os\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"your-api-key-here\"\n</code></pre>"},{"location":"examples/api-client/#error-insights","title":"Error Insights","text":"<pre><code>from sherlock_ai.monitoring import sherlock_error_handler\n\n@sherlock_error_handler\ndef monitored_function():\n    # Errors sent to: POST /v1/logs/injest-error-insights\n    result = complex_operation()\n    return result\n</code></pre>"},{"location":"examples/api-client/#performance-insights","title":"Performance Insights","text":"<pre><code>from sherlock_ai.monitoring import sherlock_performance_insights\n\n@sherlock_performance_insights\ndef slow_function():\n    # Performance data sent to: POST /v1/logs/injest-performance-insights\n    return heavy_computation()\n</code></pre>"},{"location":"examples/api-client/#manual-submission","title":"Manual Submission","text":"<pre><code>from sherlock_ai.storage import ApiClient\n\napi_client = ApiClient()\n\nerror_data = {\n    \"function_name\": \"my_function\",\n    \"error_message\": \"Error occurred\",\n    \"stack_trace\": \"...\",\n    \"probable_cause\": \"Analysis\"\n}\n\napi_client.post_error_insights(error_data)\n</code></pre>"},{"location":"examples/api-client/#complete-example","title":"Complete Example","text":"<pre><code>import os\nfrom sherlock_ai import sherlock_ai, log_performance\nfrom sherlock_ai.monitoring import sherlock_error_handler, sherlock_performance_insights\n\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"your-api-key\"\nsherlock_ai()\n\n@log_performance\n@sherlock_error_handler\n@sherlock_performance_insights\ndef api_monitored_function():\n    return process_data()\n</code></pre>"},{"location":"examples/async-functions/","title":"Async Functions","text":"<p>Monitor asynchronous functions and coroutines with Sherlock AI.</p>"},{"location":"examples/async-functions/#basic-async-monitoring","title":"Basic Async Monitoring","text":"<pre><code>from sherlock_ai import sherlock_ai, log_performance\nimport httpx\nimport asyncio\n\nsherlock_ai()\n\n@log_performance\nasync def fetch_data(url: str):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url)\n        return response.json()\n\n# Usage\nasyncio.run(fetch_data(\"https://api.example.com/data\"))\n</code></pre>"},{"location":"examples/async-functions/#combined-async-monitoring","title":"Combined Async Monitoring","text":"<pre><code>from sherlock_ai import log_performance, monitor_memory, monitor_resources\n\n@log_performance\n@monitor_memory\n@monitor_resources\nasync def process_async_data():\n    data = await fetch_large_dataset()\n    processed = await transform_data(data)\n    return processed\n</code></pre>"},{"location":"examples/async-functions/#async-context-managers","title":"Async Context Managers","text":"<pre><code>from sherlock_ai.performance import PerformanceTimer\nfrom sherlock_ai import MemoryTracker\n\nasync def async_pipeline():\n    with PerformanceTimer(\"data_fetch\"):\n        data = await fetch_data()\n\n    with MemoryTracker(\"data_processing\"):\n        result = await process_data(data)\n\n    return result\n</code></pre>"},{"location":"examples/async-functions/#fastapi-async-routes","title":"FastAPI Async Routes","text":"<pre><code>from fastapi import FastAPI\nfrom sherlock_ai import SherlockAI, LoggingConfig\n\nconfig = LoggingConfig(auto_instrument=True)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\napp = FastAPI()\n\n@app.get(\"/async-data\")\nasync def get_async_data():\n    # Automatically monitored\n    data = await fetch_external_api()\n    return {\"data\": data}\n</code></pre>"},{"location":"examples/combined-monitoring/","title":"Combined Monitoring","text":"<p>Use multiple Sherlock AI features together for comprehensive monitoring.</p>"},{"location":"examples/combined-monitoring/#complete-monitoring-stack","title":"Complete Monitoring Stack","text":"<pre><code>from sherlock_ai import sherlock_ai, log_performance, monitor_memory, monitor_resources, hardcoded_value_detector\nfrom sherlock_ai.monitoring import sherlock_error_handler\n\nsherlock_ai()\n\n@log_performance\n@monitor_memory(trace_malloc=True)\n@monitor_resources(include_io=True)\n@sherlock_error_handler\n@hardcoded_value_detector\ndef comprehensive_function():\n    # This function is monitored for:\n    # - Execution time (performance)\n    # - Memory usage (memory)\n    # - System resources (CPU, I/O, etc.)\n    # - Error analysis (AI-powered)\n    # - Hardcoded value detection\n    data = process_large_dataset()\n    save_to_database(data)\n    return len(data)\n</code></pre>"},{"location":"examples/combined-monitoring/#fastapi-with-full-monitoring","title":"FastAPI with Full Monitoring","text":"<pre><code>from fastapi import FastAPI\nfrom sherlock_ai import SherlockAI, LoggingConfig, get_logger\nimport os\n\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"your-api-key\"\n\nconfig = LoggingConfig(\n    auto_instrument=True,\n    log_format_type=\"json\"\n)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\nlogger = get_logger(__name__)\n\napp = FastAPI()\n\n@app.post(\"/process\")\ndef process_data(data: dict):\n    # Automatically monitored with all features\n    logger.info(\"Processing data\")\n    result = complex_processing(data)\n    return {\"result\": result}\n</code></pre>"},{"location":"examples/combined-monitoring/#data-pipeline-example","title":"Data Pipeline Example","text":"<pre><code>from sherlock_ai import sherlock_ai, log_performance, monitor_memory, monitor_resources\nfrom sherlock_ai.monitoring import sherlock_error_handler\n\nsherlock_ai()\n\n@log_performance\n@monitor_memory\n@sherlock_error_handler\ndef extract_data():\n    return fetch_from_source()\n\n@log_performance\n@monitor_resources(include_io=True)\n@sherlock_error_handler\ndef transform_data(data):\n    return process(data)\n\n@log_performance\n@monitor_memory\n@monitor_resources(include_io=True)\n@sherlock_error_handler\ndef load_data(data):\n    save_to_database(data)\n\n# Run pipeline\ndata = extract_data()\ntransformed = transform_data(data)\nload_data(transformed)\n</code></pre>"},{"location":"examples/fastapi-integration/","title":"FastAPI Integration","text":"<p>Complete FastAPI application example with Sherlock AI monitoring.</p>"},{"location":"examples/fastapi-integration/#auto-instrumentation-setup","title":"Auto-Instrumentation Setup","text":"<pre><code># main.py\nfrom fastapi import FastAPI, HTTPException\nfrom sherlock_ai import SherlockAI, LoggingConfig, get_logger\nfrom pydantic import BaseModel\nimport os\n\n# Initialize Sherlock AI BEFORE creating app\nconfig = LoggingConfig(\n    auto_instrument=True,\n    log_format_type=\"json\",\n    logs_dir=\"api_logs\"\n)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\nlogger = get_logger(__name__)\n\n# Create FastAPI app\napp = FastAPI(title=\"Sherlock AI Demo API\")\n\nclass Item(BaseModel):\n    name: str\n    value: int\n\n@app.get(\"/\")\ndef read_root():\n    logger.info(\"Root endpoint accessed\")\n    return {\"message\": \"Welcome to Sherlock AI Demo\"}\n\n@app.get(\"/health\")\ndef health_check():\n    return {\"status\": \"healthy\"}\n\n@app.post(\"/items\")\ndef create_item(item: Item):\n    logger.info(f\"Creating item: {item.name}\")\n    return {\"item\": item, \"id\": 123}\n\n@app.get(\"/error\")\ndef trigger_error():\n    # This error will be automatically analyzed\n    raise HTTPException(status_code=500, detail=\"Test error\")\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"examples/fastapi-integration/#manual-decorators-setup","title":"Manual Decorators Setup","text":"<pre><code>from fastapi import FastAPI\nfrom sherlock_ai import sherlock_ai, get_logger, log_performance, monitor_memory\n\nsherlock_ai()\nlogger = get_logger(__name__)\n\napp = FastAPI()\n\n@app.get(\"/monitored\")\n@log_performance\n@monitor_memory\ndef monitored_endpoint():\n    logger.info(\"Monitored endpoint called\")\n    return {\"status\": \"ok\"}\n</code></pre>"},{"location":"examples/fastapi-integration/#complete-production-example","title":"Complete Production Example","text":"<pre><code># app/main.py\nfrom fastapi import FastAPI, Request, HTTPException\nfrom fastapi.responses import JSONResponse\nfrom sherlock_ai import SherlockAI, LoggingConfig, LoggingPresets, get_logger, set_request_id\nimport os\n\n# Environment-based configuration\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\n\nif env == \"production\":\n    config = LoggingPresets.production()\n    config.auto_instrument = True\n    config.log_format_type = \"json\"\nelse:\n    config = LoggingPresets.development()\n    config.auto_instrument = True\n\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\nlogger = get_logger(__name__)\n\napp = FastAPI(title=\"Production API\")\n\n# Request ID middleware\n@app.middleware(\"http\")\nasync def request_id_middleware(request: Request, call_next):\n    request_id = request.headers.get(\"X-Request-ID\", set_request_id())\n    response = await call_next(request)\n    response.headers[\"X-Request-ID\"] = request_id\n    return response\n\n# Exception handler\n@app.exception_handler(Exception)\nasync def global_exception_handler(request: Request, exc: Exception):\n    logger.error(f\"Unhandled exception: {exc}\")\n    return JSONResponse(\n        status_code=500,\n        content={\"detail\": \"Internal server error\"}\n    )\n\n@app.get(\"/\")\ndef read_root():\n    return {\"message\": \"API is running\"}\n\n@app.get(\"/health\")\ndef health_check():\n    return {\"status\": \"healthy\"}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\n        \"app.main:app\",\n        host=\"0.0.0.0\",\n        port=8000,\n        reload=(env != \"production\")\n    )\n</code></pre> <p>Run with: <code>python -m app.main</code></p>"},{"location":"examples/mongodb-storage/","title":"MongoDB Storage","text":"<p>Store error insights and performance data in MongoDB.</p>"},{"location":"examples/mongodb-storage/#setup","title":"Setup","text":"<pre><code>import os\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\n</code></pre>"},{"location":"examples/mongodb-storage/#error-insights-storage","title":"Error Insights Storage","text":"<pre><code>from sherlock_ai.monitoring import sherlock_error_handler\n\n@sherlock_error_handler\ndef risky_function():\n    result = 1 / 0\n    return result\n\n# Error automatically stored in: sherlock-meta.error-insights\n</code></pre>"},{"location":"examples/mongodb-storage/#manual-storage","title":"Manual Storage","text":"<pre><code>from sherlock_ai.storage import MongoManager\n\nmongo = MongoManager(\"mongodb://localhost:27017\")\n\nerror_data = {\n    \"function_name\": \"my_function\",\n    \"error_message\": \"Division by zero\",\n    \"stack_trace\": \"...\",\n    \"probable_cause\": \"AI analysis result\"\n}\n\nmongo.save(error_data)\n</code></pre>"},{"location":"examples/mongodb-storage/#complete-example","title":"Complete Example","text":"<pre><code>from sherlock_ai import sherlock_ai, log_performance\nfrom sherlock_ai.monitoring import sherlock_error_handler\nimport os\n\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\nsherlock_ai()\n\n@log_performance\n@sherlock_error_handler\ndef process_with_mongodb():\n    # Errors stored automatically\n    try:\n        result = risky_operation()\n        return result\n    except Exception as e:\n        raise\n</code></pre>"},{"location":"features/","title":"Features Overview","text":"<p>Sherlock AI provides comprehensive monitoring and analysis capabilities for Python applications. Each feature is designed to work independently or in combination with others for complete observability.</p>"},{"location":"features/#core-features","title":"Core Features","text":""},{"location":"features/#performance-monitoring","title":"Performance Monitoring","text":"<p>Track execution times of functions and code blocks with the <code>@log_performance</code> decorator and <code>PerformanceTimer</code> context manager.</p> <p>Learn more \u2192</p>"},{"location":"features/#memory-monitoring","title":"Memory Monitoring","text":"<p>Monitor Python memory usage with detailed heap analysis and tracemalloc integration using <code>@monitor_memory</code>.</p> <p>Learn more \u2192</p>"},{"location":"features/#resource-monitoring","title":"Resource Monitoring","text":"<p>Track comprehensive system resources including CPU, memory, I/O, and network usage with <code>@monitor_resources</code>.</p> <p>Learn more \u2192</p>"},{"location":"features/#error-analysis","title":"Error Analysis","text":"<p>AI-powered error analysis with automatic probable cause detection and MongoDB storage using <code>@sherlock_error_handler</code>.</p> <p>Learn more \u2192</p>"},{"location":"features/#code-analysis","title":"Code Analysis","text":"<p>Automatically detect and refactor hardcoded values in your code using <code>@hardcoded_value_detector</code>.</p> <p>Learn more \u2192</p>"},{"location":"features/#auto-instrumentation","title":"Auto-Instrumentation","text":"<p>Zero-code setup for popular frameworks like FastAPI, automatically instrumenting routes with monitoring decorators.</p> <p>Learn more \u2192</p>"},{"location":"features/#feature-comparison","title":"Feature Comparison","text":"Feature Decorator Context Manager Async Support Storage Options Performance Monitoring \u2713 \u2713 \u2713 Log files Memory Monitoring \u2713 \u2713 \u2713 Log files Resource Monitoring \u2713 \u2713 \u2713 Log files Error Analysis \u2713 \u2717 \u2713 MongoDB, API Code Analysis \u2713 \u2717 \u2713 File system Auto-Instrumentation \u2713 \u2717 \u2713 All supported"},{"location":"features/#combined-usage","title":"Combined Usage","text":"<p>Features can be stacked for comprehensive monitoring:</p> <pre><code>from sherlock_ai import log_performance, monitor_memory, monitor_resources\nfrom sherlock_ai.monitoring import sherlock_error_handler\nfrom sherlock_ai import hardcoded_value_detector\n\n@log_performance\n@monitor_memory(trace_malloc=True)\n@monitor_resources(include_io=True)\n@sherlock_error_handler\n@hardcoded_value_detector\ndef comprehensive_function():\n    # This function will be monitored for:\n    # - Execution time (performance)\n    # - Memory usage (memory)\n    # - System resources (CPU, I/O, etc.)\n    # - Error analysis (AI-powered)\n    # - Hardcoded value detection\n    data = process_large_dataset()\n    save_to_database(data)\n    return len(data)\n</code></pre>"},{"location":"features/#next-steps","title":"Next Steps","text":"<p>Explore each feature in detail to understand how to use them effectively in your application:</p> <ol> <li>Start with Performance Monitoring for basic tracking</li> <li>Add Memory Monitoring for memory-intensive operations</li> <li>Use Resource Monitoring for comprehensive system analysis</li> <li>Enable Error Analysis for AI-powered debugging</li> <li>Try Code Analysis to improve code quality</li> <li>Set up Auto-Instrumentation for zero-code monitoring</li> </ol>"},{"location":"features/auto-instrumentation/","title":"Auto-Instrumentation","text":"<p>Zero-code setup for popular frameworks like FastAPI. Sherlock AI can automatically instrument your routes with monitoring decorators, similar to how Sentry works, providing comprehensive monitoring without modifying each endpoint.</p>"},{"location":"features/auto-instrumentation/#how-it-works","title":"How It Works","text":"<p>When auto-instrumentation is enabled, Sherlock AI \"monkey-patches\" the framework's routing methods at startup. This means it automatically wraps your endpoint functions with monitoring decorators at runtime, without you needing to manually add decorators to each route.</p> <p>Automatically Applied Decorators: - <code>@log_performance</code> - Track execution times - <code>@monitor_memory</code> - Monitor memory usage - <code>@monitor_resources</code> - Track CPU, I/O, and network - <code>@sherlock_error_handler</code> - AI-powered error analysis</p>"},{"location":"features/auto-instrumentation/#fastapi-integration","title":"FastAPI Integration","text":""},{"location":"features/auto-instrumentation/#basic-setup","title":"Basic Setup","text":"<pre><code># main.py\nfrom fastapi import FastAPI\nfrom sherlock_ai import SherlockAI, LoggingConfig, get_logger\n\n# 1. Initialize Sherlock AI with auto-instrumentation BEFORE creating the app\nconfig = LoggingConfig(\n    auto_instrument=True,  # Enable auto-instrumentation (default)\n    log_format_type=\"json\"  # Use JSON format for structured logging (default)\n)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\nlogger = get_logger(__name__)\n\n# 2. Create your FastAPI app as usual\napp = FastAPI()\n\n# 3. Define routes WITHOUT any manual decorators\n@app.get(\"/health\")\ndef health_check():\n    # This endpoint is now automatically monitored for:\n    # - Performance\n    # - Memory Usage\n    # - Resource Consumption\n    # - Error Insights\n    logger.info(\"Health check endpoint was called.\")\n    return {\"status\": \"healthy\"}\n\n@app.get(\"/error\")\ndef trigger_error():\n    # Errors in this endpoint will be captured automatically\n    result = 1 / 0\n    return {\"result\": result}\n\n@app.post(\"/process\")\nasync def process_data(data: dict):\n    # Async endpoints are also automatically monitored\n    logger.info(f\"Processing data: {data}\")\n    result = await process_async(data)\n    return {\"result\": result}\n</code></pre>"},{"location":"features/auto-instrumentation/#configuration-options","title":"Configuration Options","text":"<pre><code>from sherlock_ai import SherlockAI, LoggingConfig\n\n# Full configuration\nconfig = LoggingConfig(\n    auto_instrument=True,           # Enable auto-instrumentation\n    log_format_type=\"json\",         # \"json\" or \"log\"\n    logs_dir=\"application_logs\",    # Custom log directory\n    console_level=\"INFO\"            # Console log level\n)\n\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n</code></pre>"},{"location":"features/auto-instrumentation/#disable-auto-instrumentation","title":"Disable Auto-Instrumentation","text":"<p>If you prefer manual decorator control:</p> <pre><code>config = LoggingConfig(\n    auto_instrument=False  # Disable auto-instrumentation\n)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\n# Now manually add decorators\nfrom sherlock_ai import log_performance\n\n@app.get(\"/manual\")\n@log_performance\ndef manual_endpoint():\n    return {\"status\": \"ok\"}\n</code></pre>"},{"location":"features/auto-instrumentation/#what-gets-monitored","title":"What Gets Monitored","text":""},{"location":"features/auto-instrumentation/#performance-metrics","title":"Performance Metrics","text":"<p>Every endpoint automatically logs execution time:</p> <pre><code>PERFORMANCE | main.health_check | SUCCESS | 0.002s\nPERFORMANCE | main.process_data | SUCCESS | 0.145s\nPERFORMANCE | main.trigger_error | ERROR | 0.001s | division by zero\n</code></pre>"},{"location":"features/auto-instrumentation/#memory-usage","title":"Memory Usage","text":"<p>Memory consumption per request:</p> <pre><code>MEMORY | main.process_data | SUCCESS | 0.145s | Current: 95.67MB | Change: +2.34MB | Traced: 1.45MB (Peak: 1.89MB)\n</code></pre>"},{"location":"features/auto-instrumentation/#resource-consumption","title":"Resource Consumption","text":"<p>CPU, I/O, and thread usage:</p> <pre><code>RESOURCES | main.process_data | SUCCESS | 0.145s | CPU: 15.2% | Memory: 95.67MB (+2.34MB) | Threads: 8 | I/O: R:1.23MB W:0.45MB\n</code></pre>"},{"location":"features/auto-instrumentation/#error-analysis","title":"Error Analysis","text":"<p>Automatic AI-powered error insights:</p> <pre><code>{\n  \"function_name\": \"main.trigger_error\",\n  \"error_type\": \"ZeroDivisionError\",\n  \"error_message\": \"division by zero\",\n  \"probable_cause\": \"Attempting division by zero on line 42...\",\n  \"timestamp\": \"2025-01-01T12:34:56\"\n}\n</code></pre>"},{"location":"features/auto-instrumentation/#timing-requirements","title":"Timing Requirements","text":"<p>Important: Initialize Sherlock AI BEFORE creating your FastAPI app:</p> <pre><code># \u2705 CORRECT - Initialize before app creation\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\napp = FastAPI()\n\n# \u274c INCORRECT - Too late, routes already registered\napp = FastAPI()\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n</code></pre>"},{"location":"features/auto-instrumentation/#log-output-formats","title":"Log Output Formats","text":""},{"location":"features/auto-instrumentation/#standard-format","title":"Standard Format","text":"<pre><code>2025-01-01 12:34:56 - a1b2c3d4 - PerformanceLogger - INFO - PERFORMANCE | main.health_check | SUCCESS | 0.002s\n</code></pre>"},{"location":"features/auto-instrumentation/#json-format-recommended","title":"JSON Format (Recommended)","text":"<pre><code>{\n  \"timestamp\": \"2025-01-01 12:34:56\",\n  \"level\": \"INFO\",\n  \"logger\": \"PerformanceLogger\",\n  \"message\": \"PERFORMANCE | main.health_check | SUCCESS | 0.002s\",\n  \"request_id\": \"a1b2c3d4\",\n  \"module\": \"main\",\n  \"function\": \"health_check\",\n  \"line\": 42,\n  \"thread\": 13672,\n  \"process\": 22008\n}\n</code></pre>"},{"location":"features/auto-instrumentation/#request-id-tracking","title":"Request ID Tracking","text":"<p>Auto-instrumentation integrates with request ID tracking:</p> <pre><code>from sherlock_ai import set_request_id\n\n@app.middleware(\"http\")\nasync def add_request_id(request, call_next):\n    # Set request ID for all monitoring\n    request_id = request.headers.get(\"X-Request-ID\", set_request_id())\n    response = await call_next(request)\n    response.headers[\"X-Request-ID\"] = request_id\n    return response\n\n# All monitoring logs will include the request ID\n</code></pre>"},{"location":"features/auto-instrumentation/#selective-monitoring","title":"Selective Monitoring","text":""},{"location":"features/auto-instrumentation/#exclude-specific-routes","title":"Exclude Specific Routes","text":"<p>If you need to exclude certain routes from monitoring:</p> <pre><code>from fastapi import FastAPI\nfrom sherlock_ai import SherlockAI, LoggingConfig\n\n# Enable auto-instrumentation\nconfig = LoggingConfig(auto_instrument=True)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\napp = FastAPI()\n\n# This route is automatically monitored\n@app.get(\"/monitored\")\ndef monitored_endpoint():\n    return {\"status\": \"monitored\"}\n\n# To exclude a route, disable auto-instrumentation and use manual control\n# (Currently all routes are monitored when auto_instrument=True)\n</code></pre>"},{"location":"features/auto-instrumentation/#production-deployment","title":"Production Deployment","text":""},{"location":"features/auto-instrumentation/#with-uvicorn","title":"With Uvicorn","text":"<pre><code># main.py\nfrom fastapi import FastAPI\nfrom sherlock_ai import SherlockAI, LoggingConfig, LoggingPresets\nimport os\n\n# Use environment-specific presets\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\n\nif env == \"production\":\n    config = LoggingPresets.production()\n    config.auto_instrument = True\nelse:\n    config = LoggingPresets.development()\n    config.auto_instrument = True\n\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\napp = FastAPI()\n\n# Define routes...\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\n        \"main:app\",\n        host=\"0.0.0.0\",\n        port=8000,\n        reload=(env != \"production\")\n    )\n</code></pre>"},{"location":"features/auto-instrumentation/#with-docker","title":"With Docker","text":"<pre><code>FROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\n# Environment variables for monitoring\nENV ENVIRONMENT=production\nENV MONGO_URI=mongodb://mongo:27017\nENV SHERLOCK_AI_API_KEY=your-api-key\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"features/auto-instrumentation/#best-practices","title":"Best Practices","text":""},{"location":"features/auto-instrumentation/#1-initialize-early","title":"1. Initialize Early","text":"<p>Always initialize before app creation:</p> <pre><code># Initialize Sherlock AI first\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\n# Then create app\napp = FastAPI()\n</code></pre>"},{"location":"features/auto-instrumentation/#2-use-json-format","title":"2. Use JSON Format","text":"<p>JSON format is better for log aggregation:</p> <pre><code>config = LoggingConfig(\n    auto_instrument=True,\n    log_format_type=\"json\"  # Better for parsing and analysis\n)\n</code></pre>"},{"location":"features/auto-instrumentation/#3-configure-storage","title":"3. Configure Storage","text":"<p>Set up MongoDB or API client for error insights:</p> <pre><code>import os\n\n# Production configuration\nos.environ[\"MONGO_URI\"] = \"mongodb://production-mongo:27017\"\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"production-api-key\"\n\nconfig = LoggingConfig(auto_instrument=True)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n</code></pre>"},{"location":"features/auto-instrumentation/#4-add-request-id-middleware","title":"4. Add Request ID Middleware","text":"<p>Enable distributed tracing:</p> <pre><code>from sherlock_ai import set_request_id\n\n@app.middleware(\"http\")\nasync def request_id_middleware(request, call_next):\n    request_id = request.headers.get(\"X-Request-ID\", set_request_id())\n    response = await call_next(request)\n    response.headers[\"X-Request-ID\"] = request_id\n    return response\n</code></pre>"},{"location":"features/auto-instrumentation/#use-cases","title":"Use Cases","text":"<ul> <li>Microservices: Monitor all endpoints without code changes</li> <li>Rapid Development: Get monitoring without adding decorators</li> <li>Legacy APIs: Add monitoring to existing FastAPI apps</li> <li>Production Debugging: Comprehensive monitoring in production</li> <li>Performance Analysis: Track performance across all endpoints</li> <li>Error Tracking: Automatic error analysis for all routes</li> </ul>"},{"location":"features/auto-instrumentation/#comparison-manual-vs-auto-instrumentation","title":"Comparison: Manual vs Auto-Instrumentation","text":""},{"location":"features/auto-instrumentation/#manual-decorators","title":"Manual Decorators","text":"<pre><code>from sherlock_ai import log_performance, monitor_memory\nfrom sherlock_ai.monitoring import sherlock_error_handler\n\n@app.get(\"/endpoint1\")\n@log_performance\n@monitor_memory\n@sherlock_error_handler\ndef endpoint1():\n    pass\n\n@app.get(\"/endpoint2\")\n@log_performance\n@monitor_memory\n@sherlock_error_handler\ndef endpoint2():\n    pass\n\n# Need to add decorators to EVERY endpoint\n</code></pre>"},{"location":"features/auto-instrumentation/#auto-instrumentation_1","title":"Auto-Instrumentation","text":"<pre><code>from sherlock_ai import SherlockAI, LoggingConfig\n\n# One-time setup\nconfig = LoggingConfig(auto_instrument=True)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\napp = FastAPI()\n\n# All endpoints automatically monitored\n@app.get(\"/endpoint1\")\ndef endpoint1():\n    pass\n\n@app.get(\"/endpoint2\")\ndef endpoint2():\n    pass\n</code></pre>"},{"location":"features/auto-instrumentation/#supported-frameworks","title":"Supported Frameworks","text":""},{"location":"features/auto-instrumentation/#currently-supported","title":"Currently Supported","text":"<ul> <li>FastAPI - Full support with automatic route instrumentation</li> </ul>"},{"location":"features/auto-instrumentation/#coming-soon","title":"Coming Soon","text":"<ul> <li>Flask</li> <li>Django</li> <li>Starlette</li> <li>Quart</li> </ul>"},{"location":"features/auto-instrumentation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/auto-instrumentation/#monitoring-not-working","title":"Monitoring Not Working","text":"<p>If auto-instrumentation doesn't work:</p> <ol> <li>Ensure Sherlock AI is initialized BEFORE app creation</li> <li>Check that <code>auto_instrument=True</code> in config</li> <li>Verify logs directory exists and is writable</li> </ol>"},{"location":"features/auto-instrumentation/#duplicate-logs","title":"Duplicate Logs","text":"<p>If you see duplicate log entries:</p> <ol> <li>Make sure you're not calling <code>sherlock_ai()</code> multiple times</li> <li>Don't mix auto-instrumentation with manual decorators</li> <li>Check for multiple initialization in dev reload</li> </ol>"},{"location":"features/auto-instrumentation/#performance-impact","title":"Performance Impact","text":"<p>Auto-instrumentation adds minimal overhead:</p> <ul> <li>~1-2ms per request for basic monitoring</li> <li>~5-10ms per request with memory tracking</li> <li>Async operations have negligible impact</li> </ul>"},{"location":"features/auto-instrumentation/#next-steps","title":"Next Steps","text":"<ul> <li>FastAPI Setup Guide - Detailed FastAPI integration</li> <li>Configuration - Configure monitoring behavior</li> <li>Examples - Complete FastAPI examples</li> <li>Production Deployment - Deploy to production</li> </ul>"},{"location":"features/code-analysis/","title":"Code Analysis","text":"<p>Automatically detect and refactor hardcoded values in your code using AST parsing and LLM-powered suggestions. The <code>@hardcoded_value_detector</code> decorator helps improve code maintainability by identifying magic numbers, strings, and URLs that should be constants.</p>"},{"location":"features/code-analysis/#decorator-usage","title":"Decorator Usage","text":""},{"location":"features/code-analysis/#basic-example","title":"Basic Example","text":"<pre><code>from sherlock_ai import hardcoded_value_detector\n\n@hardcoded_value_detector\ndef api_handler():\n    url = \"https://api.example.com\"\n    timeout = 30\n    message = \"Processing request\"\n    return requests.get(url, timeout=timeout)\n\n# Automatically creates constants.py with:\n# API_URL = \"https://api.example.com\"\n# TIMEOUT_SECONDS = 30\n# PROCESSING_MESSAGE = \"Processing request\"\n# And updates your function to use these constants\n</code></pre>"},{"location":"features/code-analysis/#with-other-decorators","title":"With Other Decorators","text":"<p>Combine with monitoring decorators:</p> <pre><code>from sherlock_ai import log_performance, hardcoded_value_detector\nfrom sherlock_ai.monitoring import sherlock_error_handler\n\n@log_performance\n@hardcoded_value_detector\n@sherlock_error_handler\ndef comprehensive_function():\n    # Performance monitored, hardcoded values detected, errors analyzed\n    max_retries = 3\n    api_endpoint = \"https://api.example.com/data\"\n    for attempt in range(max_retries):\n        try:\n            return fetch_data(api_endpoint)\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n</code></pre>"},{"location":"features/code-analysis/#manual-code-analysis","title":"Manual Code Analysis","text":"<p>Use the CodeAnalyzer class for custom analysis:</p> <pre><code>from sherlock_ai.analysis import CodeAnalyzer\n\n# Initialize with optional Groq API key for intelligent naming\nanalyzer = CodeAnalyzer(api_key=\"your-groq-api-key\")\n\n# Detect hardcoded values in source code\nwith open('my_file.py', 'r') as f:\n    source = f.read()\n\nhardcoded_values = analyzer.detect_hardcoded_values(source)\nfor value, value_type, node in hardcoded_values:\n    constant_name = analyzer.suggest_constant_name(value, value_type, \"my_function\")\n    analyzer.append_to_constants_file(constant_name, value)\n    print(f\"Found: {value} \u2192 Suggested: {constant_name}\")\n</code></pre>"},{"location":"features/code-analysis/#what-gets-detected","title":"What Gets Detected","text":""},{"location":"features/code-analysis/#string-literals","title":"String Literals","text":"<pre><code>@hardcoded_value_detector\ndef example():\n    # Detected\n    message = \"Hello, World\"  # \u2192 HELLO_WORLD_MESSAGE\n    error_msg = \"Connection failed\"  # \u2192 CONNECTION_FAILED_ERROR_MSG\n\n    # Not detected (common patterns)\n    empty = \"\"  # Ignored\n    space = \" \"  # Ignored\n    name = \"id\"  # Too short, ignored\n</code></pre>"},{"location":"features/code-analysis/#numeric-values","title":"Numeric Values","text":"<pre><code>@hardcoded_value_detector\ndef example():\n    # Detected\n    timeout = 30  # \u2192 TIMEOUT_SECONDS\n    max_size = 1024  # \u2192 MAX_SIZE\n    rate = 0.95  # \u2192 RATE_VALUE\n\n    # Not detected (common patterns)\n    zero = 0  # Ignored\n    one = 1  # Ignored\n    negative_one = -1  # Ignored\n</code></pre>"},{"location":"features/code-analysis/#urls","title":"URLs","text":"<pre><code>@hardcoded_value_detector\ndef example():\n    # Detected\n    api_url = \"https://api.example.com\"  # \u2192 API_URL\n    endpoint = \"https://service.com/v1/data\"  # \u2192 ENDPOINT_URL\n</code></pre>"},{"location":"features/code-analysis/#constants-file-management","title":"Constants File Management","text":""},{"location":"features/code-analysis/#default-location","title":"Default Location","text":"<p>Constants are written to <code>constants.py</code> in the current directory:</p> <pre><code># constants.py (auto-generated)\nAPI_URL = \"https://api.example.com\"\nTIMEOUT_SECONDS = 30\nMAX_RETRIES = 3\nPROCESSING_MESSAGE = \"Processing request\"\n</code></pre>"},{"location":"features/code-analysis/#custom-constants-file","title":"Custom Constants File","text":"<p>Specify a custom location:</p> <pre><code>from sherlock_ai.analysis import CodeAnalyzer\n\nanalyzer = CodeAnalyzer(constants_file=\"config/constants.py\")\n\n@hardcoded_value_detector(analyzer=analyzer)\ndef my_function():\n    value = 42\n</code></pre>"},{"location":"features/code-analysis/#constant-naming","title":"Constant Naming","text":""},{"location":"features/code-analysis/#intelligent-naming-with-llm","title":"Intelligent Naming (with LLM)","text":"<p>When Groq API key is configured:</p> <pre><code>import os\nos.environ[\"GROQ_API_KEY\"] = \"your-api-key\"\n\n@hardcoded_value_detector\ndef example():\n    timeout = 30  # \u2192 LLM suggests: REQUEST_TIMEOUT_SECONDS\n    url = \"https://api.example.com\"  # \u2192 LLM suggests: PRIMARY_API_ENDPOINT\n</code></pre>"},{"location":"features/code-analysis/#heuristic-naming-fallback","title":"Heuristic Naming (fallback)","text":"<p>Without LLM, uses heuristic rules:</p> <pre><code># No GROQ_API_KEY set\n@hardcoded_value_detector\ndef example():\n    timeout = 30  # \u2192 TIMEOUT_VALUE\n    url = \"https://api.example.com\"  # \u2192 URL_VALUE\n    message = \"Hello\"  # \u2192 MESSAGE_VALUE\n</code></pre>"},{"location":"features/code-analysis/#code-refactoring","title":"Code Refactoring","text":""},{"location":"features/code-analysis/#before","title":"Before","text":"<pre><code>@hardcoded_value_detector\ndef process_request():\n    url = \"https://api.example.com\"\n    timeout = 30\n    max_retries = 3\n\n    for i in range(max_retries):\n        try:\n            response = requests.get(url, timeout=timeout)\n            return response.json()\n        except requests.Timeout:\n            if i == max_retries - 1:\n                raise\n</code></pre>"},{"location":"features/code-analysis/#after","title":"After","text":"<pre><code># constants.py (created automatically)\nAPI_URL = \"https://api.example.com\"\nTIMEOUT_SECONDS = 30\nMAX_RETRIES = 3\n\n# Original file (updated automatically)\nfrom constants import API_URL, TIMEOUT_SECONDS, MAX_RETRIES\n\ndef process_request():\n    for i in range(MAX_RETRIES):\n        try:\n            response = requests.get(API_URL, timeout=TIMEOUT_SECONDS)\n            return response.json()\n        except requests.Timeout:\n            if i == MAX_RETRIES - 1:\n                raise\n</code></pre>"},{"location":"features/code-analysis/#codeanalyzer-class","title":"CodeAnalyzer Class","text":""},{"location":"features/code-analysis/#methods","title":"Methods","text":""},{"location":"features/code-analysis/#detect_hardcoded_valuessource_code","title":"<code>detect_hardcoded_values(source_code)</code>","text":"<p>Detect hardcoded values in Python source code.</p> <p>Parameters: - <code>source_code</code> (str): Python source code to analyze</p> <p>Returns: - List of tuples: <code>(value, value_type, ast_node)</code></p> <pre><code>analyzer = CodeAnalyzer()\nhardcoded = analyzer.detect_hardcoded_values(source_code)\nfor value, value_type, node in hardcoded:\n    print(f\"{value_type}: {value}\")\n</code></pre>"},{"location":"features/code-analysis/#suggest_constant_namevalue-value_type-context","title":"<code>suggest_constant_name(value, value_type, context)</code>","text":"<p>Suggest a constant name for a hardcoded value.</p> <p>Parameters: - <code>value</code>: The hardcoded value - <code>value_type</code> (str): Type of value (\"string\", \"number\", \"url\") - <code>context</code> (str): Context where value was found (e.g., function name)</p> <p>Returns: - str: Suggested constant name</p> <pre><code>name = analyzer.suggest_constant_name(\"https://api.example.com\", \"url\", \"fetch_data\")\n# Returns: \"API_ENDPOINT\" or similar\n</code></pre>"},{"location":"features/code-analysis/#append_to_constants_fileconstant_name-value","title":"<code>append_to_constants_file(constant_name, value)</code>","text":"<p>Add a constant to the constants file.</p> <p>Parameters: - <code>constant_name</code> (str): Name of the constant - <code>value</code>: Value to assign</p> <pre><code>analyzer.append_to_constants_file(\"API_URL\", \"https://api.example.com\")\n</code></pre>"},{"location":"features/code-analysis/#modify_function_codesource_code-replacements-file_path","title":"<code>modify_function_code(source_code, replacements, file_path)</code>","text":"<p>Refactor code to use constants.</p> <p>Parameters: - <code>source_code</code> (str): Original source code - <code>replacements</code> (dict): Mapping of values to constant names - <code>file_path</code> (str): Path to the file being modified</p> <pre><code>replacements = {\"https://api.example.com\": \"API_URL\", 30: \"TIMEOUT\"}\nanalyzer.modify_function_code(source_code, replacements, \"my_module.py\")\n</code></pre>"},{"location":"features/code-analysis/#configuration","title":"Configuration","text":""},{"location":"features/code-analysis/#constructor-parameters","title":"Constructor Parameters","text":"<pre><code>from sherlock_ai.analysis import CodeAnalyzer\n\nanalyzer = CodeAnalyzer(\n    api_key=\"your-groq-api-key\",  # Optional: for intelligent naming\n    constants_file=\"constants.py\"   # Optional: custom constants file path\n)\n</code></pre>"},{"location":"features/code-analysis/#environment-variables","title":"Environment Variables","text":"Variable Required Default Description <code>GROQ_API_KEY</code> No None Groq API key for LLM-powered naming"},{"location":"features/code-analysis/#best-practices","title":"Best Practices","text":""},{"location":"features/code-analysis/#1-run-on-existing-code","title":"1. Run on Existing Code","text":"<p>Apply to existing functions to clean up hardcoded values:</p> <pre><code>@hardcoded_value_detector\ndef legacy_function():\n    # This function has many hardcoded values\n    db_host = \"localhost\"\n    db_port = 5432\n    timeout = 30\n    # ... more hardcoded values\n</code></pre>"},{"location":"features/code-analysis/#2-use-in-development","title":"2. Use in Development","text":"<p>Enable during development to catch hardcoded values early:</p> <pre><code>import os\n\nif os.getenv(\"ENVIRONMENT\") == \"development\":\n    from sherlock_ai import hardcoded_value_detector\n\n    @hardcoded_value_detector\n    def new_feature():\n        # Automatically detects hardcoded values during development\n        pass\n</code></pre>"},{"location":"features/code-analysis/#3-review-generated-constants","title":"3. Review Generated Constants","text":"<p>Always review the generated constants file:</p> <pre><code># constants.py\n# Review these names and adjust if needed\nAPI_URL = \"https://api.example.com\"\nTIMEOUT_SECONDS = 30  # Consider renaming to REQUEST_TIMEOUT_SECONDS\n</code></pre>"},{"location":"features/code-analysis/#4-combine-with-code-reviews","title":"4. Combine with Code Reviews","text":"<p>Use as part of code review process:</p> <pre><code># Before committing\n@hardcoded_value_detector\ndef new_function():\n    # Check for any hardcoded values before review\n    pass\n</code></pre>"},{"location":"features/code-analysis/#use-cases","title":"Use Cases","text":"<ul> <li>Code Quality Improvement: Systematically eliminate magic numbers and strings</li> <li>Legacy Code Modernization: Refactor old code with hardcoded values</li> <li>Configuration Extraction: Identify values that should be configurable</li> <li>Maintenance: Make code more maintainable by using named constants</li> <li>Documentation: Constants serve as self-documenting code</li> <li>Testing: Easier to mock and test with named constants</li> </ul>"},{"location":"features/code-analysis/#limitations","title":"Limitations","text":""},{"location":"features/code-analysis/#ast-based-detection","title":"AST-Based Detection","text":"<p>Only detects values in the AST: - Cannot detect values in comments - Cannot detect values in docstrings (intentionally) - Cannot detect dynamically generated values</p>"},{"location":"features/code-analysis/#heuristic-filtering","title":"Heuristic Filtering","text":"<p>Some values are intentionally ignored: - Empty strings, single characters - Common numbers (0, 1, -1) - Very short strings (&lt; 3 characters) - Common patterns (None, True, False)</p>"},{"location":"features/code-analysis/#manual-review-required","title":"Manual Review Required","text":"<p>Always review suggestions: - Not all hardcoded values need to be constants - Some values are intentionally literal - Context matters for naming</p>"},{"location":"features/code-analysis/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/code-analysis/#constants-file-not-created","title":"Constants File Not Created","text":"<p>If <code>constants.py</code> isn't created:</p> <ol> <li>Check file permissions in the directory</li> <li>Verify the decorator is actually executed</li> <li>Check that hardcoded values were detected</li> </ol>"},{"location":"features/code-analysis/#constants-not-being-used","title":"Constants Not Being Used","text":"<p>If refactoring doesn't occur:</p> <ol> <li>Check that the source file is writable</li> <li>Verify the function contains detectable hardcoded values</li> <li>Look for AST parsing errors in logs</li> </ol>"},{"location":"features/code-analysis/#poor-constant-names","title":"Poor Constant Names","text":"<p>If generated names are not ideal:</p> <ol> <li>Set <code>GROQ_API_KEY</code> for intelligent naming</li> <li>Manually edit <code>constants.py</code> after generation</li> <li>Provide better context in function names</li> </ol>"},{"location":"features/code-analysis/#next-steps","title":"Next Steps","text":"<ul> <li>Error Analysis - AI-powered error insights</li> <li>Configuration - Configure analysis behavior</li> <li>Examples - See real-world examples</li> <li>API Reference - Complete API reference</li> </ul>"},{"location":"features/error-analysis/","title":"Error Analysis","text":"<p>AI-powered error analysis with automatic probable cause detection and storage. The <code>@sherlock_error_handler</code> decorator automatically analyzes errors using LLM and stores insights in MongoDB or sends them to a centralized backend API.</p>"},{"location":"features/error-analysis/#decorator-usage","title":"Decorator Usage","text":""},{"location":"features/error-analysis/#basic-example","title":"Basic Example","text":"<pre><code>from sherlock_ai.monitoring import sherlock_error_handler\nimport os\n\n# Optional: Set up MongoDB connection\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\n\n@sherlock_error_handler\ndef risky_function():\n    # Any errors will be automatically analyzed and stored\n    result = 1 / 0  # This will trigger error analysis\n    return result\n\n# When an error occurs:\n# 1. Error is caught and analyzed by AI for probable cause\n# 2. Insight is stored in MongoDB (sherlock-meta.error-insights collection)\n# 3. Detailed information is logged\n# 4. Error is re-raised for normal handling\n</code></pre>"},{"location":"features/error-analysis/#with-other-decorators","title":"With Other Decorators","text":"<p>Combine with performance monitoring:</p> <pre><code>from sherlock_ai import log_performance\nfrom sherlock_ai.monitoring import sherlock_error_handler\n\n@log_performance\n@sherlock_error_handler\ndef monitored_function():\n    # Tracks both performance AND analyzes errors\n    try:\n        result = complex_operation()\n        return result\n    except Exception as e:\n        # Error will be analyzed before being raised\n        raise\n</code></pre>"},{"location":"features/error-analysis/#async-functions","title":"Async Functions","text":"<p>Works with async/await:</p> <pre><code>@sherlock_error_handler\nasync def async_operation():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com\")\n        if response.status_code != 200:\n            raise ValueError(f\"API returned {response.status_code}\")\n        return response.json()\n</code></pre>"},{"location":"features/error-analysis/#storage-options","title":"Storage Options","text":""},{"location":"features/error-analysis/#mongodb-storage","title":"MongoDB Storage","text":"<p>Store error insights in MongoDB:</p> <pre><code>import os\n\n# Configure MongoDB\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\n\n@sherlock_error_handler\ndef function_with_errors():\n    # Errors stored in: database: sherlock-meta, collection: error-insights\n    raise ValueError(\"Something went wrong\")\n</code></pre> <p>Error insights are stored with: - Function name and module - Error message and type - Stack trace - AI-generated probable cause - Timestamp - Request ID (if available)</p>"},{"location":"features/error-analysis/#api-client-storage","title":"API Client Storage","text":"<p>Send error insights to centralized backend:</p> <pre><code>import os\n\n# Configure API client\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"your-api-key-here\"\n\n@sherlock_error_handler\ndef function_with_errors():\n    # Errors sent to: POST /v1/logs/injest-error-insights\n    raise ValueError(\"Something went wrong\")\n</code></pre>"},{"location":"features/error-analysis/#manual-storage","title":"Manual Storage","text":"<p>Use the storage clients directly:</p> <pre><code>from sherlock_ai.storage import MongoManager, ApiClient\n\n# MongoDB\nmongo = MongoManager(\"mongodb://localhost:27017\")\nerror_data = {\n    \"function_name\": \"my_function\",\n    \"error_message\": \"Division by zero\",\n    \"stack_trace\": \"...\",\n    \"probable_cause\": \"AI analysis result\"\n}\nmongo.save(error_data)\n\n# API Client\napi_client = ApiClient()\napi_client.post_error_insights(error_data)\n</code></pre>"},{"location":"features/error-analysis/#error-insight-format","title":"Error Insight Format","text":"<p>Stored error insights include:</p> <pre><code>{\n    \"timestamp\": \"2025-01-01T12:34:56\",\n    \"function_name\": \"my_module.risky_function\",\n    \"error_type\": \"ZeroDivisionError\",\n    \"error_message\": \"division by zero\",\n    \"stack_trace\": \"Traceback (most recent call last):\\n  File ...\",\n    \"probable_cause\": \"The function attempts to divide by zero on line 42. This occurs because the divisor variable is not validated before the operation.\",\n    \"request_id\": \"a1b2c3d4\",\n    \"module\": \"my_module\",\n    \"line_number\": 42\n}\n</code></pre>"},{"location":"features/error-analysis/#ai-powered-analysis","title":"AI-Powered Analysis","text":"<p>The error handler uses LLM to analyze:</p> <ol> <li>Error Context: Function name, line number, error type</li> <li>Stack Trace: Full traceback analysis</li> <li>Code Context: Surrounding code (if available)</li> <li>Probable Cause: Human-readable explanation</li> </ol> <p>Example analysis output:</p> <pre><code>Probable Cause: The function attempts to divide by zero on line 42. \nThis occurs because the 'count' variable is initialized to 0 and \nnever modified before being used as a divisor. Consider adding \nvalidation to check if count &gt; 0 before the division operation.\n</code></pre>"},{"location":"features/error-analysis/#configuration","title":"Configuration","text":""},{"location":"features/error-analysis/#mongodb-configuration","title":"MongoDB Configuration","text":"<pre><code>from sherlock_ai.storage import MongoManager\n\n# Initialize with custom URI\nmongo = MongoManager(\"mongodb://user:pass@localhost:27017/custom_db\")\n\n# Check if MongoDB is available\nif mongo.enabled:\n    print(\"MongoDB storage is configured\")\n</code></pre>"},{"location":"features/error-analysis/#api-client-configuration","title":"API Client Configuration","text":"<pre><code>from sherlock_ai.storage import ApiClient\n\n# Required: API key\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"your-api-key\"\n\n# Optional: Custom base URL\nos.environ[\"SHERLOCK_AI_API_BASE_URL\"] = \"https://your-backend.com/api/v1\"\n\n# Initialize\napi_client = ApiClient()\n</code></pre>"},{"location":"features/error-analysis/#environment-variables","title":"Environment Variables","text":"Variable Required Default Description <code>MONGO_URI</code> No None MongoDB connection string <code>SHERLOCK_AI_API_KEY</code> For API None API authentication key <code>SHERLOCK_AI_API_BASE_URL</code> No http://localhost:8000/v1/logs API base URL <code>GROQ_API_KEY</code> No None Groq API key for LLM analysis"},{"location":"features/error-analysis/#best-practices","title":"Best Practices","text":""},{"location":"features/error-analysis/#1-use-with-critical-functions","title":"1. Use with Critical Functions","text":"<p>Apply to functions where errors need detailed analysis:</p> <pre><code>@sherlock_error_handler\ndef critical_payment_processing():\n    # Errors here need thorough investigation\n    process_payment(amount, card_details)\n</code></pre>"},{"location":"features/error-analysis/#2-combine-with-logging","title":"2. Combine with Logging","text":"<p>Use with standard logging for complete visibility:</p> <pre><code>from sherlock_ai import get_logger\nfrom sherlock_ai.monitoring import sherlock_error_handler\n\nlogger = get_logger(__name__)\n\n@sherlock_error_handler\ndef monitored_function():\n    try:\n        logger.info(\"Starting operation\")\n        result = risky_operation()\n        logger.info(\"Operation completed\")\n        return result\n    except Exception as e:\n        logger.error(f\"Operation failed: {e}\")\n        raise  # Error will be analyzed before re-raising\n</code></pre>"},{"location":"features/error-analysis/#3-dont-catch-errors-inside","title":"3. Don't Catch Errors Inside","text":"<p>Let the decorator handle error catching:</p> <pre><code># \u274c Don't do this\n@sherlock_error_handler\ndef bad_example():\n    try:\n        risky_operation()\n    except Exception:\n        pass  # Decorator won't see this error\n\n# \u2705 Do this instead\n@sherlock_error_handler\ndef good_example():\n    risky_operation()  # Let decorator catch and analyze\n</code></pre>"},{"location":"features/error-analysis/#4-use-for-production-monitoring","title":"4. Use for Production Monitoring","text":"<p>Enable in production for automatic error tracking:</p> <pre><code>import os\n\nif os.getenv(\"ENVIRONMENT\") == \"production\":\n    os.environ[\"MONGO_URI\"] = os.getenv(\"PROD_MONGO_URI\")\n    os.environ[\"SHERLOCK_AI_API_KEY\"] = os.getenv(\"PROD_API_KEY\")\n\n@sherlock_error_handler\ndef production_function():\n    # Errors automatically tracked in production\n    return process_data()\n</code></pre>"},{"location":"features/error-analysis/#use-cases","title":"Use Cases","text":"<ul> <li>Production Error Tracking: Automatic error collection and analysis</li> <li>Debugging: AI-powered insights into error causes</li> <li>Error Pattern Recognition: Identify recurring issues</li> <li>Microservices: Distributed error tracking with request IDs</li> <li>API Monitoring: Track and analyze API errors</li> <li>Data Pipeline Failures: Analyze ETL pipeline errors</li> <li>Critical Operations: Deep analysis for payment, auth, etc.</li> </ul>"},{"location":"features/error-analysis/#error-handling-flow","title":"Error Handling Flow","text":"<pre><code>Function Call\n    \u2193\nDecorator Wraps Execution\n    \u2193\nError Occurs\n    \u2193\nCapture Error Details (type, message, traceback)\n    \u2193\nExtract Function Context (name, module, line)\n    \u2193\nAI Analysis (probable cause using LLM)\n    \u2193\nStore Insight (MongoDB or API)\n    \u2193\nLog Error Details\n    \u2193\nRe-raise Original Error\n    \u2193\nNormal Error Handling\n</code></pre>"},{"location":"features/error-analysis/#limitations","title":"Limitations","text":""},{"location":"features/error-analysis/#llm-api-required","title":"LLM API Required","text":"<p>Error analysis requires LLM API access: - Groq API (default) - Configure with <code>GROQ_API_KEY</code> environment variable - Without API key, basic error logging still works</p>"},{"location":"features/error-analysis/#storage-optional","title":"Storage Optional","text":"<p>Storage is optional: - Without MongoDB or API client, errors are still logged - Configure storage for persistent error tracking - Use both storage options for redundancy</p>"},{"location":"features/error-analysis/#performance-impact","title":"Performance Impact","text":"<p>AI analysis adds latency: - Only occurs on errors (not normal execution) - Async analysis recommended for high-traffic apps - Consider rate limiting for error analysis</p>"},{"location":"features/error-analysis/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/error-analysis/#no-insights-stored","title":"No Insights Stored","text":"<p>If error insights aren't being stored:</p> <ol> <li> <p>Check MongoDB connection: <pre><code>from sherlock_ai.storage import MongoManager\nmongo = MongoManager()\nprint(f\"MongoDB enabled: {mongo.enabled}\")\n</code></pre></p> </li> <li> <p>Check API client configuration: <pre><code>import os\nprint(f\"API Key set: {'SHERLOCK_AI_API_KEY' in os.environ}\")\n</code></pre></p> </li> </ol>"},{"location":"features/error-analysis/#ai-analysis-failing","title":"AI Analysis Failing","text":"<p>If LLM analysis fails:</p> <ol> <li>Verify Groq API key is set</li> <li>Check API rate limits</li> <li>Errors are still logged even if analysis fails</li> </ol>"},{"location":"features/error-analysis/#errors-not-being-caught","title":"Errors Not Being Caught","text":"<p>Ensure errors are not caught before decorator:</p> <pre><code># \u2705 Correct\n@sherlock_error_handler\ndef function():\n    risky_operation()  # Error caught by decorator\n\n# \u274c Incorrect\n@sherlock_error_handler\ndef function():\n    try:\n        risky_operation()\n    except:\n        pass  # Decorator never sees error\n</code></pre>"},{"location":"features/error-analysis/#next-steps","title":"Next Steps","text":"<ul> <li>MongoDB Storage - MongoDB integration examples</li> <li>API Client - HTTP-based storage examples</li> <li>Performance Insights - Related decorator</li> <li>Configuration - Environment configuration</li> </ul>"},{"location":"features/memory-monitoring/","title":"Memory Monitoring","text":"<p>Track Python memory usage with detailed heap analysis and tracemalloc integration. The <code>@monitor_memory</code> decorator and <code>MemoryTracker</code> context manager help identify memory leaks and optimize memory-intensive operations.</p>"},{"location":"features/memory-monitoring/#decorator-usage","title":"Decorator Usage","text":""},{"location":"features/memory-monitoring/#basic-example","title":"Basic Example","text":"<pre><code>from sherlock_ai import monitor_memory\n\n@monitor_memory\ndef memory_intensive_function():\n    # Allocate memory\n    data = [i * i for i in range(1000000)]\n    processed = sum(data)\n    return processed\n\n# Logs: MEMORY | my_module.memory_intensive_function | SUCCESS | 0.245s | Current: 45.67MB | Change: +12.34MB | Traced: 38.92MB (Peak: 52.18MB)\n</code></pre>"},{"location":"features/memory-monitoring/#advanced-tracking-with-tracemalloc","title":"Advanced Tracking with tracemalloc","text":"<p>Enable detailed Python memory tracking:</p> <pre><code>@monitor_memory(trace_malloc=True, min_duration=0.1)\ndef critical_memory_function():\n    # Only logs if execution time &gt;= 0.1 seconds\n    # Includes detailed Python memory tracking\n    large_dict = {i: str(i) * 100 for i in range(10000)}\n    return len(large_dict)\n\n# Logs: MEMORY | my_module.critical_memory_function | SUCCESS | 0.261s | Current: 57.66MB | Change: +1.64MB | Traced: 24.33KB (Peak: 30.33KB)\n</code></pre>"},{"location":"features/memory-monitoring/#async-functions","title":"Async Functions","text":"<p>Works with async/await:</p> <pre><code>@monitor_memory(trace_malloc=True)\nasync def async_data_processing():\n    # Process data asynchronously\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com/large-data\")\n        data = response.json()\n        # Process large dataset\n        return process_data(data)\n</code></pre>"},{"location":"features/memory-monitoring/#context-manager","title":"Context Manager","text":"<p>Monitor memory usage in specific code blocks:</p> <pre><code>from sherlock_ai import MemoryTracker\n\ndef data_pipeline():\n    # Initialization\n    config = load_config()\n\n    # Monitor this specific block\n    with MemoryTracker(\"data_processing\"):\n        # Your memory-intensive code here\n        data = load_large_dataset()\n        processed = process_data(data)\n\n    # Cleanup\n    save_results(processed)\n\n# Logs: MEMORY | data_processing | SUCCESS | 1.234s | Current: 125.45MB | Change: +45.23MB | Traced: 42.18MB (Peak: 48.92MB)\n</code></pre>"},{"location":"features/memory-monitoring/#with-minimum-duration","title":"With Minimum Duration","text":"<p>Only log if execution or memory change exceeds thresholds:</p> <pre><code>with MemoryTracker(\"cache_operation\", min_duration=0.01, trace_malloc=True):\n    # Only logs if this takes more than 10ms\n    cache.set(key, large_value)\n</code></pre>"},{"location":"features/memory-monitoring/#parameters","title":"Parameters","text":""},{"location":"features/memory-monitoring/#monitor_memory-decorator","title":"<code>@monitor_memory</code> Decorator","text":"Parameter Type Default Description <code>min_duration</code> float 0.0 Only log if execution time &gt;= this value in seconds <code>log_level</code> str \"INFO\" Log level to use (INFO, DEBUG, WARNING, etc.) <code>trace_malloc</code> bool True Use tracemalloc for detailed Python memory tracking"},{"location":"features/memory-monitoring/#memorytracker-context-manager","title":"<code>MemoryTracker</code> Context Manager","text":"Parameter Type Default Description <code>name</code> str Required Name identifier for the operation <code>min_duration</code> float 0.0 Only log if execution time &gt;= this value in seconds <code>trace_malloc</code> bool True Use tracemalloc for detailed tracking"},{"location":"features/memory-monitoring/#log-output-format","title":"Log Output Format","text":"<p>Memory logs follow this format:</p> <pre><code>{timestamp} - {request_id} - MonitoringLogger - {level} - MEMORY | {function_name} | {STATUS} | {execution_time}s | Current: {current_memory} | Change: {memory_change} | Traced: {traced_memory} (Peak: {peak_memory})\n</code></pre>"},{"location":"features/memory-monitoring/#examples","title":"Examples","text":"<pre><code>2025-07-05 19:19:11 - 07ca74ed - MonitoringLogger - INFO - MEMORY | tests.test_fastapi.health_check | SUCCESS | 0.261s | Current: 57.66MB | Change: +1.64MB | Traced: 24.33KB (Peak: 30.33KB)\n\n2025-07-05 21:15:22 - - - MonitoringLogger - INFO - MEMORY | data_processor | SUCCESS | 0.245s | Current: 45.67MB | Change: +12.34MB\n\n2025-07-05 19:20:15 - 2c4774b0 - MonitoringLogger - INFO - MEMORY | load_large_file | SUCCESS | 2.156s | Current: 256.89MB | Change: +128.45MB | Traced: 125.67MB (Peak: 145.23MB)\n</code></pre>"},{"location":"features/memory-monitoring/#understanding-memory-metrics","title":"Understanding Memory Metrics","text":""},{"location":"features/memory-monitoring/#current-memory","title":"Current Memory","text":"<p>The total memory currently used by the Python process (RSS - Resident Set Size).</p> <pre><code>@monitor_memory\ndef example():\n    pass\n# Current: 57.66MB - total memory used by the process\n</code></pre>"},{"location":"features/memory-monitoring/#memory-change","title":"Memory Change","text":"<p>The difference in memory usage before and after function execution.</p> <pre><code>@monitor_memory\ndef allocate_memory():\n    data = [0] * 10000000  # Allocates ~40MB\n# Change: +40.23MB - memory increase from this function\n</code></pre>"},{"location":"features/memory-monitoring/#traced-memory-tracemalloc","title":"Traced Memory (tracemalloc)","text":"<p>When <code>trace_malloc=True</code>, shows memory allocated specifically by Python objects during execution.</p> <pre><code>@monitor_memory(trace_malloc=True)\ndef create_objects():\n    objects = [{\"id\": i} for i in range(100000)]\n# Traced: 8.45MB (Peak: 10.23MB) - Python object memory\n</code></pre>"},{"location":"features/memory-monitoring/#best-practices","title":"Best Practices","text":""},{"location":"features/memory-monitoring/#1-enable-tracemalloc-for-detailed-tracking","title":"1. Enable tracemalloc for Detailed Tracking","text":"<p>For memory leak investigation:</p> <pre><code>@monitor_memory(trace_malloc=True)\ndef investigate_memory_leak():\n    # tracemalloc shows exact Python object allocations\n    return process_data()\n</code></pre>"},{"location":"features/memory-monitoring/#2-use-minimum-duration-thresholds","title":"2. Use Minimum Duration Thresholds","text":"<p>Avoid noise from quick operations:</p> <pre><code>@monitor_memory(min_duration=0.1)  # Only log if &gt; 100ms\ndef frequent_operation():\n    # Only logs if slow or memory-intensive\n    return quick_calculation()\n</code></pre>"},{"location":"features/memory-monitoring/#3-monitor-critical-sections-only","title":"3. Monitor Critical Sections Only","text":"<p>Use context managers for targeted monitoring:</p> <pre><code>def full_pipeline():\n    config = load_config()  # Don't monitor\n\n    with MemoryTracker(\"model_training\"):\n        # Monitor only the memory-intensive part\n        model = train_large_model(data)\n\n    save_model(model)  # Don't monitor\n</code></pre>"},{"location":"features/memory-monitoring/#4-combine-with-performance-monitoring","title":"4. Combine with Performance Monitoring","text":"<p>Get complete insights:</p> <pre><code>from sherlock_ai import log_performance, monitor_memory\n\n@log_performance\n@monitor_memory(trace_malloc=True)\ndef comprehensive_monitoring():\n    # Tracks both time AND memory\n    return process_large_dataset()\n</code></pre>"},{"location":"features/memory-monitoring/#memory-monitoring-utilities","title":"Memory Monitoring Utilities","text":"<p>Access low-level memory monitoring:</p> <pre><code>from sherlock_ai import ResourceMonitor\n\n# Capture current memory snapshot\nmemory_snapshot = ResourceMonitor.capture_memory()\nprint(f\"Current memory: {ResourceMonitor.format_bytes(memory_snapshot.current_size)}\")\nprint(f\"Memory change: {ResourceMonitor.format_bytes(memory_snapshot.size_diff)}\")\n\n# Format bytes in human-readable format\nformatted = ResourceMonitor.format_bytes(1024 * 1024 * 512)  # \"512.00MB\"\n</code></pre>"},{"location":"features/memory-monitoring/#use-cases","title":"Use Cases","text":"<ul> <li>Memory Leak Detection: Monitor memory growth over time</li> <li>ML Model Training: Track memory during model training</li> <li>Data Processing: Monitor memory in ETL pipelines</li> <li>Cache Management: Optimize cache size based on memory usage</li> <li>Image/Video Processing: Monitor memory in media processing</li> <li>Large Dataset Operations: Track memory when handling large datasets</li> </ul>"},{"location":"features/memory-monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/memory-monitoring/#high-memory-usage","title":"High Memory Usage","text":"<p>If you see unexpectedly high memory usage:</p> <ol> <li>Enable <code>trace_malloc=True</code> to see Python object allocations</li> <li>Look for the \"Peak\" value - it shows the maximum memory used</li> <li>Check for large data structures that aren't being garbage collected</li> </ol>"},{"location":"features/memory-monitoring/#memory-not-decreasing","title":"Memory Not Decreasing","text":"<p>If memory doesn't decrease after function exit:</p> <ul> <li>Python doesn't always return memory to OS immediately</li> <li>Enable tracemalloc to see if Python objects are properly freed</li> <li>Use <code>gc.collect()</code> to force garbage collection for testing</li> </ul>"},{"location":"features/memory-monitoring/#tracemalloc-overhead","title":"tracemalloc Overhead","text":"<p>tracemalloc adds ~10-20% overhead:</p> <ul> <li>Use <code>trace_malloc=True</code> only when needed</li> <li>Disable in production for high-frequency operations</li> <li>Enable temporarily for debugging memory issues</li> </ul>"},{"location":"features/memory-monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Resource Monitoring - Monitor CPU, I/O, and network alongside memory</li> <li>Performance Monitoring - Track execution times</li> <li>Examples - See real-world memory monitoring examples</li> <li>API Reference - Complete decorator reference</li> </ul>"},{"location":"features/performance-monitoring/","title":"Performance Monitoring","text":"<p>Track execution times of functions and code blocks with minimal overhead. The <code>@log_performance</code> decorator and <code>PerformanceTimer</code> context manager make it easy to identify slow operations and optimize your code.</p>"},{"location":"features/performance-monitoring/#decorator-usage","title":"Decorator Usage","text":""},{"location":"features/performance-monitoring/#basic-example","title":"Basic Example","text":"<pre><code>from sherlock_ai import log_performance, get_logger\n\nlogger = get_logger(__name__)\n\n@log_performance\ndef process_data():\n    # Your code here\n    data = fetch_from_database()\n    result = transform_data(data)\n    return result\n\n# Logs: PERFORMANCE | my_module.process_data | SUCCESS | 0.234s\n</code></pre>"},{"location":"features/performance-monitoring/#with-parameters","title":"With Parameters","text":"<p>Configure the decorator for specific needs:</p> <pre><code>@log_performance(min_duration=0.1, include_args=True, log_level=\"DEBUG\")\ndef slow_database_query(user_id, limit=10):\n    # Only logs if execution time &gt;= 0.1 seconds\n    # Includes function arguments in the log\n    query = f\"SELECT * FROM users WHERE id={user_id} LIMIT {limit}\"\n    return execute_query(query)\n\n# Logs: PERFORMANCE | my_module.slow_database_query | SUCCESS | 0.156s | Args: ('user123',) | Kwargs: {'limit': 10}\n</code></pre>"},{"location":"features/performance-monitoring/#async-functions","title":"Async Functions","text":"<p>Works seamlessly with async/await:</p> <pre><code>import httpx\n\n@log_performance\nasync def async_api_call():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com/data\")\n        return response.json()\n\n# Usage\nresult = await async_api_call()\n# Logs: PERFORMANCE | my_module.async_api_call | SUCCESS | 0.523s\n</code></pre>"},{"location":"features/performance-monitoring/#context-manager","title":"Context Manager","text":"<p>Monitor specific code blocks without decorating entire functions:</p> <pre><code>from sherlock_ai.performance import PerformanceTimer\n\ndef complex_operation():\n    # Some initialization\n    config = load_config()\n\n    # Monitor only this block\n    with PerformanceTimer(\"database_operation\"):\n        connection = database.connect()\n        result = connection.execute(\"SELECT * FROM large_table\")\n        connection.close()\n\n    # More processing\n    return process_result(result)\n\n# Logs: PERFORMANCE | database_operation | SUCCESS | 0.234s\n</code></pre>"},{"location":"features/performance-monitoring/#with-minimum-duration","title":"With Minimum Duration","text":"<p>Only log if execution exceeds a threshold:</p> <pre><code>with PerformanceTimer(\"cache_check\", min_duration=0.01):\n    # Only logs if this takes more than 10ms\n    value = cache.get(key)\n</code></pre>"},{"location":"features/performance-monitoring/#manual-time-logging","title":"Manual Time Logging","text":"<p>For more control, use the low-level API:</p> <pre><code>from sherlock_ai.performance import log_execution_time\nimport time\n\ndef custom_operation():\n    start_time = time.time()\n    try:\n        # Your code here\n        result = complex_calculation()\n        log_execution_time(\"complex_calculation\", start_time, success=True)\n        return result\n    except Exception as e:\n        log_execution_time(\"complex_calculation\", start_time, success=False, error=str(e))\n        raise\n</code></pre>"},{"location":"features/performance-monitoring/#parameters","title":"Parameters","text":""},{"location":"features/performance-monitoring/#log_performance-decorator","title":"<code>@log_performance</code> Decorator","text":"Parameter Type Default Description <code>min_duration</code> float 0.0 Only log if execution time &gt;= this value in seconds <code>include_args</code> bool False Include function arguments in the log <code>log_level</code> str \"INFO\" Log level to use (INFO, DEBUG, WARNING, etc.)"},{"location":"features/performance-monitoring/#performancetimer-context-manager","title":"<code>PerformanceTimer</code> Context Manager","text":"Parameter Type Default Description <code>name</code> str Required Name identifier for the operation <code>min_duration</code> float 0.0 Only log if execution time &gt;= this value in seconds"},{"location":"features/performance-monitoring/#log_execution_time-function","title":"<code>log_execution_time</code> Function","text":"Parameter Type Default Description <code>name</code> str Required Name identifier for the operation <code>start_time</code> float Required Start time from <code>time.time()</code> <code>success</code> bool True Whether the operation succeeded <code>error</code> str None Error message if operation failed"},{"location":"features/performance-monitoring/#log-output-format","title":"Log Output Format","text":"<p>Performance logs follow this format:</p> <pre><code>{timestamp} - {request_id} - PerformanceLogger - {level} - PERFORMANCE | {function_name} | {STATUS} | {execution_time}s | {additional_info}\n</code></pre>"},{"location":"features/performance-monitoring/#examples","title":"Examples","text":"<pre><code>2025-07-05 19:19:11 - 07ca74ed - PerformanceLogger - INFO - PERFORMANCE | tests.test_fastapi.health_check | SUCCESS | 0.262s\n\n2025-07-05 21:13:03 - 2c4774b0 - PerformanceLogger - INFO - PERFORMANCE | my_module.api_call | ERROR | 2.456s | Connection timeout\n\n2025-07-05 19:20:15 - - - PerformanceLogger - INFO - PERFORMANCE | database_query | SUCCESS | 0.089s | Args: ('user123',) | Kwargs: {'limit': 10}\n</code></pre>"},{"location":"features/performance-monitoring/#best-practices","title":"Best Practices","text":""},{"location":"features/performance-monitoring/#1-use-minimum-duration-for-frequent-operations","title":"1. Use Minimum Duration for Frequent Operations","text":"<p>For functions called frequently, set a minimum duration to avoid log noise:</p> <pre><code>@log_performance(min_duration=0.05)  # Only log if &gt; 50ms\ndef cache_lookup(key):\n    return cache.get(key)\n</code></pre>"},{"location":"features/performance-monitoring/#2-include-arguments-for-debugging","title":"2. Include Arguments for Debugging","text":"<p>Enable <code>include_args</code> when you need to correlate performance with input:</p> <pre><code>@log_performance(include_args=True)\ndef process_user_request(user_id, action):\n    # If this is slow, you'll know which user and action\n    return perform_action(user_id, action)\n</code></pre>"},{"location":"features/performance-monitoring/#3-use-context-managers-for-partial-monitoring","title":"3. Use Context Managers for Partial Monitoring","text":"<p>When you only want to monitor part of a function:</p> <pre><code>def full_operation():\n    setup()  # Don't monitor this\n\n    with PerformanceTimer(\"critical_section\"):\n        # Only monitor this expensive part\n        result = expensive_operation()\n\n    cleanup()  # Don't monitor this\n    return result\n</code></pre>"},{"location":"features/performance-monitoring/#4-combine-with-other-decorators","title":"4. Combine with Other Decorators","text":"<p>Stack with memory and resource monitoring for comprehensive insights:</p> <pre><code>from sherlock_ai import log_performance, monitor_memory, monitor_resources\n\n@log_performance\n@monitor_memory\n@monitor_resources(include_io=True)\ndef comprehensive_monitoring():\n    # Full monitoring of this function\n    return process_large_dataset()\n</code></pre>"},{"location":"features/performance-monitoring/#use-cases","title":"Use Cases","text":"<ul> <li>API Endpoint Monitoring: Track response times for all API endpoints</li> <li>Database Query Optimization: Identify slow queries</li> <li>Algorithm Benchmarking: Compare performance of different implementations</li> <li>Microservices: Track execution times across service boundaries</li> <li>Batch Processing: Monitor job execution times</li> <li>Cache Performance: Measure cache hit/miss latencies</li> </ul>"},{"location":"features/performance-monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Memory Monitoring - Track memory usage alongside performance</li> <li>Resource Monitoring - Monitor CPU, I/O, and network</li> <li>Configuration - Customize log output and rotation</li> <li>Examples - See real-world integration examples</li> </ul>"},{"location":"features/resource-monitoring/","title":"Resource Monitoring","text":"<p>Monitor comprehensive system resources including CPU, memory, I/O, and network usage during function execution. The <code>@monitor_resources</code> decorator and <code>ResourceTracker</code> context manager provide complete visibility into your application's resource consumption.</p>"},{"location":"features/resource-monitoring/#decorator-usage","title":"Decorator Usage","text":""},{"location":"features/resource-monitoring/#basic-example","title":"Basic Example","text":"<pre><code>from sherlock_ai import monitor_resources\n\n@monitor_resources\ndef resource_intensive_function():\n    # Monitors CPU, memory, and threads\n    result = sum(i * i for i in range(1000000))\n    return result\n\n# Logs: RESOURCES | my_module.resource_intensive_function | SUCCESS | 0.156s | CPU: 25.4% | Memory: 128.45MB (+5.23MB) | Threads: 12\n</code></pre>"},{"location":"features/resource-monitoring/#with-io-monitoring","title":"With I/O Monitoring","text":"<p>Include disk I/O statistics:</p> <pre><code>@monitor_resources(include_io=True)\ndef file_processing():\n    with open('large_file.txt', 'r') as f:\n        data = f.read()\n    processed = process_data(data)\n    with open('output.txt', 'w') as f:\n        f.write(processed)\n    return len(processed)\n\n# Logs: RESOURCES | my_module.file_processing | SUCCESS | 0.234s | CPU: 15.2% | Memory: 95.67MB (+0.12MB) | Threads: 8 | I/O: R:45.23MB W:12.34MB\n</code></pre>"},{"location":"features/resource-monitoring/#with-network-monitoring","title":"With Network Monitoring","text":"<p>Include network statistics:</p> <pre><code>import requests\n\n@monitor_resources(include_io=True, include_network=True)\ndef api_call_function():\n    # Monitors CPU, memory, I/O, network, and threads\n    response = requests.get(\"https://api.example.com/data\")\n    return response.json()\n\n# Logs: RESOURCES | my_module.api_call_function | SUCCESS | 0.523s | CPU: 10.5% | Memory: 85.34MB (+2.15MB) | Threads: 10 | I/O: R:1.23MB W:0.05MB | Network: Sent:2.34KB Recv:125.67KB\n</code></pre>"},{"location":"features/resource-monitoring/#async-functions","title":"Async Functions","text":"<p>Works seamlessly with async/await:</p> <pre><code>import httpx\n\n@monitor_resources(include_network=True)\nasync def async_api_call():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com/data\")\n        return response.json()\n</code></pre>"},{"location":"features/resource-monitoring/#context-manager","title":"Context Manager","text":"<p>Monitor specific code blocks:</p> <pre><code>from sherlock_ai import ResourceTracker\n\ndef database_operation():\n    # Setup\n    config = load_config()\n\n    # Monitor only this block\n    with ResourceTracker(\"database_operation\", include_io=True):\n        connection = database.connect()\n        result = connection.execute(\"SELECT * FROM large_table\")\n        connection.close()\n\n    # Processing\n    return process_result(result)\n\n# Logs: RESOURCES | database_operation | SUCCESS | 0.145s | CPU: 20.3% | Memory: 112.56MB (+3.45MB) | Threads: 9 | I/O: R:25.67MB W:0.12MB\n</code></pre>"},{"location":"features/resource-monitoring/#parameters","title":"Parameters","text":""},{"location":"features/resource-monitoring/#monitor_resources-decorator","title":"<code>@monitor_resources</code> Decorator","text":"Parameter Type Default Description <code>min_duration</code> float 0.0 Only log if execution time &gt;= this value in seconds <code>log_level</code> str \"INFO\" Log level to use (INFO, DEBUG, WARNING, etc.) <code>include_io</code> bool True Include disk I/O statistics <code>include_network</code> bool False Include network statistics"},{"location":"features/resource-monitoring/#resourcetracker-context-manager","title":"<code>ResourceTracker</code> Context Manager","text":"Parameter Type Default Description <code>name</code> str Required Name identifier for the operation <code>min_duration</code> float 0.0 Only log if execution time &gt;= this value in seconds <code>include_io</code> bool True Include I/O statistics <code>include_network</code> bool False Include network statistics"},{"location":"features/resource-monitoring/#log-output-format","title":"Log Output Format","text":"<p>Resource logs follow this format:</p> <pre><code>{timestamp} - {request_id} - MonitoringLogger - {level} - RESOURCES | {function_name} | {STATUS} | {execution_time}s | CPU: {cpu_percent}% | Memory: {memory_usage} ({memory_change}) | Threads: {thread_count} | I/O: R:{read_bytes} W:{write_bytes} | Network: Sent:{sent_bytes} Recv:{recv_bytes}\n</code></pre>"},{"location":"features/resource-monitoring/#examples","title":"Examples","text":"<pre><code>2025-07-05 19:19:11 - 07ca74ed - MonitoringLogger - INFO - RESOURCES | tests.test_fastapi.health_check | SUCCESS | 0.144s | CPU: 59.3% | Memory: 57.66MB (+1.63MB) | Threads: 9 | I/O: R:0.00B W:414.00B\n\n2025-07-05 21:13:03 - 2c4774b0 - MonitoringLogger - INFO - RESOURCES | api_handler | SUCCESS | 0.156s | CPU: 25.4% | Memory: 128.45MB (+5.23MB) | Threads: 12 | I/O: R:2.34MB W:1.12MB\n\n2025-07-05 19:25:30 - - - MonitoringLogger - INFO - RESOURCES | database_query | SUCCESS | 0.089s | CPU: 15.2% | Memory: 95.67MB (+0.12MB) | Threads: 8\n\n2025-07-05 20:15:45 - a1b2c3d4 - MonitoringLogger - INFO - RESOURCES | api_call | SUCCESS | 0.523s | CPU: 10.5% | Memory: 85.34MB (+2.15MB) | Threads: 10 | I/O: R:1.23MB W:0.05MB | Network: Sent:2.34KB Recv:125.67KB\n</code></pre>"},{"location":"features/resource-monitoring/#understanding-resource-metrics","title":"Understanding Resource Metrics","text":""},{"location":"features/resource-monitoring/#cpu-usage","title":"CPU Usage","text":"<p>Percentage of CPU time used by the process during execution:</p> <pre><code>@monitor_resources\ndef cpu_intensive():\n    # Heavy computation\n    result = [i**2 for i in range(10000000)]\n# CPU: 85.3% - high CPU usage during computation\n</code></pre>"},{"location":"features/resource-monitoring/#memory-usage","title":"Memory Usage","text":"<p>Current memory and change during execution:</p> <pre><code>@monitor_resources\ndef memory_allocation():\n    data = [0] * 10000000  # Allocates memory\n# Memory: 128.45MB (+40.23MB) - shows increase\n</code></pre>"},{"location":"features/resource-monitoring/#thread-count","title":"Thread Count","text":"<p>Number of threads in the process:</p> <pre><code>from concurrent.futures import ThreadPoolExecutor\n\n@monitor_resources\ndef multithreaded_operation():\n    with ThreadPoolExecutor(max_workers=5) as executor:\n        results = executor.map(process_item, items)\n# Threads: 15 - includes main thread + workers + system threads\n</code></pre>"},{"location":"features/resource-monitoring/#io-statistics","title":"I/O Statistics","text":"<p>Disk read and write operations:</p> <pre><code>@monitor_resources(include_io=True)\ndef file_operations():\n    data = open('file.txt').read()  # Read\n    open('output.txt', 'w').write(data)  # Write\n# I/O: R:45.23MB W:45.23MB\n</code></pre>"},{"location":"features/resource-monitoring/#network-statistics","title":"Network Statistics","text":"<p>Network send and receive operations (when <code>include_network=True</code>):</p> <pre><code>@monitor_resources(include_network=True)\ndef api_request():\n    response = requests.post(\"https://api.example.com\", json=large_payload)\n# Network: Sent:125.67KB Recv:45.23KB\n</code></pre>"},{"location":"features/resource-monitoring/#resource-monitoring-utilities","title":"Resource Monitoring Utilities","text":"<p>Access low-level resource monitoring:</p> <pre><code>from sherlock_ai import ResourceMonitor\n\n# Capture current resource snapshot\nsnapshot = ResourceMonitor.capture_resources()\nif snapshot:\n    print(f\"CPU: {snapshot.cpu_percent}%\")\n    print(f\"Memory: {ResourceMonitor.format_bytes(snapshot.memory_rss)}\")\n    print(f\"Threads: {snapshot.num_threads}\")\n\n# Capture memory snapshot\nmemory_snapshot = ResourceMonitor.capture_memory()\nprint(f\"Current memory: {ResourceMonitor.format_bytes(memory_snapshot.current_size)}\")\n\n# Format bytes in human-readable format\nformatted = ResourceMonitor.format_bytes(1024 * 1024 * 512)  # \"512.00MB\"\n</code></pre>"},{"location":"features/resource-monitoring/#best-practices","title":"Best Practices","text":""},{"location":"features/resource-monitoring/#1-selective-monitoring","title":"1. Selective Monitoring","text":"<p>Enable only the metrics you need:</p> <pre><code># Basic monitoring - CPU, memory, threads\n@monitor_resources\ndef basic_function():\n    pass\n\n# With I/O - for file operations\n@monitor_resources(include_io=True)\ndef file_function():\n    pass\n\n# Full monitoring - for network operations\n@monitor_resources(include_io=True, include_network=True)\ndef network_function():\n    pass\n</code></pre>"},{"location":"features/resource-monitoring/#2-minimum-duration-threshold","title":"2. Minimum Duration Threshold","text":"<p>Avoid noise from quick operations:</p> <pre><code>@monitor_resources(min_duration=0.1)  # Only log if &gt; 100ms\ndef frequent_operation():\n    return quick_calculation()\n</code></pre>"},{"location":"features/resource-monitoring/#3-target-critical-sections","title":"3. Target Critical Sections","text":"<p>Use context managers for specific blocks:</p> <pre><code>def complex_pipeline():\n    setup()  # Don't monitor\n\n    with ResourceTracker(\"processing\", include_io=True):\n        # Monitor only the resource-intensive part\n        result = process_large_dataset()\n\n    cleanup()  # Don't monitor\n    return result\n</code></pre>"},{"location":"features/resource-monitoring/#4-combine-with-other-monitoring","title":"4. Combine with Other Monitoring","text":"<p>Get comprehensive insights:</p> <pre><code>from sherlock_ai import log_performance, monitor_memory, monitor_resources\n\n@log_performance\n@monitor_memory(trace_malloc=True)\n@monitor_resources(include_io=True)\ndef comprehensive_monitoring():\n    # Tracks time, memory, AND system resources\n    return process_large_dataset()\n</code></pre>"},{"location":"features/resource-monitoring/#use-cases","title":"Use Cases","text":"<ul> <li>Performance Profiling: Identify CPU and memory bottlenecks</li> <li>I/O Optimization: Monitor disk read/write patterns</li> <li>Network Analysis: Track API call network usage</li> <li>Capacity Planning: Understand resource consumption patterns</li> <li>Multithreading Analysis: Monitor thread creation and usage</li> <li>Database Operations: Track I/O during database queries</li> <li>File Processing: Monitor resource usage in ETL pipelines</li> <li>API Monitoring: Track resource consumption per endpoint</li> </ul>"},{"location":"features/resource-monitoring/#performance-considerations","title":"Performance Considerations","text":""},{"location":"features/resource-monitoring/#network-monitoring-overhead","title":"Network Monitoring Overhead","text":"<p>Network monitoring adds minimal overhead but requires <code>psutil</code> with network support:</p> <pre><code># Only enable when needed\n@monitor_resources(include_network=True)  # Adds ~1-2% overhead\ndef api_operation():\n    pass\n</code></pre>"},{"location":"features/resource-monitoring/#io-monitoring","title":"I/O Monitoring","text":"<p>I/O monitoring is lightweight and enabled by default:</p> <pre><code>@monitor_resources(include_io=True)  # Minimal overhead\ndef file_operation():\n    pass\n</code></pre>"},{"location":"features/resource-monitoring/#high-frequency-operations","title":"High-Frequency Operations","text":"<p>For operations called very frequently:</p> <pre><code># Use minimum duration to reduce log volume\n@monitor_resources(min_duration=0.05)\ndef frequent_cache_operation():\n    return cache.get(key)\n</code></pre>"},{"location":"features/resource-monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/resource-monitoring/#high-cpu-usage","title":"High CPU Usage","text":"<p>If you see unexpected CPU usage: - Check for inefficient algorithms - Look for unnecessary loops or computations - Consider caching or optimization</p>"},{"location":"features/resource-monitoring/#high-memory-with-low-memory-change","title":"High Memory with Low Memory Change","text":"<p>If memory is high but change is small: - The baseline process memory is high - Consider process restart or memory cleanup - Check for memory leaks in earlier operations</p>"},{"location":"features/resource-monitoring/#no-io-statistics","title":"No I/O Statistics","text":"<p>If I/O shows 0.00B: - Operation might be using cache - I/O might be too small to measure - Check that <code>include_io=True</code> is set</p>"},{"location":"features/resource-monitoring/#network-statistics-not-available","title":"Network Statistics Not Available","text":"<p>If network monitoring fails: - Ensure <code>psutil</code> is properly installed - Check that the platform supports network monitoring - Some systems require elevated privileges</p>"},{"location":"features/resource-monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Performance Monitoring - Track execution times</li> <li>Memory Monitoring - Monitor memory usage</li> <li>Examples - Combined monitoring examples</li> <li>API Reference - Complete decorator reference</li> </ul>"},{"location":"guides/fastapi-setup/","title":"FastAPI Setup Guide","text":"<p>Step-by-step guide for integrating Sherlock AI with FastAPI applications.</p>"},{"location":"guides/fastapi-setup/#step-1-install-sherlock-ai","title":"Step 1: Install Sherlock AI","text":"<pre><code>pip install sherlock-ai\n</code></pre>"},{"location":"guides/fastapi-setup/#step-2-initialize-before-app-creation","title":"Step 2: Initialize Before App Creation","text":"<pre><code># main.py\nfrom fastapi import FastAPI\nfrom sherlock_ai import SherlockAI, LoggingConfig, get_logger\n\n# IMPORTANT: Initialize BEFORE creating app\nconfig = LoggingConfig(\n    auto_instrument=True,\n    log_format_type=\"json\"\n)\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\nlogger = get_logger(__name__)\n\n# Now create your app\napp = FastAPI()\n</code></pre>"},{"location":"guides/fastapi-setup/#step-3-add-request-id-middleware","title":"Step 3: Add Request ID Middleware","text":"<pre><code>from fastapi import Request\nfrom sherlock_ai import set_request_id\n\n@app.middleware(\"http\")\nasync def request_id_middleware(request: Request, call_next):\n    request_id = request.headers.get(\"X-Request-ID\", set_request_id())\n    response = await call_next(request)\n    response.headers[\"X-Request-ID\"] = request_id\n    return response\n</code></pre>"},{"location":"guides/fastapi-setup/#step-4-define-your-routes","title":"Step 4: Define Your Routes","text":"<pre><code>@app.get(\"/\")\ndef read_root():\n    logger.info(\"Root endpoint accessed\")\n    return {\"message\": \"Welcome\"}\n\n@app.get(\"/health\")\ndef health_check():\n    return {\"status\": \"healthy\"}\n</code></pre>"},{"location":"guides/fastapi-setup/#step-5-run-your-application","title":"Step 5: Run Your Application","text":"<pre><code>uvicorn main:app --reload\n</code></pre>"},{"location":"guides/fastapi-setup/#development-vs-production","title":"Development vs Production","text":"<pre><code>import os\n\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\n\nif env == \"production\":\n    from sherlock_ai import LoggingPresets\n    config = LoggingPresets.production()\n    config.auto_instrument = True\nelse:\n    config = LoggingConfig(\n        auto_instrument=True,\n        console_level=\"DEBUG\"\n    )\n</code></pre>"},{"location":"guides/fastapi-setup/#testing-the-setup","title":"Testing the Setup","text":"<pre><code># Test that monitoring works\nimport requests\n\nresponse = requests.get(\"http://localhost:8000/health\")\nprint(response.json())\n\n# Check logs directory\n# logs/application.json (or .log)\n# logs/performance.json\n# logs/errors.json\n</code></pre> <p>See complete example \u2192</p>"},{"location":"guides/production-deployment/","title":"Production Deployment","text":"<p>Best practices for deploying Sherlock AI in production environments.</p>"},{"location":"guides/production-deployment/#configuration","title":"Configuration","text":"<p>Use production preset with customizations:</p> <pre><code>from sherlock_ai import SherlockAI, LoggingPresets\nimport os\n\nconfig = LoggingPresets.production()\nconfig.auto_instrument = True\nconfig.log_format_type = \"json\"  # JSON for log aggregation\nconfig.logs_dir = \"/var/log/myapp\"\n\n# Add MongoDB for error insights\nos.environ[\"MONGO_URI\"] = os.getenv(\"MONGO_URI\")\nos.environ[\"SHERLOCK_AI_API_KEY\"] = os.getenv(\"SHERLOCK_AI_API_KEY\")\n\nlogger_manager = SherlockAI(config=config)\nlogger_manager.setup()\n</code></pre>"},{"location":"guides/production-deployment/#docker-setup","title":"Docker Setup","text":"<pre><code>FROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\n# Create logs directory\nRUN mkdir -p /var/log/myapp\n\n# Environment variables\nENV ENVIRONMENT=production\nENV MONGO_URI=mongodb://mongo:27017\nENV SHERLOCK_AI_API_KEY=your-api-key\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"guides/production-deployment/#docker-compose","title":"Docker Compose","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - ENVIRONMENT=production\n      - MONGO_URI=mongodb://mongo:27017\n      - SHERLOCK_AI_API_KEY=${SHERLOCK_AI_API_KEY}\n    volumes:\n      - ./logs:/var/log/myapp\n    depends_on:\n      - mongo\n\n  mongo:\n    image: mongo:latest\n    ports:\n      - \"27017:27017\"\n    volumes:\n      - mongodb_data:/data/db\n\nvolumes:\n  mongodb_data:\n</code></pre>"},{"location":"guides/production-deployment/#log-rotation","title":"Log Rotation","text":"<p>Configure appropriate rotation for production:</p> <pre><code>from sherlock_ai import LoggingConfig, LogFileConfig\n\nconfig = LoggingConfig(\n    logs_dir=\"/var/log/myapp\",\n    log_format_type=\"json\",\n    log_files={\n        \"app\": LogFileConfig(\n            \"application\",\n            max_bytes=100*1024*1024,  # 100MB\n            backup_count=20           # 2GB total\n        ),\n        \"errors\": LogFileConfig(\n            \"errors\",\n            level=\"ERROR\",\n            max_bytes=50*1024*1024,\n            backup_count=30\n        )\n    }\n)\n</code></pre>"},{"location":"guides/production-deployment/#monitoring","title":"Monitoring","text":"<p>Monitor log file sizes:</p> <pre><code># Add to cron or monitoring script\ndu -sh /var/log/myapp/*\n</code></pre>"},{"location":"guides/production-deployment/#environment-variables","title":"Environment Variables","text":"<pre><code># .env for production\nENVIRONMENT=production\nLOG_DIR=/var/log/myapp\nLOG_LEVEL=INFO\nMONGO_URI=mongodb://production-mongo:27017\nSHERLOCK_AI_API_KEY=production-api-key\n</code></pre>"},{"location":"guides/production-deployment/#health-checks","title":"Health Checks","text":"<pre><code>from sherlock_ai import get_logging_stats\n\n@app.get(\"/health/logging\")\ndef logging_health():\n    stats = get_logging_stats()\n    return {\n        \"configured\": stats[\"is_configured\"],\n        \"handlers\": stats[\"handlers\"],\n        \"logs_dir\": stats[\"logs_dir\"]\n    }\n</code></pre>"},{"location":"guides/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and solutions for Sherlock AI.</p>"},{"location":"guides/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"guides/troubleshooting/#import-error","title":"Import Error","text":"<p>Problem: <code>ModuleNotFoundError: No module named 'sherlock_ai'</code></p> <p>Solution: <pre><code>pip install sherlock-ai\n# or\npip install --upgrade sherlock-ai\n</code></pre></p>"},{"location":"guides/troubleshooting/#dependencies-missing","title":"Dependencies Missing","text":"<p>Problem: Missing dependencies for optional features</p> <p>Solution: <pre><code># For MongoDB support\npip install pymongo\n\n# For code analysis\npip install astor groq\n\n# For API client\npip install requests\n</code></pre></p>"},{"location":"guides/troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"guides/troubleshooting/#logs-not-created","title":"Logs Not Created","text":"<p>Problem: Log files not appearing in logs directory</p> <p>Solution: 1. Check directory permissions 2. Verify configuration: <pre><code>from sherlock_ai import get_logging_stats\nstats = get_logging_stats()\nprint(stats)\n</code></pre></p>"},{"location":"guides/troubleshooting/#duplicate-logs","title":"Duplicate Logs","text":"<p>Problem: Seeing duplicate log entries</p> <p>Solution: - Don't call <code>sherlock_ai()</code> multiple times - In FastAPI with reload, initialize only once</p>"},{"location":"guides/troubleshooting/#auto-instrumentation-not-working","title":"Auto-Instrumentation Not Working","text":"<p>Problem: FastAPI routes not being monitored</p> <p>Solution: <pre><code># Initialize BEFORE creating app\nlogging_manager = SherlockAI(config=config)\nlogging_manager.setup()\n\n# THEN create app\napp = FastAPI()\n</code></pre></p>"},{"location":"guides/troubleshooting/#monitoring-issues","title":"Monitoring Issues","text":""},{"location":"guides/troubleshooting/#performance-logs-missing","title":"Performance Logs Missing","text":"<p>Problem: No performance logs appearing</p> <p>Solution: - Ensure <code>@log_performance</code> decorator is applied - Check that performance log file is enabled: <pre><code>config = get_current_config()\nprint(config.log_files[\"performance\"].enabled)\n</code></pre></p>"},{"location":"guides/troubleshooting/#memory-monitoring-not-detailed","title":"Memory Monitoring Not Detailed","text":"<p>Problem: Memory logs don't show traced memory</p> <p>Solution: <pre><code># Enable tracemalloc\n@monitor_memory(trace_malloc=True)\ndef my_function():\n    pass\n</code></pre></p>"},{"location":"guides/troubleshooting/#storage-issues","title":"Storage Issues","text":""},{"location":"guides/troubleshooting/#mongodb-connection-failed","title":"MongoDB Connection Failed","text":"<p>Problem: Error insights not being stored</p> <p>Solution: <pre><code>import os\nfrom sherlock_ai.storage import MongoManager\n\nos.environ[\"MONGO_URI\"] = \"mongodb://localhost:27017\"\n\n# Verify connection\nmongo = MongoManager()\nprint(f\"MongoDB enabled: {mongo.enabled}\")\n</code></pre></p>"},{"location":"guides/troubleshooting/#api-client-authentication-failed","title":"API Client Authentication Failed","text":"<p>Problem: HTTP 401 when sending insights</p> <p>Solution: <pre><code>import os\n\n# Set API key\nos.environ[\"SHERLOCK_AI_API_KEY\"] = \"your-valid-api-key\"\n\n# Verify\nprint(os.getenv(\"SHERLOCK_AI_API_KEY\"))\n</code></pre></p>"},{"location":"guides/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"guides/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Problem: tracemalloc causing high memory usage</p> <p>Solution: <pre><code># Disable tracemalloc in production\n@monitor_memory(trace_malloc=False)\ndef my_function():\n    pass\n</code></pre></p>"},{"location":"guides/troubleshooting/#slow-performance","title":"Slow Performance","text":"<p>Problem: Monitoring adds too much overhead</p> <p>Solution: 1. Use <code>min_duration</code> to reduce logging: <pre><code>@log_performance(min_duration=0.1)  # Only log &gt; 100ms\ndef frequent_function():\n    pass\n</code></pre></p> <ol> <li>Disable unused monitoring: <pre><code>config = LoggingConfig()\nconfig.log_files[\"api\"].enabled = False\nconfig.log_files[\"services\"].enabled = False\n</code></pre></li> </ol>"},{"location":"guides/troubleshooting/#file-system-issues","title":"File System Issues","text":""},{"location":"guides/troubleshooting/#disk-space-full","title":"Disk Space Full","text":"<p>Problem: Running out of disk space</p> <p>Solution: 1. Reduce log file sizes: <pre><code>config.log_files[\"app\"].max_bytes = 10*1024*1024  # 10MB\nconfig.log_files[\"app\"].backup_count = 3\n</code></pre></p> <ol> <li>Clean up old logs: <pre><code>find /var/log/myapp -name \"*.log.*\" -mtime +7 -delete\n</code></pre></li> </ol>"},{"location":"guides/troubleshooting/#permission-denied","title":"Permission Denied","text":"<p>Problem: Cannot write to logs directory</p> <p>Solution: <pre><code># Fix permissions\nsudo chown -R your_user:your_group /var/log/myapp\nsudo chmod -R 755 /var/log/myapp\n</code></pre></p>"},{"location":"guides/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li>Check the GitHub Issues</li> <li>Enable debug logging: <pre><code>config = LoggingConfig(console_level=\"DEBUG\")\n</code></pre></li> <li>Check logging statistics: <pre><code>from sherlock_ai import get_logging_stats\nprint(get_logging_stats())\n</code></pre></li> </ol>"},{"location":"providers/","title":"Providers","text":"<p>Sherlock AI supports multiple providers for different integrations and AI-powered features. Configure providers to customize how Sherlock AI interacts with external services.</p>"},{"location":"providers/#available-providers","title":"Available Providers","text":""},{"location":"providers/#llm-providers","title":"LLM Providers","text":"<p>Configure AI language models for intelligent features like error analysis, performance insights, and code analysis.</p> <p>Learn more about LLM Providers \u2192</p> <p>Supported:</p> <ul> <li>Groq (default) - Fast inference with open-source models</li> <li>Azure OpenAI - Enterprise-grade OpenAI models on Azure</li> </ul>"},{"location":"providers/#why-multiple-providers","title":"Why Multiple Providers?","text":"<p>Sherlock AI's provider system gives you flexibility to:</p> <ul> <li>\u2705 Choose the best service for your infrastructure</li> <li>\u2705 Use enterprise solutions or open-source alternatives</li> <li>\u2705 Switch providers without changing your code</li> <li>\u2705 Support different environments (dev, staging, production)</li> </ul>"},{"location":"providers/#getting-started","title":"Getting Started","text":"<ol> <li>Choose your provider based on your needs</li> <li>Configure environment variables</li> <li>Sherlock AI automatically uses the configured provider</li> </ol>"},{"location":"providers/#provider-configuration","title":"Provider Configuration","text":"<p>Each provider has its own configuration requirements. Check the individual provider documentation for setup instructions.</p>"},{"location":"providers/#coming-soon","title":"Coming Soon","text":"<p>More provider integrations are planned:</p> <ul> <li>Additional LLM providers</li> <li>Monitoring backends</li> <li>Log aggregation services</li> <li>And more!</li> </ul>"},{"location":"providers/#next-steps","title":"Next Steps","text":"<ul> <li>LLM Providers - Configure AI language models</li> <li>Configuration - General configuration options</li> <li>Error Analysis - Use AI-powered error analysis</li> </ul>"},{"location":"providers/llm-providers/","title":"LLM Provider Configuration","text":"<p>Sherlock AI supports multiple LLM (Large Language Model) providers for AI-powered features like error analysis, performance insights, and code analysis. Choose the provider that best fits your infrastructure and requirements.</p>"},{"location":"providers/llm-providers/#overview","title":"Overview","text":"<p>LLM providers power these features:</p> <ul> <li>Error Analysis: AI-powered error cause detection</li> <li>Performance Insights: Intelligent performance bottleneck analysis</li> <li>Code Analysis: Smart constant naming suggestions</li> </ul>"},{"location":"providers/llm-providers/#supported-providers","title":"Supported Providers","text":""},{"location":"providers/llm-providers/#groq-default","title":"Groq (Default)","text":"<p>Fast inference with open-source models. Great for development and production use.</p> <p>Pros:</p> <ul> <li>\u26a1 Very fast inference</li> <li>\ud83c\udd93 Generous free tier</li> <li>\ud83d\udd13 Open-source models</li> <li>\ud83d\ude80 Simple setup (1 environment variable)</li> </ul>"},{"location":"providers/llm-providers/#azure-openai","title":"Azure OpenAI","text":"<p>Enterprise-grade OpenAI models hosted on Azure infrastructure.</p> <p>Pros:</p> <ul> <li>\ud83c\udfe2 Enterprise SLA and support</li> <li>\ud83d\udd10 Advanced security (VNet, private endpoints)</li> <li>\ud83c\udf0d Regional deployment options</li> <li>\ud83e\udd16 Access to latest GPT models</li> </ul>"},{"location":"providers/llm-providers/#quick-setup","title":"Quick Setup","text":""},{"location":"providers/llm-providers/#using-groq-default","title":"Using Groq (Default)","text":"<p>Groq is the default provider and requires only an API key:</p> <pre><code>import os\n\n# Set Groq API key\nos.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key\"\n</code></pre> <p>Environment Variables: <pre><code>export GROQ_API_KEY=\"your-groq-api-key\"\n</code></pre></p> <p>Get API Key:</p> <ol> <li>Visit console.groq.com</li> <li>Sign up for a free account</li> <li>Generate an API key</li> <li>Set the environment variable</li> </ol>"},{"location":"providers/llm-providers/#using-azure-openai","title":"Using Azure OpenAI","text":"<p>To use Azure OpenAI instead of Groq:</p> <pre><code>import os\n\n# Configure Azure OpenAI\nos.environ[\"LLM_PROVIDER\"] = \"azure_openai\"\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"your-azure-key\"\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://your-resource.openai.azure.com/\"\nos.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4-turbo\"\n</code></pre> <p>Environment Variables: <pre><code># Required\nexport LLM_PROVIDER=\"azure_openai\"\nexport AZURE_OPENAI_API_KEY=\"your-azure-openai-key\"\nexport AZURE_OPENAI_ENDPOINT=\"https://your-resource.openai.azure.com/\"\nexport AZURE_OPENAI_DEPLOYMENT_NAME=\"gpt-4-turbo\"\n\n# Optional (defaults to 2024-02-15-preview)\nexport AZURE_OPENAI_API_VERSION=\"2024-02-15-preview\"\n</code></pre></p> <p>Setup Steps:</p> <ol> <li>Create an Azure OpenAI resource in Azure Portal</li> <li>Deploy a model (e.g., gpt-4, gpt-4-turbo)</li> <li>Get your endpoint URL and API key</li> <li>Set the environment variables</li> </ol>"},{"location":"providers/llm-providers/#provider-comparison","title":"Provider Comparison","text":"Feature Groq Azure OpenAI Setup Complexity Simple (1 env var) Moderate (4 env vars) Cost Pay-per-use Enterprise pricing Models Open-source models GPT-3.5, GPT-4, GPT-4 Turbo Performance Very fast inference Standard OpenAI performance Enterprise Features Basic Advanced (VNet, Private endpoints) Free Tier Yes No Best For Development, fast iteration Enterprise, compliance needs"},{"location":"providers/llm-providers/#configuration-reference","title":"Configuration Reference","text":""},{"location":"providers/llm-providers/#groq-configuration","title":"Groq Configuration","text":"Environment Variable Required Default Description <code>GROQ_API_KEY</code> Yes None Your Groq API key"},{"location":"providers/llm-providers/#azure-openai-configuration","title":"Azure OpenAI Configuration","text":"Environment Variable Required Default Description <code>LLM_PROVIDER</code> Yes \"groq\" Set to \"azure_openai\" <code>AZURE_OPENAI_API_KEY</code> Yes None Azure OpenAI API key <code>AZURE_OPENAI_ENDPOINT</code> Yes None Azure OpenAI endpoint URL <code>AZURE_OPENAI_DEPLOYMENT_NAME</code> Yes None Deployment/model name <code>AZURE_OPENAI_API_VERSION</code> No \"2024-02-15-preview\" API version"},{"location":"providers/llm-providers/#using-with-features","title":"Using with Features","text":""},{"location":"providers/llm-providers/#error-analysis","title":"Error Analysis","text":"<pre><code>from sherlock_ai.monitoring import sherlock_error_handler\nimport os\n\n# Configure your provider\nos.environ[\"GROQ_API_KEY\"] = \"your-api-key\"\n\n@sherlock_error_handler\ndef risky_function():\n    # Errors automatically analyzed with configured LLM\n    result = 1 / 0\n    return result\n</code></pre>"},{"location":"providers/llm-providers/#code-analysis","title":"Code Analysis","text":"<pre><code>from sherlock_ai import hardcoded_value_detector\nimport os\n\n# Configure your provider\nos.environ[\"GROQ_API_KEY\"] = \"your-api-key\"\n\n@hardcoded_value_detector\ndef my_function():\n    # LLM suggests intelligent constant names\n    url = \"https://api.example.com\"\n    timeout = 30\n    return fetch_data(url, timeout)\n</code></pre>"},{"location":"providers/llm-providers/#performance-insights","title":"Performance Insights","text":"<pre><code>from sherlock_ai.monitoring import sherlock_performance_insights\nimport os\n\n# Configure your provider\nos.environ[\"GROQ_API_KEY\"] = \"your-api-key\"\n\n@sherlock_performance_insights\ndef slow_function():\n    # LLM analyzes performance bottlenecks\n    return expensive_computation()\n</code></pre>"},{"location":"providers/llm-providers/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"providers/llm-providers/#development","title":"Development","text":"<pre><code>import os\n\n# Use Groq for fast development\nos.environ[\"GROQ_API_KEY\"] = os.getenv(\"DEV_GROQ_KEY\")\n</code></pre>"},{"location":"providers/llm-providers/#production","title":"Production","text":"<pre><code>import os\n\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\n\nif env == \"production\":\n    # Use Azure OpenAI in production\n    os.environ[\"LLM_PROVIDER\"] = \"azure_openai\"\n    os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"PROD_AZURE_KEY\")\n    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"PROD_AZURE_ENDPOINT\")\n    os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4-turbo\"\nelse:\n    # Use Groq for development\n    os.environ[\"GROQ_API_KEY\"] = os.getenv(\"DEV_GROQ_KEY\")\n</code></pre>"},{"location":"providers/llm-providers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"providers/llm-providers/#provider-not-responding","title":"Provider Not Responding","text":"<p>Groq:</p> <ul> <li>Verify API key is set: <code>echo $GROQ_API_KEY</code></li> <li>Check rate limits at console.groq.com</li> <li>Ensure internet connectivity</li> </ul> <p>Azure OpenAI:</p> <ul> <li>Verify all 4 required environment variables are set</li> <li>Check endpoint URL format (must include https://)</li> <li>Verify deployment name matches Azure Portal</li> <li>Check Azure OpenAI resource is not paused</li> </ul>"},{"location":"providers/llm-providers/#api-key-invalid","title":"API Key Invalid","text":"<pre><code># Test your provider connection\nimport os\nfrom sherlock_ai.monitoring import sherlock_error_handler\n\n# This will show if provider is working\n@sherlock_error_handler\ndef test_provider():\n    raise ValueError(\"Test error\")\n\ntest_provider()\n# Check logs for successful AI analysis\n</code></pre>"},{"location":"providers/llm-providers/#no-ai-analysis-in-logs","title":"No AI Analysis in Logs","text":"<p>If you don't see AI-generated insights:</p> <ol> <li>Verify environment variables are set before importing sherlock_ai</li> <li>Check that decorators are properly applied</li> <li>Look for provider error messages in logs</li> <li>Ensure the decorated function actually raises an error</li> </ol>"},{"location":"providers/llm-providers/#best-practices","title":"Best Practices","text":""},{"location":"providers/llm-providers/#1-use-environment-variables","title":"1. Use Environment Variables","text":"<p>Don't hardcode API keys in your code:</p> <pre><code># \u274c Bad\nos.environ[\"GROQ_API_KEY\"] = \"gsk_abc123...\"\n\n# \u2705 Good\nos.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n</code></pre>"},{"location":"providers/llm-providers/#2-different-providers-per-environment","title":"2. Different Providers per Environment","text":"<pre><code># Development: Fast and free\nif os.getenv(\"ENV\") == \"dev\":\n    os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_KEY\")\n\n# Production: Enterprise features\nelif os.getenv(\"ENV\") == \"prod\":\n    os.environ[\"LLM_PROVIDER\"] = \"azure_openai\"\n    # ... Azure config\n</code></pre>"},{"location":"providers/llm-providers/#3-graceful-fallback","title":"3. Graceful Fallback","text":"<p>LLM features are optional - if provider fails, Sherlock AI continues logging without AI analysis.</p>"},{"location":"providers/llm-providers/#4-cost-management","title":"4. Cost Management","text":"<p>Monitor your usage:</p> <ul> <li>Groq: Check console.groq.com for usage</li> <li>Azure OpenAI: Monitor in Azure Portal</li> </ul>"},{"location":"providers/llm-providers/#coming-soon","title":"Coming Soon","text":"<p>Additional LLM providers planned:</p> <ul> <li>OpenAI (direct)</li> <li>Anthropic Claude</li> <li>Local models (Ollama)</li> <li>AWS Bedrock</li> </ul>"},{"location":"providers/llm-providers/#next-steps","title":"Next Steps","text":"<ul> <li>Error Analysis - AI-powered error insights</li> <li>Code Analysis - Intelligent code analysis</li> <li>Configuration - General configuration</li> <li>Troubleshooting - Common issues</li> </ul>"}]}